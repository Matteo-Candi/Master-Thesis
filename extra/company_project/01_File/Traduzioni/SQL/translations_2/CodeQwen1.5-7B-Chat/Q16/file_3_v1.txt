system
You are an expert in translating code from SQL to PySpark error-free, maintaining all functionality; the code is commented but not exaplined; do not use spark.sql() function and define properly columns; PySpark code is more efficient than SQL one while keeping it readable and concise.
user
Translate the following code from SQL to PySpark:
CREATE OR REPLACE
FORCE EDITIONABLE VIEW "DDWH02_SM"."VW_EKKO_PURCH_DOC_HEADER_AGCE" ("EKKO_DT_LAST_MODIFY",
                                                                    "EKKO_ID_PURCH_DOC_HEADER_GPP",
                                                                    "EKKO_CD_PURCH_DOC_NBR",
                                                                    "EKKO_NR_TOT_VAL_OF_RELEASE",
                                                                    "EKKO_DT_PURCH_DOC_DATE",
                                                                    "EKKO_DT_RECORD_CREATED_ON",
                                                                    "EKKO_CD_PURCH_GRP",
                                                                    "EKKO_FL_TAKE_PURCH_GRP",
                                                                    "EKKO_CD_VENDOR_ACCOUNT_NBR",
                                                                    "EKKO_CD_DOC_PROCESS_STATE",
                                                                    "EKKO_CD_PURCH_DOC_CATEGORY",
                                                                    "EKKO_CD_PURCH_DOCTYPE",
                                                                    "EKKO_DT_CONTRACT_START_DATE",
                                                                    "EKKO_NR_CHG_TIMESTAMP",
                                                                    "EKKO_DT_CONTRACT_END_DATE",
                                                                    "EKKO_CD_PURCH_DOC_STATUS",
                                                                    "EKKO_NR_CURRENCY_KEY",
                                                                    "EKKO_CD_PURCH_AGREEMENT_NBR",
                                                                    "EKKO_CD_OBJ_CREATED_BY",
                                                                    "EKKO_CD_INCOTERMS_PART_1",
                                                                    "EKKO_CD_INCOTERMS_PART_2",
                                                                    "EKKO_CD_TERMS_OF_PAYMENT_1",
                                                                    "EKKO_CD_PURCH_ORG_1",
                                                                    "EKKO_CD_COMPANY_CODE",
                                                                    "EKKO_CD_REMARK_1",
                                                                    "EKKO_NR_PURCH_DOC_YEAR",
                                                                    "PLBR_DS_PLANT_SEGMENT",
                                                                    "ODAG_PODOCUMENTTYPE",
                                                                    "ODAG_SUPPLIERCODE",
                                                                    "EKKO_DT_RETENTION_YEAR",
                                                                    "ODAG_PODOCUMENTYEAR",
                                                                    "EKKO_CD_PURCH_DOC_NBR10",
                                                                    "EKKO_CD_SUPPLIER_TYPE") AS
SELECT EKKO_DT_LAST_MODIFY,
       EKKO_ID_PURCH_DOC_HEADER_GPP,
       EKKO_CD_PURCH_DOC_NBR,
       EKKO_NR_TOT_VAL_OF_RELEASE,
       EKKO_DT_PURCH_DOC_DATE,
       EKKO_DT_RECORD_CREATED_ON,
       EKKO_CD_PURCH_GRP,
       EKKO_FL_TAKE_PURCH_GRP,
       EKKO_CD_VENDOR_ACCOUNT_NBR,
       EKKO_CD_DOC_PROCESS_STATE,
       EKKO_CD_PURCH_DOC_CATEGORY,
       EKKO_CD_PURCH_DOCTYPE,
       EKKO_DT_CONTRACT_START_DATE,
       EKKO_NR_CHG_TIMESTAMP,
       EKKO_DT_CONTRACT_END_DATE,
       EKKO_CD_PURCH_DOC_STATUS,
       EKKO_NR_CURRENCY_KEY,
       EKKO_CD_PURCH_AGREEMENT_NBR,
       EKKO_CD_OBJ_CREATED_BY,
       EKKO_CD_INCOTERMS_PART_1,
       EKKO_CD_INCOTERMS_PART_2,
       EKKO_CD_TERMS_OF_PAYMENT_1,
       EKKO_CD_PURCH_ORG_1,
       EKKO_CD_COMPANY_CODE,
       EKKO_CD_REMARK_1,
       TO_NUMBER(TO_CHAR(EKKO_DT_PURCH_DOC_DATE, 'YYYY')) AS EKKO_NR_PURCH_DOC_YEAR,
       ' ' AS PLBR_DS_PLANT_SEGMENT,
       EKKO_CD_PURCH_DOCTYPE AS ODAG_PODOCUMENTTYPE,
       EKKO_CD_VENDOR_ACCOUNT_NBR AS ODAG_SUPPLIERCODE,
       TO_CHAR(COALESCE(EKKO_DT_CONTRACT_END_DATE, EKKO_DT_RECORD_CREATED_ON), 'YYYY') AS EKKO_DT_RETENTION_YEAR,
       TO_CHAR(EKKO_DT_PURCH_DOC_DATE, 'YYYY') AS ODAG_PODOCUMENTYEAR,
       to_Char(substr('0000000000' || EKKO_CD_PURCH_DOC_NBR, -10)) AS EKKO_CD_PURCH_DOC_NBR10,
       Supplier_Type AS EKKO_CD_SUPPLIER_TYPE
FROM ddwh01_dw.TT_EKKO_PURCH_DOC_HEADER_GPP
INNER JOIN
  (SELECT DISTINCT EKPO_CD_PO_NBR
   FROM ddwh01_dw.TT_EKPO_PURCH_DOC_ITEM_GPP
   INNER JOIN ddwh01_dw.TD_PLBR_PLANT_BRANCHES ON EKPO_CD_PLANT = PLBR_CD_PLANT
   AND PLBR_DS_PLANT_SEGMENT IN ('AG',
                                 'CE',
                                 '-1',
                                 'AM',
                                 'AS')
   AND (EKPO_CD_PLANT NOT IN ('FA01',
                              'FB01',
                              'IA01')
        OR EKPO_CD_PLANT NOt like '00%')) AGCE ON EKKO_CD_PURCH_DOC_NBR = AGCE.EKPO_CD_PO_NBR
LEFT JOIN
  (SELECT DISTINCT SUPM_CD_ACCOUNT_NBR,
                   CASE
                       WHEN LENGTH(SUPM_CD_COMP_TRADING_PARTNER) > 1 THEN 'Intercompany'
                       ELSE 'Third Party'
                   END AS Supplier_Type
   FROM ddwh01_dw.TM_SUPM_SUPPLIER_GPP) SUPM ON EKKO_CD_VENDOR_ACCOUNT_NBR = SUPM.SUPM_CD_ACCOUNT_NBR;
assistant
Here is the equivalent PySpark code:

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, to_char, to_number, coalesce, substr

# Create SparkSession
spark = SparkSession.builder.appName("Translate SQL to PySpark").getOrCreate()

# Define the columns
columns = [
    "EKKO_DT_LAST_MODIFY",
    "EKKO_ID_PURCH_DOC_HEADER_GPP",
    "EKKO_CD_PURCH_DOC_NBR",
    "EKKO_NR_TOT_VAL_OF_RELEASE",
    "EKKO_DT_PURCH_DOC_DATE",
    "EKKO_DT_RECORD_CREATED_ON",
    "EKKO_CD_PURCH_GRP",
    "EKKO_FL_TAKE_PURCH_GRP",
    "EKKO_CD_VENDOR_ACCOUNT_NBR",
    "EKKO_CD_DOC_PROCESS_STATE",
    "EKKO_CD_PURCH_DOC_CATEGORY",
    "EKKO_CD_PURCH_DOCTYPE",
    "EKKO_DT_CONTRACT_START_DATE",
    "EKKO_NR_CHG_TIMESTAMP",
    "EKKO_DT_CONTRACT_END_DATE",
    "EKKO_CD_PURCH_DOC_STATUS",
    "EKKO_NR_CURRENCY_KEY",
    "EKKO_CD_PURCH_AGREEMENT_NBR",
    "EKKO_CD_OBJ_CREATED_BY",
    "EKKO_CD_INCOTERMS_PART_1",
    "EKKO_CD_INCOTERMS_PART_2",
    "EKKO_CD_TERMS_OF_PAYMENT_1",
    "EKKO_CD_PURCH_ORG_1",
    "EKKO_CD_COMPANY_CODE",
    "EKKO_CD_REMARK_1",
    "EKKO_NR_PURCH_DOC_YEAR",
    "PLBR_DS_PLANT_SEGMENT",
    "ODAG_PODOCUMENTTYPE",
    "ODAG_SUPPLIERCODE",
    "EKKO_DT_RETENTION_YEAR",
    "ODAG_PODOCUMENTYEAR",
    "EKKO_CD_PURCH_DOC_NBR10",
    "EKKO_CD_SUPPLIER_TYPE"
]

# Load data from source tables
ekko_df = spark.table("ddwh01_dw.TT_EKKO_PURCH_DOC_HEADER_GPP")
ekpo_df = spark.table("ddwh01_dw.TT_EKPO_PURCH_DOC_ITEM_GPP")
plbr_df = spark.table("ddwh01_dw.TD_PLBR_PLANT_BRANCHES")
supm_df = spark.table("ddwh01_dw.TM_SUPM_SUPPLIER_GPP")

# Perform the JOINs
agce_df = ekko_df.join(ekpo_df, ekko_df["EKKO_CD_PURCH_DOC_NBR"] == ekpo_df["EKPO_CD_PO_NBR"], "inner") \
    .join(plbr_df, ekpo_df["EKPO_CD_PLANT"] == plbr_df["PLBR_CD_PLANT"]
          & (plbr_df["PLBR_DS_PLANT_SEGMENT"].isin(['AG', 'CE', '-1', 'AM', 'AS'])
             | (plbr_df["EKPO_CD_PLANT"].isin(['FA01', 'FB01', 'IA01'])
                & ~plbr_df["EKPO_CD_PLANT"].startswith('00'))))

# Perform the LEFT JOIN
supm_df = supm_df.alias("supm")
agce_df = agce_df.alias("agce")
agce_df = agce_df.join(supm_df, agce_df["EKKO_CD_VENDOR_ACCOUNT_NBR"] == supm_df["SUPM_CD_ACCOUNT_NBR"], "left")

# Perform the SELECTs
agce_df = agce_df.select(columns)

# Perform the calculations
agce_df = agce_df.withColumn("EKKO_NR_PURCH_DOC_YEAR", to_number(to_char(col("EKKO_DT_PURCH_DOC_DATE"), 'YYYY'))) \
    .withColumn("PLBR_DS_PLANT_SEGMENT", lit(' ')) \
    .withColumn("ODAG_PODOCUMENTTYPE", col("EKKO_CD_PURCH_DOCTYPE")) \
    .withColumn("ODAG_SUPPLIERCODE", col("EKKO_CD_VENDOR_ACCOUNT_NBR")) \
    .withColumn("EKKO_DT_RETENTION_YEAR", to_char(coalesce(col("EKKO_DT_CONTRACT_END_DATE"), col("EKKO_DT_RECORD_CREATED_ON")), 'YYYY')) \
    .withColumn("ODAG_PODOCUMENTYEAR", to_char(col("EKKO_DT_PURCH_DOC_DATE"), 'YYYY')) \
    .withColumn("EKKO_CD_PURCH_DOC_NBR10", to_char(substr(concat('0000000000', col("EKKO_CD_PURCH_DOC_NBR")), -10))) \
    .withColumn("EKKO_CD_SUPPLIER_TYPE", when(length(col("supm.SUPM_CD_COMP_TRADING_PARTNER")) > 1, 'Intercompany').otherwise('Third Party'))

# Display the result
agce_df.show()
```

Please note that the above code assumes that the PySpark environment is properly set up and the source tables are accessible.