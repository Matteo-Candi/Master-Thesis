
The translated code in PySpark would be as follows:

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import to_char, coalesce, ltrim, replace, substr, nvl, instr

# Initialize a Spark session
spark = SparkSession.builder \
    .appName("Translate SQL to PySpark") \
    .getOrCreate()

# Read the table from DDWH01_DW database in SQL format
df_tt_ekpo_purch_doc_item_gpp = spark.read.format('jdbc') \
    .option('url', 'jdbc:sqlserver://<database_host>;database=DDWH01_DW') \
    .option('dbtable', 'TT_EKPO_PURCH_DOC_ITEM_GPP') \
    .load()

# Perform necessary transformations and calculations on the dataframe
df_tt_ekpo_purch_doc_item_gpp = df_tt_ekpo_purch_doc_item_gpp.withColumn('EKPO_NR_PURCH_DOC_YEAR', to_char(df_tt_ekpo_purch_doc_item_gpp['EKKO_DT_PURCH_DOC_DATE'], 'yyyy')) \
    .withColumn('ODAG_PARTNUMBER', df_tt_ekpo_purch_doc_item_gpp['EKPO_CD_MATERIAL_NBR']) \
    .withColumn('ODAG_PROGRAM', df_tt_ekpo_purch_doc_item_gpp['EKPO_CD_PROGRAM_ID']) \
    .withColumn('ODAG_PODOCUMENT', concat(df_tt_ekpo_purch_doc_item_gpp['EKPO_CD_PO_NBR'], lit('-'), df_tt_ekpo_purch_doc_item_gpp['EKPO_NR_ITEM_NBR_PO'])) \
    .withColumn('EKPO_DT_RETENTION_YEAR', to_char(coalesce(df_tt_ekpo_purch_doc_item_gpp['EKKO_DT_CONTRACT_END_DATE'], df_tt_ekpo_purch_doc_item_gpp['EKKO_DT_RECORD_CREATED_ON']), 'yyyy')) \
    .withColumn('EKPO_NR_NET_WEIGHT', df_tt_ekpo_purch_doc_item_gpp['EKPO_NR_NET_WEIGHT'] / 1000) \
    .withColumn('EKPO_NR_GROSS_WEIGHT', df_tt_ekpo_purch_doc_item_gpp['EKPO_NR_GROSS_WEIGHT'] / 1000) \
    .withColumn('EKPO_CD_PLANT_R3_STC', coalesce(df_tt_ekpo_purch_doc_item_gpp['PF.TRGE_CD_DESTINATION_DATA'], df_tt_ekpo_purch_doc_item_gpp['EKPO_CD_PLANT']))

# Write the transformed dataframe back to DDWH01_DW database in Parquet format
df_tt_ekpo_purch_doc_item_gpp.write.format('parquet').save('/path/to/output')
```