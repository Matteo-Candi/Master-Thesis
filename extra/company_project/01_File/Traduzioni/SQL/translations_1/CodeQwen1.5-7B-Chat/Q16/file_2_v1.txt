system
You are an expert in translating code from SQL to PySpark. Translate anyway at the best that you can. Return just the code with comments. Do not explain the code.
user
Translate the following code from SQL to PySpark:
INSERT INTO ddwh01_dw.td_aemr_retail_history (aemr_id_retail_history, aemr_cd_scenario, aemr_cd_rep_company_code, aemr_cd_program_code, aemr_cd_prodruct_code, aemr_cd_model_chart, aemr_cd_rep_frequency, aemr_cd_activity_code, aemr_cd_size_code, aemr_cd_upper_size, aemr_cd_lower_size, aemr_cd_year, aemr_cd_month, aemr_dt_rdate, aemr_dt_post_date, aemr_cd_fips_country_code, aemr_cd_fips_state_code, aemr_cd_fips_county_code, aemr_cd_fips_sub_county_code, aemr_cd_customer_type_code, aemr_cd_end_use_code, aemr_cd_attribute, aemr_qt_retail_qty, aemr_cd_source_system, aemr_id_batch_id, aemr_cd_vin, aemr_cd_model_id)
SELECT ddwh01_dw.seq_aemr_td00001.nextval,
       CASE
           WHEN TO_CHAR (main1.postdate,
                         'YYYYMM') = TO_CHAR (main1.rdate,
                                              'YYYYMM') THEN 'COMPANY DATA'
           ELSE 'COMPANY REVISION'
       END AS aemr_cd_scenario,
       company_id AS aemr_cd_rep_company_code,
       SUBSTR (product_id,
               1,
               2) AS aemr_cd_program_code,
              SUBSTR (product_id,
                      3,
                      2) AS aemr_cd_prodruct_code,
                     chart_id AS aemr_cd_model_chart,
                     frequency_id AS aemr_cd_rep_frequency,
                     lpad (activity_id, 3, 0) AS aemr_cd_activity_code,
                     size_id AS aemr_cd_size_code,
                     NULL AS aemr_cd_upper_size,
                     NULL AS aemr_cd_lower_size,
                     main1.cd_year AS aemr_cd_year,
                     lpad (period, 2, 0) AS aemr_cd_month,
                     rdate AS aemr_dt_rdate,
                     main1.postdate AS aemr_dt_post_date,
                     SUBSTR (geography_id,
                             1,
                             3) AS aemr_cd_fips_country_code,
                            SUBSTR (geography_id,
                                    4,
                                    3) AS aemr_cd_fips_state_code,
                                   SUBSTR (geography_id,
                                           7,
                                           3) AS aemr_cd_fips_county_code,
                                          SUBSTR (geography_id,
                                                  10,
                                                  3) AS aemr_cd_fips_sub_county_code,
                                                 lpad (customer_type_id, 3, '0') AS aemr_cd_customer_type_code,
                                                 lpad (end_use_id, 3, '0') AS aemr_cd_end_use_code,
                                                 NULL AS aemr_cd_attribute,
                                                 count_id AS aemr_qt_retail_qty,
                                                 'US AEM' AS aemr_cd_source_system,
                                                 1 AS aemr_id_batch_id,
                                                 NULL AS aemr_cd_vin,
                                                 chart_id AS aemr_cd_model_id
FROM ddwh00_sa.ts_aemi0004_us_aem main1
WHERE company_id IN ('JIC',
                     'FOR')
  AND frequency_id = 'M'
  AND CASE
          WHEN product_id IN ('CEB0',
                              'CEE2',
                              'CEE3',
                              'CEF0',
                              'CEG0') THEN '010'
          ELSE '011'
      END = lpad (activity_id, 3, '0')
  AND attribute_id = '99' ;
assistant
The following is the translated PySpark code:

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lpad, when, to_char

# Create a SparkSession
spark = SparkSession.builder.appName('aemr_retail_history').getOrCreate()

# Read data from the source table
df_source = spark.table("ddwh00_sa.ts_aemi0004_us_aem")

# Perform the necessary transformations
df_transformed = (
    df_source
    .filter(col("company_id").isin("JIC", "FOR"))
    .filter(col("frequency_id") == "M")
    .filter(when(col("product_id").isin("CEB0", "CEE2", "CEE3", "CEF0", "CEG0"), "010").otherwise("011") == col("activity_id").cast("string").lpad(3, "0"))
    .filter(col("attribute_id") == "99")
    .withColumn("aemr_cd_scenario", when(to_char(col("postdate"), "YYYYMM") == to_char(col("rdate"), "YYYYMM"), "COMPANY DATA").otherwise("COMPANY REVISION"))
    .withColumn("aemr_cd_rep_company_code", col("company_id"))
    .withColumn("aemr_cd_program_code", col("product_id").substr(1, 2))
    .withColumn("aemr_cd_prodruct_code", col("product_id").substr(3, 2))
    .withColumn("aemr_cd_model_chart", col("chart_id"))
    .withColumn("aemr_cd_rep_frequency", col("frequency_id"))
    .withColumn("aemr_cd_activity_code", col("activity_id").cast("string").lpad(3, "0"))
    .withColumn("aemr_cd_size_code", col("size_id"))
    .withColumn("aemr_cd_upper_size", None)
    .withColumn("aemr_cd_lower_size", None)
    .withColumn("aemr_cd_year", col("cd_year"))
    .withColumn("aemr_cd_month", col("period").cast("string").lpad(2, "0"))
    .withColumn("aemr_dt_rdate", col("rdate"))
    .withColumn("aemr_dt_post_date", col("postdate"))
    .withColumn("aemr_cd_fips_country_code", col("geography_id").substr(1, 3))
    .withColumn("aemr_cd_fips_state_code", col("geography_id").substr(4, 3))
    .withColumn("aemr_cd_fips_county_code", col("geography_id").substr(7, 3))
    .withColumn("aemr_cd_fips_sub_county_code", col("geography_id").substr(10, 3))
    .withColumn("aemr_cd_customer_type_code", col("customer_type_id").cast("string").lpad(3, "0"))
    .withColumn("aemr_cd_end_use_code", col("end_use_id").cast("string").lpad(3, "0"))
    .withColumn("aemr_cd_attribute", None)
    .withColumn("aemr_qt_retail_qty", col("count_id"))
    .withColumn("aemr_cd_source_system", "US AEM")
    .withColumn("aemr_id_batch_id", 1)
    .withColumn("aemr_cd_vin", None)
    .withColumn("aemr_cd_model_id", col("chart_id"))
)

# Generate the next value from the sequence
next_value = spark.sql("SELECT nextval FROM ddwh01_dw.seq_aemr_td00001").first()[0]

# Assign the next value to the aemr_id_retail_history column
df_transformed = df_transformed.withColumn("aemr_id_retail_history", next_value)

# Write the transformed data to the target table
df_transformed.write.insertInto("ddwh01_dw.td_aemr_retail_history", overwrite=True)
```

Please note that this code assumes that the sequence `ddwh01_dw.seq_aemr_td00001` is already created and has the necessary permissions to generate the next value.