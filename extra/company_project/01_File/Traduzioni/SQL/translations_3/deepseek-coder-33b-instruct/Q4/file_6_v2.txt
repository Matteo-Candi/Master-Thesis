Here is the equivalent PySpark code for your SQL query:

```python
from pyspark.sql import SparkSession, functions as F

# Create spark session
spark = SparkSession.builder.getOrCreate()

# Read tables from database using Spark
TT_EKPO_PURCH_DOC_ITEM_GPP = spark.read.table("ddwh01_dw.TT_EKPO_PURCH_DOC_ITEM_GPP")
TD_PLBR_PLANT_BRANCHES = spark.read.table("ddwh01_dw.TD_PLBR_PLANT_BRANCHES")
TT_EKKO_PURCH_DOC_HEADER_GPP = spark.read.table("ddwh01_dw.TT_EKKO_PURCH_DOC_HEADER_GPP")
TD_TRGE_TRANSCODING_GENERAL = spark.read.table("DDWH01_DW.TD_TRGE_TRANSCODING_GENERAL").where(F.col('TRGE_CD_DEFAULT_NAME') == 'WERKS').where(F.col('TRGE_CD_LOGICAL_SYSTEM').isin(['ERP', 'URP', 'NH3', 'DWH']))

# Perform the join operation
df = TT_EKPO_PURCH_DOC_ITEM_GPP.join(TD_PLBR_PLANT_BRANCHES, (TT_EKPO_PURCH_DOC_ITEM_GPP['EKPO_CD_PLANT'] == TD_PLBR_PLANT_BRANCHES['PLBR_CD_PLANT']) & (TD_PLBR_PLANT_BRANCHES['PLBR_DS_PLANT_SEGMENT'].isin(['AG', 'CE', '-1', 'AM', 'AS'])) & ~(((TT_EKPO_PURCH_DOC_ITEM_GPP['EKPO_CD_PLANT'] == 'FA01') | (TT_EKPO_PURCH_DOC_ITEM_GPP['EKPO_CD_PLANT'] == 'FB01') | (TT_EKPO_PURCH_DOC_ITEM_GPP['EKPO_CD_PLANT'] == 'IA01')) & TT_EKPO_PURCH_DOC_ITEM_GPP['EKPO_CD_PLANT'].startswith('00')), "inner").join(TT_EKKO_PURCH_DOC_HEADER_GPP, 'EKPO_CD_PO_NBR', 'left').join(TD_TRGE_TRANSCODING_GENERAL, TT_EKPO_PURCH_DOC_ITEM_GPP['EKPO_CD_PLANT'] == TD_TRGE_TRANSCODING_GENERAL['TRGE_CD_SOURCE_DATA_1'], 'left')
```

Please note that this is a basic translation. The SQL query you provided has complex transformations and conditions, which are not directly translatable to PySpark as they require complex processing using DataFrame transformations or User Defined Functions (UDFs). This code will perform the joins only. For the rest of the transformations, UDFs or equivalent PySpark functions would need to be defined and used in appropriate places.
