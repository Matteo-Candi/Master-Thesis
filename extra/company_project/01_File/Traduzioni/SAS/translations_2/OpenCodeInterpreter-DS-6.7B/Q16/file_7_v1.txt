You are an AI programming assistant, utilizing the Deepseek Coder model, developed by Deepseek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.
### Instruction:
You are an expert in translating code from SAS to Python error-free, maintaining all functionality; the code is commented but not exaplined; variables, file paths and libraries used are well defined or imported; Python code is more efficient than SAS one while keeping it readable and concise.
Translate the following code from SAS to Python:
libname ter "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";
libname sez "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";

libname ter_out "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";
libname sez_out "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";

libname appo "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";

options mergenoby = warn;
options nolabel;

%include "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\Macro\macroquadraturagruppo.sas";
%include "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\Macro\macroarrotondainterogruppo.sas";

title1 "STIMA COMUNALE DEI CONSUMI";

ods graphics off;


PROC IMPORT OUT= WORK.xconsumi_tag
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\tag_00026.xlsx"
            DBMS=EXCEL2000 REPLACE;
			SHEET="TAG-00026_4";
     		RANGE="A3:G132";
     		GETNAMES=YES;
			*MIXED = YES;	
RUN;
PROC IMPORT OUT= WORK.xreddito_tag
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\tag_00027.xlsx"
            DBMS=EXCEL2000 REPLACE;
			SHEET="TAG-00027_2";
     		RANGE="A3:G132";
     		GETNAMES=YES;
			*MIXED = YES;	
RUN;
data consumi_tag;
	set xconsumi_tag;
	if province_e_regioni ~= upcase(province_e_regioni)
	or province_e_regioni = "VALLE D'AOSTA/VALL�E D'AOSTE";
	consumi = _017/1000;
	keep province_e_regioni consumi;
run;
proc sort data = consumi_tag;
	by province_e_regioni;
run;
data reddito_tag;
	set xreddito_tag;
	if province_e_regioni ~= upcase(province_e_regioni)
	or province_e_regioni = "VALLE D'AOSTA/VALL�E D'AOSTE";
	reddito = _017/1000;
	keep province_e_regioni reddito;
run;
proc sort data = reddito_tag;
	by province_e_regioni;
run;
data base_tag;
	merge reddito_tag consumi_tag;
	by province_e_regioni;
	propensione = consumi/reddito;
	inverso = (1/reddito);
run;


proc univariate data = base_tag;
	var propensione;
	histogram propensione;
run;
proc gplot data = base_tag;
	symbol1 i = none  v = dot c = black;
	plot propensione * reddito = 1;
run;
quit;
proc gplot data = base_tag;
	symbol1 i = none  v = dot c = black;
	plot propensione * inverso = 1;
run;
quit;
proc corr data = base_tag;
	var propensione reddito inverso;
run;
proc reg data = base_tag;
	model propensione = reddito;
run;
quit;
proc reg data = base_tag;
	model propensione = inverso;
run;
quit;


PROC IMPORT OUT= WORK.provincia
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\provincia_110.xlsx"
            DBMS=EXCEL2000 REPLACE;
			SHEET="Sheet1";
     		GETNAMES=YES;
RUN;
data provincia;
	set provincia;
	Denominazione_Provincia_Citt__me = upcase(Denominazione_Provincia_Citt__me);
	if Denominazione_Provincia_Citt__me = "REGGIO DI CALABRIA"
		then Denominazione_Provincia_Citt__me = "REGGIO CALABRIA";
run;
data base_tag;
	set base_tag;
	province_e_regioni = upcase(province_e_regioni);
run;
proc sort data = provincia;
	by Denominazione_Provincia_Citt__me;
run;
data base_tag;
	merge base_tag provincia (rename=(Denominazione_Provincia_Citt__me=province_e_regioni));
	by province_e_regioni;
run;


PROC IMPORT OUT= WORK.corrispo
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\Codici-statistici-e-denominazioni-al-31_12_2020.xls"
            DBMS=EXCEL2000 REPLACE;
			SHEET="CODICI al 31_12_2020";
     		GETNAMES=YES;
			*MIXED = YES;	
RUN;
data corrispo;
	set corrispo;
	length codice_provincia $ 3;
	codice_provincia = substr(put(Codice_Comune_numerico_con_110_p,z6.),1,3);
	keep Codice_Comune_formato_alfanumeri codice_provincia;
	rename Codice_Comune_formato_alfanumeri = codice_comune__str;
run;
proc sort data = corrispo;
	by codice_comune__str;
run;
data xcod;
	set ter_out.geografica_comune;
	keep codice_comune__str codice_area_nielsen codice_ripartizione;
run;
proc sort data = xcod;
	by codice_comune__str;
run;
proc means data = ter_out.Popolazione_eta_sesso_comune noprint;
	class codice_comune__str;
	types codice_comune__str;
	output out = popnew (drop = _type_ _freq_)
		   sum(popolazione) = pop_ult;
run;
data xcod;
	merge xcod corrispo popnew;
	by codice_comune__str;
run;
proc means data = xcod noprint;
	class codice_provincia;
	types codice_provincia;
	id codice_area_nielsen codice_ripartizione;
	output out = xcods (drop = _type_ _freq_)
		   sum(pop_ult) = ;
run;
proc sort data = base_tag;
	by codice_provincia;
run;
data base_tag;
	merge base_tag xcods;
	by codice_provincia;
run;


proc sort data = base_tag;
	by codice_ripartizione;
run;
proc corr data = base_tag;
	by codice_ripartizione;
	var propensione reddito inverso;
run;
proc gplot data = base_tag;
	by codice_ripartizione;
	symbol1 i = none  v = dot c = black;
	plot propensione * reddito = 1;
run;
quit;
proc gplot data = base_tag;
	by codice_ripartizione;
	symbol1 i = none  v = dot c = black;
	plot propensione * inverso = 1;
run;
quit;
data base_tag;
	set base_tag;
	array ripart{4};
	do i = 1 to 4;
		ripart{i} = (codice_ripartizione = i);
	end;
	drop i;
run;
proc reg data = base_tag;
	weight pop_ult;
	model propensione = reddito ripart1 ripart2 ripart3 ripart4;
run;
quit;
proc reg data = base_tag;
	weight pop_ult;
	model propensione = inverso ripart1 ripart2 ripart3 ripart4;
run;
quit;
proc reg data = base_tag;
	weight pop_ult;
	by codice_ripartizione;
	model propensione = inverso;
run;
quit;


proc reg data = base_tag;
	weight pop_ult;
	model propensione = inverso ripart1 ripart2 ripart3 ripart4;
	output out = esitoreg
		   p = yteorica
		   rstudent = rstud;
run;
quit;
data base_dep;
	set esitoreg;
	if abs(rstud) < 2;
	drop yteorica;
run;
proc reg data = base_dep outest = parametri;
	weight pop_ult;
	model propensione = inverso ripart1 ripart2 ripart3 ripart4;
	output out = esitoregnew
		   p = yteorica;
run;
quit;
proc gplot data = esitoregnew;
	symbol1 i = none  v = dot c = black;
	plot yteorica * propensione = 1;
run;
quit;
proc corr data = esitoregnew;
	var yteorica propensione;
run;
proc univariate data = esitoregnew;
	var yteorica;
	histogram yteorica;
run;


data geog;
	set ter_out.geografica_comune;
	length territorio $ 40;
	if nome_regione = "TRENTINO-ALTO ADIGE"
		then territorio = nome_provincia;
		else territorio = nome_regione;
	array ripart{4};
	do i = 1 to 4;
		ripart{i} = (codice_ripartizione = i);
	end;
	keep codice_comune__str nome_comune sigla_provincia
		 territorio nome_regione codice_ripartizione ripart1 ripart2 ripart3 ripart4;
run;
proc sort data = geog;
	 by codice_comune__str;
run;
data red;
	set ter_out.economica_comune;
	keep codice_comune__str reddito;
	rename reddito = red_ult;
run;
proc sort data = red;
	 by codice_comune__str;
run;
proc sort data = xcod;
	 by codice_comune__str;
run;
data base_com;
	merge geog xcod (keep = codice_comune__str codice_provincia) popnew red;
	by codice_comune__str;
	red_pop_ult = red_ult/pop_ult;
	inverso = 1/red_pop_ult;
run;


proc score data = base_com
		   score = parametri
		   type = parms
		   out = espay;
		   var inverso ripart1 ripart2 ripart3 ripart4;
run;
proc univariate data = espay nextrobs = 20;
	var model1;
	histogram model1;
	id nome_comune sigla_provincia red_pop_ult;
run;


proc freq data = geog;
	tables territorio*nome_regione /list;
run;
proc sort data = geog;
	by codice_comune__str;
run;
data eco;
	set ter.econom20b;
	keep codc620b red19 con19;
	rename codc620b = codice_comune__str
		   red19 = red_pre
		   con19 = con_pre;
run;
proc sort data = eco;
	by codice_comune__str;
run;
data eco_g;
	merge geog eco red popnew;
	by codice_comune__str;
run;
proc means data = eco_g noprint;
	class territorio;
	types territorio;
	output out = regionale_precedente (drop = _type_ _freq_)
		   sum(red_pre con_pre red_ult pop_ult) = 
			   reddito_stima_preced consumi_stima_preced reddito_stima_ult pop_ult;
run;


PROC IMPORT OUT= WORK.consumi_istat 
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\quadratura_consumi.csv" 
            DBMS=CSV REPLACE;
     GETNAMES=YES;
     DATAROW=2; 
RUN;
data consumi_istat;
	attrib territorio length=$40 format=$40. informat=$40.;
	set consumi_istat;
	territorio = upcase(territorio);
	if territorio = "PROVINCIA AUTONOMA BOLZANO / BOZEN"
		then territorio = "BOLZANO";
	if territorio = "PROVINCIA AUTONOMA TRENTO"
		then territorio = "TRENTO";
	if territorio = "VALLE D'AOSTA / VALLéE D'AOSTE"
		then territorio = "VALLE D'AOSTA";
	consumi_2019 = round(consumi_2019*1000);
	consumi_2020 = round(consumi_2020*1000);
	rename consumi_2019 = consumi_istat_preced
		   consumi_2020 = consumi_istat_ultimo;
run;
proc sort data = consumi_istat;
	by territorio;
run;
data confronto;
	merge regionale_precedente (in = sele) consumi_istat;
	by territorio;
	if sele;
	red_pop_ult = reddito_stima_ult/pop_ult;
	difperc = 100*(consumi_stima_preced - consumi_istat_preced)/consumi_istat_preced;
	mediaistat = consumi_istat_ultimo/reddito_stima_ult;
	drop _ itter107;
run;
proc sort data = confronto;
	by difperc;
run;
proc print data = confronto;
	format reddito_stima_preced consumi_stima_preced reddito_stima_ult pop_ult
		   consumi_istat_preced consumi_istat_ultimo comma18.;
	sum reddito_stima_preced consumi_stima_preced reddito_stima_ult consumi_istat_preced consumi_istat_ultimo;
run;
proc gplot data = confronto;
	symbol1 i = none  v = dot c = black;
	plot mediaistat * red_pop_ult = 1;
run;
quit;


proc sort data = espay;
	by territorio;
run; 
proc means data = espay noprint;
	weight red_ult;
	class territorio;
	types territorio;
	output out = mediat (drop = _type_ _freq_)
		   mean(model1) = mediat;
run;
data mediaistat;
	set confronto;
	keep territorio mediaistat;
run;
proc sort data = mediaistat;
	by territorio;
run;
data medie;
	merge mediat mediaistat;
	by territorio;
	correttivo = mediaistat/mediat;
run;
data baseprop;
	merge espay medie;
	by territorio;
run;
data baseprop;
	set baseprop;
	propensione = model1*correttivo;
run;
proc univariate data = baseprop;
	var propensione;
	histogram propensione;
run;


proc univariate data = baseprop noprint;
	var propensione;
	output out = estremi_p
		   pctlpre = prop
		   pctlname = p95 pctlpts = 95
		   pctlname = p5 pctlpts = 5;
run;
data norma;
	if _N_ = 1 then set estremi_p;
	set baseprop;
run;
data norma;
	set norma;
	pronorma = propensione;
	if propensione < propp5
		then pronorma = sum(.1*propensione,.9*propp5);
	if propensione > propp95
		then pronorma = sum(.1*propensione,.9*propp95);
	drop propp5 propp95;
run;
proc gplot data = norma;
	symbol1 i = none  v = dot c = black;
	plot pronorma * propensione = 1;
run;
quit;
proc univariate data = norma nextrobs = 20;
	var pronorma;
	histogram pronorma;
	id nome_comune sigla_provincia;
run;


proc sort data = norma;
	by territorio;
run; 
proc means data = norma noprint;
	weight red_ult;
	class territorio;
	types territorio;
	output out = mediat (drop = _type_ _freq_)
		   mean(pronorma) = mediat;
run;
data norma;
	merge norma (drop = mediat propensione) mediat;
	by territorio;
run;
data norma;
	set norma;
	propensione = pronorma*mediaistat/mediat;
	drop correttivo;
run;
proc univariate data = norma;
	var propensione;
	histogram propensione;
run;
proc means data = norma noprint;
	weight red_ult;
	class territorio;
	types territorio;
	output out = verifica (drop = _type_ _freq_)
		   mean(propensione) = mediastima;
run;
data verifica;
	merge verifica mediaistat;
	by territorio;
	d = mediastima - mediaistat;
run;
proc print data = verifica;
run;


data stima1;
	set norma;
	stima_grezza = red_ult*propensione;
run;
proc tabulate data = stima1;
	var red_ult stima_grezza;
	table red_ult stima_grezza,sum*f=comma18.;
run;


data quadra;
	set confronto;
	keep territorio consumi_istat_ultimo;
run;
%quadraturagruppo(stima1,		
				  stima_grezza,	
				  quadra,		
				  consumi_istat_ultimo,	
				  stima_qua,	
				  territorio,	
				  qua1);		
data qua2;
	set qua1;
	stima_qua = round(stima_qua);
run;
%arrotondainterogruppo(qua2,		
					   stima_qua,	
					   quadra,		
					   consumi_istat_ultimo,	
					   territorio,	
					   qua3);		
proc tabulate data = qua3;
	class territorio;
	var stima_qua;
	table territorio all, stima_qua*sum*f = comma18.3;
run;


data pop_pre;
	set ter.demo20b;
	keep codc620b pop19;
	rename codc620b = codice_comune__str
		   pop19 = pop_pre;
run;
proc sort data = pop_pre;
	by codice_comune__str;
run;
proc sort data = qua3;
	by codice_comune__str;
run;
data base_controllo;
	merge qua3 eco pop_pre;
	by codice_comune__str;
	prop_pre = con_pre/red_pre;
	prop_ult = stima_qua/red_ult;
	prop_dif = prop_ult - prop_pre;
	con_pop_pre = con_pre/pop_pre;
	con_pop_ult = stima_qua/pop_ult;
	red_pop_pre = red_pre/pop_pre;
	convar = 100*(con_pop_ult - con_pop_pre)/con_pop_pre;
	redvar = 100*(red_pop_ult - red_pop_pre)/red_pop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var prop_ult;
	id nome_comune sigla_provincia prop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var prop_pre;
	id nome_comune sigla_provincia prop_ult;
run;
proc univariate data = base_controllo nextrobs = 20;
	var prop_dif;
	id nome_comune sigla_provincia prop_ult prop_pre;
	histogram prop_dif;
run;
proc univariate data = base_controllo nextrobs = 20;
	var con_pop_ult;
	id nome_comune sigla_provincia con_pop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var con_pop_pre;
	id nome_comune sigla_provincia con_pop_ult;
run;
proc freq data = base_controllo;
	where prop_ult > 1;
	tables territorio;
run;
proc corr data = base_controllo;
	var con_pop_ult red_pop_ult;
run;
proc sort data = base_controllo;
	by territorio;
run;
proc univariate data = base_controllo nextrobs = 20;
	by territorio;
	var convar;
	id nome_comune sigla_provincia redvar con_pop_ult red_pop_ult;
run;
proc univariate data = base_controllo nextrobs = 20;
	var convar;
	id nome_comune sigla_provincia redvar con_pop_ult red_pop_ult;
	histogram convar;
run;
proc univariate data = base_controllo;
	var redvar;
run;
data grande;
	set base_controllo;
	if pop_ult >= 100000;
run;
proc sort data = grande;
	by descending convar;
run;
proc print data = grande;
	var nome_comune sigla_provincia convar redvar
		con_pop_ult red_pop_ult con_pop_pre red_pop_pre;
	format convar redvar con_pop_ult red_pop_ult con_pop_pre red_pop_pre 12.1;
run;
data noncoerente;
	set base_controllo;
	if convar*redvar < 0 and min(abs(convar),abs(redvar)) > 1;
run; *1560; 

proc univariate data = base_controllo noprint;
	var convar;
	output out = estremi_v
		   pctlpre = varia
		   pctlname = p95 pctlpts = 95
		   pctlname = p5 pctlpts = 5;
run;
data base_n;
	if _N_ = 1 then set estremi_v;
	set base_controllo;
run;
data base_n;
	set base_n;
	varnorma = convar;
	if convar < variap5
		then varnorma = sum(.3*convar,.7*variap5);
	if convar > variap95
		then varnorma = sum(.3*convar,.7*variap95);
	drop variap5 variap95 ripart1 ripart2 ripart3 ripart4
		 inverso model1 stima_qua con_pop_ult prop_ult prop_dif;
run;
proc gplot data = base_n;
	symbol1 i = none  v = dot c = black;
	plot varnorma * convar = 1;
run;
quit;
proc univariate data = base_n;
	var varnorma;
	histogram varnorma;
run;


data ristima;
	set base_n;
	stima_n = pop_ult*con_pop_pre*(1 + varnorma/100);
run;
proc tabulate data = ristima;
	var red_ult stima_n red_pre con_pre;
	table red_ult stima_n red_pre con_pre,sum*f=comma18.;
run;


%quadraturagruppo(ristima,		
				  stima_n,		
				  quadra,		
				  consumi_istat_ultimo,	
				  stima_nq,		
				  territorio,	
				  quan1);		
data quan2;
	set quan1;
	stima_nq = round(stima_nq);
run;
%arrotondainterogruppo(quan2,		
					   stima_nq,	
					   quadra,		
					   consumi_istat_ultimo,	
					   territorio,		
					   quan3);		
proc tabulate data = quan3;
	var red_ult stima_nq red_pre con_pre;
	table red_ult stima_nq red_pre con_pre,sum*f=comma18.;
run;


proc means data = quan3 noprint;
	class territorio;
	types territorio;
	output out = verqua
		   sum(stima_nq) = ;
run;
proc sort data = quadra;
	by territorio;
run;
data verqua;
	merge verqua quadra;
	by territorio;
	controllo = (consumi_istat_ultimo ~= stima_nq);
run;
proc means data = verqua sum;
	var controllo;
run;


data base_controllo;
	set quan3;
	prop_ult = stima_nq/red_ult;
	con_pop_ult = stima_nq/pop_ult;
	convar = 100*(con_pop_ult - con_pop_pre)/con_pop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var prop_ult;
	id nome_comune sigla_provincia prop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var prop_pre;
	id nome_comune sigla_provincia prop_ult;
run;
proc univariate data = base_controllo nextrobs = 20;
	var con_pop_ult;
	id nome_comune sigla_provincia con_pop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var con_pop_pre;
	id nome_comune sigla_provincia con_pop_ult;
run;
proc freq data = base_controllo;
	where prop_ult > 1;
	tables territorio;
run;
proc corr data = base_controllo;
	var con_pop_ult red_pop_ult;
run;
proc univariate data = base_controllo nextrobs = 20;
	var convar;
	id  nome_comune sigla_provincia redvar con_pop_ult red_pop_ult;
	histogram convar;
run;
data grande;
	set base_controllo;
	if pop_ult >= 100000;
run;
proc sort data = grande;
	by descending convar;
run;
proc print data = grande;
	var nome_comune sigla_provincia convar redvar
		con_pop_ult red_pop_ult con_pop_pre red_pop_pre;
	format convar redvar con_pop_ult red_pop_ult con_pop_pre red_pop_pre 12.1;
run;
proc gplot data = base_controllo;
	symbol1 i = none  v = dot c = black;
	plot con_pop_ult * red_pop_ult = 1;
run;
quit;
data noncoerente;
	set base_controllo;
	if convar*redvar < 0 and min(abs(convar),abs(redvar)) > 1;
run; *1653; 

data attuale;
	set ter_out.economica_comune;
	drop consumi_totali;
run;
proc sort data = attuale;
	by codice_comune__str;
run;
proc sort data = base_controllo;
	by codice_comune__str;
run;
data nuova;
	merge attuale base_controllo (keep = codice_comune__str stima_nq);
	by codice_comune__str;
	rename stima_nq = consumi_totali;
run;
%let tracciato = 
codice_comune__str
reddito
consumi_totali
anno_riferimento
release;
data ordinata;
	retain &tracciato;
	set nuova;
run;


### Response:
The code you provided is written in SAS language. To translate it into Python, we need to rewrite the code using the Python programming language. Please note that the translation may not be perfect due to differences in syntax and functionality between SAS and Python.

Here is the translated code:

```python
import os
import pandas as pd

# Set the paths
ter_path = "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets"
sez_path = "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets"
ter_out_path = "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets"
sez_out_path = "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets"
appo_path = "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets"

# Set the options
pd.options.mode.chained_assignment = None

# Include the macro files
macro_path = "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets\\Macro"
os.system(f"sas -sysin '{macro_path}\\macroquadraturagruppo.sas' -sysparm '{macro_path}\\macroquadraturagruppo.sas'")
os.system(f"sas -sysin '{macro_path}\\macroarrotondainterogruppo.sas' -sysparm '{macro_path}\\macroarrotondainterogruppo.sas'")

# Import the data files
xconsumi_tag_path = "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets\\tag_00026.xlsx"
xreddito_tag_path = "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets\\tag_00027.xlsx"
provincia_path = "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets\\provincia_110.xlsx"
corrispo_path = "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets\\Codici-statistici-e-denominazioni-al-31_12_2020.xls"

# Read the data files
xconsumi_tag = pd.read_excel(xconsumi_tag_path, sheet_name="TAG-00026_4", usecols="A3:G132", skiprows=3)
xreddito_tag = pd.read_excel(xreddito_tag_path, sheet_name="TAG-00027_2", usecols="A3:G132", skiprows=3)
provincia = pd.read_excel(provincia_path, sheet_name="Sheet1")
corrispo = pd.read_excel(corrispo_path, sheet_name="CODICI al 31_12_2020")

# Perform data manipulation
consumi_tag = xconsumi_tag.copy()
consumi_tag['province_e_regioni'] = consumi_tag['province_e_regioni'].str.upper()
consumi_tag = consumi_tag.loc[consumi_tag['province_e_regioni'].ne(consumi_tag['province_e_regioni'].str.upper()) | consumi_tag['province_e_regioni'].eq("VALLE D'AOSTA/VALLÃ¨ D'AOSTE")]
consumi_tag['consumi'] = consumi_tag['_017'] / 1000
consumi_tag = consumi_tag.drop(columns=['_017'])
consumi_tag = consumi_tag.sort_values(by='province_e_regioni')

reddito_tag = xreddito_tag.copy()
reddito_tag['province_e_regioni'] = reddito_tag['province_e_regioni'].str.upper()
reddito_tag = reddito_tag.loc[reddito_tag['province_e_regioni'].ne(reddito_tag['province_e_regioni'].str.upper()) | reddito_tag['province_e_regioni'].eq("VALLE D'AOSTA/VALLÃ¨ D'AOSTE")]
reddito_tag['reddito'] = reddito_tag['_017'] / 1000
reddito_tag = reddito_tag.drop(columns=['_017'])
reddito_tag = reddito_tag.sort_values(by='province_e_regioni')

base_tag = pd.merge(reddito_tag, consumi_tag, on='province_e_regioni')
base_tag['propensione'] = base_tag['consumi'] / base_tag['reddito']
base_tag['inverso'] = 1 / base_tag['reddito']

# Perform statistical analysis
base_tag.describe()
base_tag.hist(column='propensione')

# Plot the data
import matplotlib.pyplot as plt

plt.scatter(base_tag['propensione'], base_tag['reddito'])
plt.xlabel('Propensione')
plt.ylabel('Reddito')
plt.title('Propensione vs Reddito')
plt.show()

plt.scatter(base_tag['propensione'], base_tag['inverso'])
plt.xlabel('Propensione')
plt.ylabel('Inverso')
plt.title('Propensione vs Inverso')
plt.show()

# Correlation analysis
correlation = base_tag.corr()
print(correlation)

# Regression analysis
import statsmodels.api as sm

X = sm.add_constant(base_tag['reddito'])
Y = base_tag['propensione']
model = sm.OLS(Y, X)
results = model.fit()
print(results.summary())

X = sm.add_constant(base_tag['inverso'])
Y = base_tag['propensione']
model = sm.OLS(Y, X)
results = model.fit()
print(results.summary())

# Merge provincia and corrispo datasets
provincia['Denominazione_Provincia_CittÃ¬_me'] = provincia['Denominazione_Provincia_CittÃ¬_me'].str.upper()
provincia.loc[provincia['Denominazione_Provincia_CittÃ¬_me'].eq("REGGIO DI CALABRIA"), 'Denominazione_Provincia_CittÃ¬_me'] = "REGGIO CALABRIA"

base_tag = base_tag.merge(provincia, how='left', left_on='province_e_regioni', right_on='Denominazione_Provincia_CittÃ¬_me')

# Merge corrispo dataset
corrispo['codice_provincia'] = corrispo['Codice_Comune_numerico_con_110_p'].astype(str).str[:3]
corrispo = corrispo.loc[corrispo['codice_comune__str'].notna()]

base_tag = base_tag.merge(corrispo, how='left', left_on='province_e_regioni', right_on='codice_provincia')

# Perform statistical analysis
base_tag.describe()

# Correlation analysis
correlation = base_tag.corr()
print(correlation)

# Regression analysis
X = sm.add_constant(base_tag['inverso'])
Y = base_tag['propensione']
model = sm.OLS(Y, X)
results = model.fit()
print(results.summary())

# Create geog dataset
geog = ter_out.geografica_comune.copy()
geog['territorio'] = geog['nome_regione'].where(geog['nome_regione'] != "TRENTINO-ALTO ADIGE", geog['nome_provincia'])
geog['territorio'] = geog['territorio'].str.upper()
geog['codice_provincia'] = geog['codice_provincia'].astype(str)

# Merge geog dataset with corrispo dataset
geog = geog.merge(corrispo, how='left', left_on='codice_comune__str', right_on='codice_provincia')

# Perform statistical analysis
regionale_precedente = geog.groupby('territorio').agg({'red_pre': 'sum', 'con_pre': 'sum', 'red_ult': 'sum', 'pop_ult': 'sum'})
regionale_precedente.columns = ['reddito_stima_preced', 'consumi_stima_preced', 'reddito_stima_ult', 'pop_ult']

# Merge regionale_precedente dataset with confronto dataset
confronto = pd.merge(regionale_precedente, confronto, on='territorio')

# Calculate the mean and standard deviation of the consumi_istat dataset
consumi_istat_mean = consumi_istat['consumi_2020'].mean()
consumi_istat_std = consumi_istat['consumi_2020'].std()

# Calculate the mean and standard deviation of the confronto dataset
confronto_mean = confronto['consumi_stima_preced'].mean()
confronto_std = confronto['consumi_stima_preced'].std()

# Calculate the z-score
z_score = (confronto_mean - consumi_istat_mean) / consumi_istat_std

# Calculate the confidence interval
confidence_interval = 1.96 * (confronto_std / np.sqrt(len(confronto)))

# Print the results
print(f"Z-score: {z_score}")
print(f"Confidence Interval: {confidence_interval}")

# Perform statistical analysis
confronto.describe()

# Create eco dataset
eco = ter.econom20b.copy()
eco['red_pre'] = eco['red19']
eco['con_pre'] = eco['con19']

# Merge geog dataset with eco dataset
eco_g = pd.merge(geog, eco, on='codice_comune__str')

# Perform statistical analysis
regionale_precedente = eco_g.groupby('territorio').agg({'red_pre': 'sum', 'con_pre': 'sum', 'red_ult': 'sum', 'pop_ult': 'sum'})
regionale_precedente.columns = ['reddito_stima_preced', 'consumi_stima_preced', 'reddito_stima_ult', 'pop_ult']

# Merge regionale_precedente dataset with confronto dataset
confronto = pd.merge(regionale_precedente, confronto, on='territorio')

# Calculate the mean and standard deviation of the consumi_istat dataset
consumi_istat_mean = consumi_istat['consumi_2020'].mean()
consumi_istat_std = consumi_istat['consumi_2020'].std()

# Calculate the mean and standard deviation of the confronto dataset
confronto_mean = confronto['consumi_stima_preced'].mean()
confronto_std = confronto['consumi_stima_preced'].std()

# Calculate the z-score
z_score = (confronto_mean - consumi_istat_mean) / consumi_istat_std

# Calculate the confidence interval
confidence_interval = 1.96 * (confronto_std / np.sqrt(len(confronto)))

# Print the results
print(f"Z-score: {z_score}")
print(f"Confidence Interval: {confidence_interval}")

# Perform statistical analysis
confronto.describe()

# Create stima1 dataset
stima1 = norma.copy()
stima1['stima_grezza'] = stima1['red_ult'] * stima1['propensione']

# Perform statistical analysis
stima1.describe()

# Create quadra dataset
quadra = confronto.copy()
quadra = quadra[['territorio', 'consumi_istat_ultimo']]

# Perform statistical analysis
quadra.describe()

# Perform quadraturagruppo analysis
def quadraturagruppo(stima1, stima, quadra, consumi_istat_ultimo, territorio):
    # Perform quadraturagruppo analysis
    # ...

# Perform arrotondainterogruppo analysis
def arrotondainterogruppo(qua2, stima_qua, quadra, consumi_istat_ultimo, territorio):
    # Perform arrotondainterogruppo analysis
    # ...

# Perform quadraturagruppo analysis
quadraturagruppo(stima1, stima_qua, quadra, consumi_istat_ultimo, territorio)

# Perform arrotondainterogruppo analysis
arrotondainterogruppo(qua2, stima_qua, quadra, consumi_istat_ultimo, territorio)

# Perform statistical analysis
verifica.describe()

# Create base_controllo dataset
base_controllo = pd.merge(norma, mediaistat, on='territorio')
base_controllo['prop_pre'] = base_controllo['con_pop_pre'] / base_controllo['red_pre']
base_controllo['prop_ult'] = base_controllo['stima_qua'] / base_controllo['red_ult']
base_controllo['prop_dif'] = base_controllo['prop_ult'] - base_controllo['prop_pre']
base_controllo['con_pop_pre'] = base_controllo['con_pop_pre'] / base_controllo['pop_pre']
base_controllo['con_pop_ult'] = base_controllo['stima_qua'] / base_controllo['pop_ult']
base_controllo['red_pop_pre'] = base_controllo['red_pre'] / base_controllo['pop_pre']
base_controllo['convar'] = 100 * (base_controllo['con_pop_ult'] - base_controllo['con_pop_pre']) / base_controllo['con_pop_pre']
base_controllo['redvar'] = 100 * (base_controllo['red_pop_ult'] - base_controllo['red_pop_pre']) / base_controllo['red_pop_pre']

# Perform statistical analysis
base_controllo.describe()

# Create grande dataset
grande = base_controllo.loc[base_controllo['pop_ult'] >= 100000]

# Perform statistical analysis
grande.describe()

# Create noncoerente dataset
noncoerente = base_controllo.loc[base_controllo['convar'] * base_controllo['redvar'] < 0]
noncoerente = noncoerente.loc[abs(noncoherente['convar']) > abs(noncoherente['redvar'])]

# Perform statistical analysis
noncoherente.describe()

# Create ristima dataset
ristima = base_controllo.copy()
ristima['stima_n'] = ristima['pop_ult'] * ristima['con_pop_pre'] * (1 + ristima['varnorma'] / 100)

# Perform statistical analysis
ristima.describe()

# Perform quadraturagruppo analysis
quadraturagruppo(ristima, stima_n, quadra, consumi_istat_ultimo, territorio)

# Perform arrotondainterogruppo analysis
arrotondainterogruppo(quan2, stima_nq, quadra, consumi_istat_ultimo, territorio)

# Perform statistical analysis
verqua.describe()

# Create base_controllo dataset
base_controllo = ristima.copy()
base_controllo['prop_ult'] = base_controllo['stima_n'] / base_controllo['red_ult']
base_controllo['con_pop_ult'] = base_controllo['stima_n'] / base_controllo['pop_ult']
base_controllo['convar'] = 100 * (base_controllo['con_pop_ult'] - base_controllo['con_pop_pre']) / base_controllo['con_pop_pre']

# Perform statistical analysis
base_controllo.describe()

# Create grande dataset
grande = base_controllo.loc[base_controllo['pop_ult'] >= 100000]

# Perform statistical analysis
grande.describe()

# Create noncoherente dataset
noncoherente = base_controllo.loc[base_controllo['convar'] * base_controllo['redvar'] < 0]
noncoherente = noncoherente.loc[abs(noncoherente['convar']) > abs(noncoherente['redvar'])]

# Perform statistical analysis
noncoherente.describe()

# Perform statistical analysis
base_controllo.describe()

# Create attuale dataset
attuale = ter_out.economica_comune.copy()
attuale.drop(columns=['consumi_totali'])

# Merge attuale dataset with base_controllo dataset
nuova = pd.merge(attuale, base_controllo, on='codice_comune__str', suffixes=('_old', '_new'))

# Create ordinata dataset
ordinata = nuova.copy()
ordinata.columns = [f"{col}_old" if col.endswith("_old") else col for col in nuova.columns]

# Perform statistical analysis
ordinata.describe()
```

Please note that some parts of the code may need to be adjusted based on the specific requirements of your project. The translation was done based on the information provided, and some parts of the code may not be perfect due to differences in syntax and functionality between SAS and Python.