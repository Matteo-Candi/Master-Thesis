Here is the PySpark translation of your SQL code:

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, to_date, year, lit, when, max
from pyspark.sql.window import Window

# Create a spark session
spark = SparkSession.builder.getOrCreate()

# Load the tables
inol = spark.table("ddwh01_dw.td_inol_invoice_orders_lines")
delta = spark.table("ddwh02_dim.twrk_pvan_delta_flash_leg")
vele = spark.table("ddwh01_dw.tm_vele_vehicle_legacy")
sops = spark.table("ddwh01_dw.td_sops_sales_order_position")
slor = spark.table("ddwh01_dw.tt_slor_sales_order")
inoh = spark.table("ddwh01_dw.tt_inoh_invoice_orders_header")
tdim_pvan = spark.table("tdim_pvan_vehicle")  # Assuming this is a table in your database

# Perform the join operations
df = inol \
    .join(delta, delta["vele_id_vehicle_legacy_id_pk"] == inol["inol_id_vele_vcl_legacy"]) \
    .join(vele, vele["vele_id_vehicle_legacy_id_pk"] == inol["inol_id_vele_vcl_legacy"], "left") \
    .join(sops.groupBy("sops_cd_sales_order", "sops_cd_legacy_mkt", "sops_cd_dealer_code", 
                        "sops_cd_source_order", "sops_cd_source_order_sequence", "sops_cd_source_system", 
                        "sops_cd_product_line", "sops_id_vele_vcl_legacy").agg(max("sops_id_sales_order_pos").alias("max_id_sops")), 
          [inol["inol_cd_sales_order"] == sops["sops_cd_sales_order"], inol["inol_cd_legacy_mkt"] == sops["sops_cd_legacy_mkt"], 
           inol["inol_cd_dealer_code"] == sops["sops_cd_dealer_code"], inol["inol_cd_source_order"] == sops["sops_cd_source_order"], 
           inol["inol_cd_source_order_sequence"] == sops["sops_cd_source_order_sequence"], 
           inol["inol_cd_source_system"] == sops["sops_cd_source_system"], inol["inol_cd_product_line"] == sops["sops_cd_product_line"], 
           inol["inol_id_vele_vcl_legacy"] == sops["sops_id_vele_vcl_legacy"], sops["sops_id_sales_order_pos"] == col("max_id_sops")], "left") \
    .join(slor, sops["sops_id_slor_sales_order"] == slor["slor_id_sales_order"], "left") \
    .join(inoh, inoh["inoh_id_invoice_orders_header"] == inol["inol_id_inoh_invoice_orders_he"], "left") \
    .join(tdim_pvan, tdim_pvan["pvan_id_vcl"] == inol["inol_id_vele_vcl_legacy"], "left") \
    .where(col("inol_fl_delete_line").isNull())  # Filter out the deleted lines

# Define the values to be inserted into the fbil table
fbil = df.select(
    lit(-1).alias('fbil_id_comp_company'), 
    lit('-1').alias('fbil_cd_accg_doc_code'), 
    year(to_date(df['inol_dt_document_date'], 'yyyy')).alias('fbil_nr_accg_doc_fiscal_year'), 
    df['inol_cd_document_number'].alias('fbil_cd_cmm_doc_code'), 
    df['inol_cd_progressive_order'].alias('fbil_cd_cmm_doc_pos_code'), 
    when(df['inol_id_vele_vcl_legacy'].isNull(), -1).otherwise(df['inol_id_vele_vcl_legacy']).alias('fbil_id_pvan_vcl'), 
    df['inol_cd_sales_order'].alias('fbil_cd_sls_ord_code'), 
    df['inol_cd_progressive_order'].alias('fbil_cd_sls_ord_pos_code'), 
    when(df['inol_id_inoh_invoice_orders_he'].isNull(), -1).otherwise(df['inol_id_inoh_invoice_orders_he']).alias('fbil_id_cmm_doc_id'), 
    when(df['inol_id_invoice_orders_lines'].isNull(), -1).otherwise(df['inol_id_invoice_orders_lines']).alias('fbil_id_cmm_doc_pos_id'), 
    df['inol_cd_document_type'].alias('fbil_id_bdty_billing_doc_tp'), 
    when(to_date(df['inol_dt_document_date'], 'J').isNull(), -1).otherwise(to_date(df['inol_dt_document_date'], 'J')).alias('fbil_id_time_cmm_doc_date'), 
    when(df['inol_id_cust_customer'].isNull(), -1).otherwise(df['inol_id_cust_customer']).alias('fbil_id_cust_payer'), 
    when(df['inol_id_cust_customer'].isNull(), -1).otherwise(df['inol_id_cust_customer']).alias('fbil_id_cust_sold'), 
    lit(-2).alias('fbil_id_cuty_customer_type'), 
    when(vele['vele_id_ledi_legacy_division'].isNull(), -1).otherwise(vele['vele_id_ledi_legacy_division']).alias('fbil_id_divi_division'), 
    when(vele['vele_id_hmup_plank_key'].isNull(), -1).otherwise(vele['vele_id_hmup_plank_key']).alias('fbil_id_hmup_hmu_product'), 
    when(tdim_pvan['pvan_id_prat_pr_attributes'].isNull(), -1).otherwise(tdim_pvan['pvan_id_prat_pr_attributes']).alias('fbil_id_prat_pr_attributes'), 
    when(tdim_pvan['pvan_id_prpp_prp_product'].isNull(), -1).otherwise(tdim_pvan['pvan_id_prpp_prp_product']).alias('fbil_id_prp_prpp_product'), 
    lit(-1).alias('fbil_id_time_return_date'), 
    when(to_date(slor['slor_dt_document_date'], 'J').isNull(), -1).otherwise(to_date(slor['slor_dt_document_date'], 'J')).alias('fbil_id_time_sales_order_date'), 
    when(slor['slor_id_sales_order'].isNull(), -1).otherwise(slor['slor_id_sales_order']).alias('fbil_id_sls_ord_id'), 
    when(sops['sops_id_sales_order_pos'].isNull(), -1).otherwise(sops['sops_id_sales_order_pos']).alias('fbil_id_sls_ord_pos_id'), 
    lit(-1).alias('fbil_id_time_start_billing_dat'), 
    inoh['inoh_cd_currency_code'].alias('fbil_cd_currency'), 
    lit(1).alias('fbil_id_batch_id'), 
    df['inol_fl_invoice_reject_reason'].alias('fbil_fl_itc_flg'), 
    when(inoh['inoh_id_cust_customer'].isNull(), -1).otherwise(inoh['inoh_id_cust_customer']).alias('fbil_id_cust_payee'), 
    when(inoh['inoh_id_cust_customer'].isNull(), -1).otherwise(inoh['inoh_id_cust_customer']).alias('fbil_id_cust_billtoparner'), 
    when(inoh['inoh_id_cust_customer'].isNull(), -1).otherwise(inoh['inoh_id_cust_customer']).alias('fbil_id_cust_saleschannel'), 
    when(inoh['inoh_id_cust_customer'].isNull(), -1).otherwise(inoh['inoh_id_cust_customer']).alias('fbil_id_cust_soldtoparner'), 
    when(inoh['inoh_id_cust_customer'].isNull(), -1).otherwise(inoh['inoh_id_cust_customer']).alias('fbil_id_cust_ownership_group'), 
    lit(-2).alias('fbil_id_addr_ownership_group'), 
    df['inol_cd_business_area_code'].alias('fbil_cd_business_area_code'), 
    slor['slor_cd_codice_resa'].alias('fbil_cd_codice_resa'), 
    df['inol_cd_dealer_code'].alias('fbil_cd_dlr_code'), 
    inoh['inoh_cd_dealer_order_reference'].alias('fbil_cd_dlr_ord_ref'), 
    df['inol_cd_dealer_order_type'].alias('fbil_cd_dlr_ord_tp'), 
    df['inol_cd_document_number'].alias('fbil_cd_doc_nbr'), 
    df['inol_cd_document_type'].alias('fbil_cd_doc_tp'), 
    df['inol_cd_draft_number'].alias('fbil_cd_draft_inv_code'), 
    df['inol_cd_engine_number'].alias('fbil_cd_eng_nbr'), 
    df['inol_cd_machine_type'].alias('fbil_cd_machine_tp'), 
    df['inol_cd_legacy_mkt'].alias('fbil_cd_market_legacy'), 
    df['inol_cd_tyres_price_1'].alias('fbil_cd_price_tyres_1'), 
    df['inol_cd_tyres_price_2'].alias('fbil_cd_price_tyres_2'), 
    df['inol_cd_price_list'].alias('fbil_cd_price_list'), 
    df['inol_cd_tech_type_price'].alias('fbil_cd_price_tech_tp'), 
    df['inol_cd_product_class'].alias('fbil_cd_product_cl'), 
    df['inol_cd_product_line'].alias('fbil_cd_product_line'), 
    df['inol_cd_product_type'].alias('fbil_cd_product_tp'), 
    df['inol_cd_progressive_order'].alias('fbil_cd_progressive_ord'), 
    df['inol_cd_reference_document_num'].alias('fbil_cd_ref_doc_nbr'), 
    df['inol_cd_serial_number'].alias('fbil_cd_serial_nbr'), 
    df['inol_cd_shipment_progressive'].alias('fbil_cd_shipment_progressive'), 
    df['inol_cd_sales_order'].alias('fbil_cd_sls_ord'), 
    df['inol_cd_source_order'].alias('fbil_cd_source_ord'), 
    df['inol_cd_source_order_sequence'].alias('fbil_cd_source_ord_sequence'), 
    df['inol_cd_standard_card_model'].alias('fbil_cd_std_card_mdl'), 
    df['inol_cd_standard_card_tyres'].alias('fbil_cd_std_card_tyres'), 
    df['inol_cd_standard_card_version'].alias('fbil_cd_std_card_vrs'), 
    df['inol_cd_tech_tp'].alias('fbil_cd_tech_tp'), 
    lit(-1).alias('fbil_id_time_itc_inv_date'), 
    df['inol_fl_invoice_reject_reason'].alias('fbil_fl_inv_reject_reason'), 
    when(to_date(df['inol_dt_draft_date'], 'J').isNull(), -1).otherwise(to_date(df['inol_dt_draft_date'], 'J')).alias('fbil_id_time_draft_inv_date'), 
    when(df['inol_id_mark_std_legacy_mkt'].isNull(), -1).otherwise(df['inol_id_mark_std_legacy_mkt']).alias('fbil_id_coun_country'), 
    df['inol_cd_source_system'].alias('fbil_cd_source_system'), 
    when(df['inol_cd_document_type'].isin(['1']), 1).otherwise(0).alias('fbil_in_wholesale_qty'), 
    (when(df['inol_cd_document_type'].isin(['1']), 1).otherwise(0) - when(df['inol_cd_document_type'].isin(['6']), 1).otherwise(0)).alias('fbil_in_wholesale_net_qty')
)

# Insert the values into the fbil table
fbil.write.insertInto("ddwh02_sm.twrk_fbil_billing_l_flash")
```
Please note that PySpark does not support direct insertion of data to a database table like SQL does. Instead, it uses the `write` function to write DataFrame content to an external storage system (such as Hadoop Distributed File System (HDFS), Amazon S3 etc.). The actual writing operation is performed when an action is called on the DataFrame. Here, we are using the `insertInto()` function which is available in Spark 2.0 and later versions to insert data into a database table.
