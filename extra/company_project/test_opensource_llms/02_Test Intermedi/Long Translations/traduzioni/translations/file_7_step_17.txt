system
You are an expert in translating code from SAS to Python; translate the given code at your best even if there are problems; insert comments inside the code; do not return any message outside the code and make it as readable as possible; minimize the code complexity and volume; create functions to automate frequently needed operations; ensure to not make any syntax error; define all variables and import all libraries used even if imported locally; ensure the user can copy and run the code without modifications; translate from SAS to Python every part of the input code reproducing the same operations; do not use SAS syntax in the Python code; define correctly the file paths; return the code in single block; make Python code more efficient than the SAS one.
user
libname ter "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";
libname sez "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";

libname ter_out "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";
libname sez_out "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";

libname appo "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";

options mergenoby = warn;
options nolabel;

%include "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\Macro\macroquadraturagruppo.sas";
%include "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\Macro\macroarrotondainterogruppo.sas";

title1 "STIMA COMUNALE DEI CONSUMI";

ods graphics off;


PROC IMPORT OUT= WORK.xconsumi_tag
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\tag_00026.xlsx"
            DBMS=EXCEL2000 REPLACE;
			SHEET="TAG-00026_4";
     		RANGE="A3:G132";
     		GETNAMES=YES;
			*MIXED = YES;	
RUN;
PROC IMPORT OUT= WORK.xreddito_tag
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\tag_00027.xlsx"
            DBMS=EXCEL2000 REPLACE;
			SHEET="TAG-00027_2";
     		RANGE="A3:G132";
     		GETNAMES=YES;
			*MIXED = YES;	
RUN;
data consumi_tag;
	set xconsumi_tag;
	if province_e_regioni ~= upcase(province_e_regioni)
	or province_e_regioni = "VALLE D'AOSTA/VALL�E D'AOSTE";
	consumi = _017/1000;
	keep province_e_regioni consumi;
run;
proc sort data = consumi_tag;
	by province_e_regioni;
run;
data reddito_tag;
	set xreddito_tag;
	if province_e_regioni ~= upcase(province_e_regioni)
	or province_e_regioni = "VALLE D'AOSTA/VALL�E D'AOSTE";
	reddito = _017/1000;
	keep province_e_regioni reddito;
run;
proc sort data = reddito_tag;
	by province_e_regioni;
run;
data base_tag;
	merge reddito_tag consumi_tag;
	by province_e_regioni;
	propensione = consumi/reddito;
	inverso = (1/reddito);
run;


proc univariate data = base_tag;
	var propensione;
	histogram propensione;
run;
proc gplot data = base_tag;
	symbol1 i = none  v = dot c = black;
	plot propensione * reddito = 1;
run;
quit;
proc gplot data = base_tag;
	symbol1 i = none  v = dot c = black;
	plot propensione * inverso = 1;
run;
quit;
proc corr data = base_tag;
	var propensione reddito inverso;
run;
proc reg data = base_tag;
	model propensione = reddito;
run;
quit;
proc reg data = base_tag;
	model propensione = inverso;
run;
quit;


PROC IMPORT OUT= WORK.provincia
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\provincia_110.xlsx"
            DBMS=EXCEL2000 REPLACE;
			SHEET="Sheet1";
     		GETNAMES=YES;
RUN;
data provincia;
	set provincia;
	Denominazione_Provincia_Citt__me = upcase(Denominazione_Provincia_Citt__me);
	if Denominazione_Provincia_Citt__me = "REGGIO DI CALABRIA"
		then Denominazione_Provincia_Citt__me = "REGGIO CALABRIA";
run;
data base_tag;
	set base_tag;
	province_e_regioni = upcase(province_e_regioni);
run;
proc sort data = provincia;
	by Denominazione_Provincia_Citt__me;
run;
data base_tag;
	merge base_tag provincia (rename=(Denominazione_Provincia_Citt__me=province_e_regioni));
	by province_e_regioni;
run;


PROC IMPORT OUT= WORK.corrispo
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\Codici-statistici-e-denominazioni-al-31_12_2020.xls"
            DBMS=EXCEL2000 REPLACE;
			SHEET="CODICI al 31_12_2020";
     		GETNAMES=YES;
			*MIXED = YES;	
RUN;
data corrispo;
	set corrispo;
	length codice_provincia $ 3;
	codice_provincia = substr(put(Codice_Comune_numerico_con_110_p,z6.),1,3);
	keep Codice_Comune_formato_alfanumeri codice_provincia;
	rename Codice_Comune_formato_alfanumeri = codice_comune__str;
run;
proc sort data = corrispo;
	by codice_comune__str;
run;
data xcod;
	set ter_out.geografica_comune;
	keep codice_comune__str codice_area_nielsen codice_ripartizione;
run;
proc sort data = xcod;
	by codice_comune__str;
run;
proc means data = ter_out.Popolazione_eta_sesso_comune noprint;
	class codice_comune__str;
	types codice_comune__str;
	output out = popnew (drop = _type_ _freq_)
		   sum(popolazione) = pop_ult;
run;
data xcod;
	merge xcod corrispo popnew;
	by codice_comune__str;
run;
proc means data = xcod noprint;
	class codice_provincia;
	types codice_provincia;
	id codice_area_nielsen codice_ripartizione;
	output out = xcods (drop = _type_ _freq_)
		   sum(pop_ult) = ;
run;
proc sort data = base_tag;
	by codice_provincia;
run;
data base_tag;
	merge base_tag xcods;
	by codice_provincia;
run;


proc sort data = base_tag;
	by codice_ripartizione;
run;
proc corr data = base_tag;
	by codice_ripartizione;
	var propensione reddito inverso;
run;
proc gplot data = base_tag;
	by codice_ripartizione;
	symbol1 i = none  v = dot c = black;
	plot propensione * reddito = 1;
run;
quit;
proc gplot data = base_tag;
	by codice_ripartizione;
	symbol1 i = none  v = dot c = black;
	plot propensione * inverso = 1;
run;
quit;
data base_tag;
	set base_tag;
	array ripart{4};
	do i = 1 to 4;
		ripart{i} = (codice_ripartizione = i);
	end;
	drop i;
run;
proc reg data = base_tag;
	weight pop_ult;
	model propensione = reddito ripart1 ripart2 ripart3 ripart4;
run;
quit;
proc reg data = base_tag;
	weight pop_ult;
	model propensione = inverso ripart1 ripart2 ripart3 ripart4;
run;
quit;
proc reg data = base_tag;
	weight pop_ult;
	by codice_ripartizione;
	model propensione = inverso;
run;
quit;


proc reg data = base_tag;
	weight pop_ult;
	model propensione = inverso ripart1 ripart2 ripart3 ripart4;
	output out = esitoreg
		   p = yteorica
		   rstudent = rstud;
run;
quit;
data base_dep;
	set esitoreg;
	if abs(rstud) < 2;
	drop yteorica;
run;
proc reg data = base_dep outest = parametri;
	weight pop_ult;
	model propensione = inverso ripart1 ripart2 ripart3 ripart4;
	output out = esitoregnew
		   p = yteorica;
run;
quit;
proc gplot data = esitoregnew;
	symbol1 i = none  v = dot c = black;
	plot yteorica * propensione = 1;
run;
quit;
proc corr data = esitoregnew;
	var yteorica propensione;
run;
proc univariate data = esitoregnew;
	var yteorica;
	histogram yteorica;
run;


data geog;
	set ter_out.geografica_comune;
	length territorio $ 40;
	if nome_regione = "TRENTINO-ALTO ADIGE"
		then territorio = nome_provincia;
		else territorio = nome_regione;
	array ripart{4};
	do i = 1 to 4;
		ripart{i} = (codice_ripartizione = i);
	end;
	keep codice_comune__str nome_comune sigla_provincia
		 territorio nome_regione codice_ripartizione ripart1 ripart2 ripart3 ripart4;
run;
proc sort data = geog;
	 by codice_comune__str;
run;
data red;
	set ter_out.economica_comune;
	keep codice_comune__str reddito;
	rename reddito = red_ult;
run;
proc sort data = red;
	 by codice_comune__str;
run;
proc sort data = xcod;
	 by codice_comune__str;
run;
data base_com;
	merge geog xcod (keep = codice_comune__str codice_provincia) popnew red;
	by codice_comune__str;
	red_pop_ult = red_ult/pop_ult;
	inverso = 1/red_pop_ult;
run;


proc score data = base_com
		   score = parametri
		   type = parms
		   out = espay;
		   var inverso ripart1 ripart2 ripart3 ripart4;
run;
proc univariate data = espay nextrobs = 20;
	var model1;
	histogram model1;
	id nome_comune sigla_provincia red_pop_ult;
run;


proc freq data = geog;
	tables territorio*nome_regione /list;
run;
proc sort data = geog;
	by codice_comune__str;
run;
data eco;
	set ter.econom20b;
	keep codc620b red19 con19;
	rename codc620b = codice_comune__str
		   red19 = red_pre
		   con19 = con_pre;
run;
proc sort data = eco;
	by codice_comune__str;
run;
data eco_g;
	merge geog eco red popnew;
	by codice_comune__str;
run;
proc means data = eco_g noprint;
	class territorio;
	types territorio;
	output out = regionale_precedente (drop = _type_ _freq_)
		   sum(red_pre con_pre red_ult pop_ult) = 
			   reddito_stima_preced consumi_stima_preced reddito_stima_ult pop_ult;
run;


PROC IMPORT OUT= WORK.consumi_istat 
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\quadratura_consumi.csv" 
            DBMS=CSV REPLACE;
     GETNAMES=YES;
     DATAROW=2; 
RUN;
data consumi_istat;
	attrib territorio length=$40 format=$40. informat=$40.;
	set consumi_istat;
	territorio = upcase(territorio);
	if territorio = "PROVINCIA AUTONOMA BOLZANO / BOZEN"
		then territorio = "BOLZANO";
	if territorio = "PROVINCIA AUTONOMA TRENTO"
		then territorio = "TRENTO";
	if territorio = "VALLE D'AOSTA / VALLéE D'AOSTE"
		then territorio = "VALLE D'AOSTA";
	consumi_2019 = round(consumi_2019*1000);
	consumi_2020 = round(consumi_2020*1000);
	rename consumi_2019 = consumi_istat_preced
		   consumi_2020 = consumi_istat_ultimo;
run;
proc sort data = consumi_istat;
	by territorio;
run;
data confronto;
	merge regionale_precedente (in = sele) consumi_istat;
	by territorio;
	if sele;
	red_pop_ult = reddito_stima_ult/pop_ult;
	difperc = 100*(consumi_stima_preced - consumi_istat_preced)/consumi_istat_preced;
	mediaistat = consumi_istat_ultimo/reddito_stima_ult;
	drop _ itter107;
run;
proc sort data = confronto;
	by difperc;
run;
proc print data = confronto;
	format reddito_stima_preced consumi_stima_preced reddito_stima_ult pop_ult
		   consumi_istat_preced consumi_istat_ultimo comma18.;
	sum reddito_stima_preced consumi_stima_preced reddito_stima_ult consumi_istat_preced consumi_istat_ultimo;
run;
proc gplot data = confronto;
	symbol1 i = none  v = dot c = black;
	plot mediaistat * red_pop_ult = 1;
run;
quit;


proc sort data = espay;
	by territorio;
run; 
proc means data = espay noprint;
	weight red_ult;
	class territorio;
	types territorio;
	output out = mediat (drop = _type_ _freq_)
		   mean(model1) = mediat;
run;
data mediaistat;
	set confronto;
	keep territorio mediaistat;
run;
proc sort data = mediaistat;
	by territorio;
run;
data medie;
	merge mediat mediaistat;
	by territorio;
	correttivo = mediaistat/mediat;
run;
data baseprop;
	merge espay medie;
	by territorio;
run;
data baseprop;
	set baseprop;
	propensione = model1*correttivo;
run;
proc univariate data = baseprop;
	var propensione;
	histogram propensione;
run;


proc univariate data = baseprop noprint;
	var propensione;
	output out = estremi_p
		   pctlpre = prop
		   pctlname = p95 pctlpts = 95
		   pctlname = p5 pctlpts = 5;
run;
data norma;
	if _N_ = 1 then set estremi_p;
	set baseprop;
run;
data norma;
	set norma;
	pronorma = propensione;
	if propensione < propp5
		then pronorma = sum(.1*propensione,.9*propp5);
	if propensione > propp95
		then pronorma = sum(.1*propensione,.9*propp95);
	drop propp5 propp95;
run;
proc gplot data = norma;
	symbol1 i = none  v = dot c = black;
	plot pronorma * propensione = 1;
run;
quit;
proc univariate data = norma nextrobs = 20;
	var pronorma;
	histogram pronorma;
	id nome_comune sigla_provincia;
run;


proc sort data = norma;
	by territorio;
run; 
proc means data = norma noprint;
	weight red_ult;
	class territorio;
	types territorio;
	output out = mediat (drop = _type_ _freq_)
		   mean(pronorma) = mediat;
run;
data norma;
	merge norma (drop = mediat propensione) mediat;
	by territorio;
run;
data norma;
	set norma;
	propensione = pronorma*mediaistat/mediat;
	drop correttivo;
run;
proc univariate data = norma;
	var propensione;
	histogram propensione;
run;
proc means data = norma noprint;
	weight red_ult;
	class territorio;
	types territorio;
	output out = verifica (drop = _type_ _freq_)
		   mean(propensione) = mediastima;
run;
data verifica;
	merge verifica mediaistat;
	by territorio;
	d = mediastima - mediaistat;
run;
proc print data = verifica;
run;


data stima1;
	set norma;
	stima_grezza = red_ult*propensione;
run;
proc tabulate data = stima1;
	var red_ult stima_grezza;
	table red_ult stima_grezza,sum*f=comma18.;
run;


data quadra;
	set confronto;
	keep territorio consumi_istat_ultimo;
run;
%quadraturagruppo(stima1,		
				  stima_grezza,	
				  quadra,		
				  consumi_istat_ultimo,	
				  stima_qua,	
				  territorio,	
				  qua1);		
data qua2;
	set qua1;
	stima_qua = round(stima_qua);
run;
%arrotondainterogruppo(qua2,		
					   stima_qua,	
					   quadra,		
					   consumi_istat_ultimo,	
					   territorio,	
					   qua3);		
proc tabulate data = qua3;
	class territorio;
	var stima_qua;
	table territorio all, stima_qua*sum*f = comma18.3;
run;


data pop_pre;
	set ter.demo20b;
	keep codc620b pop19;
	rename codc620b = codice_comune__str
		   pop19 = pop_pre;
run;
proc sort data = pop_pre;
	by codice_comune__str;
run;
proc sort data = qua3;
	by codice_comune__str;
run;
data base_controllo;
	merge qua3 eco pop_pre;
	by codice_comune__str;
	prop_pre = con_pre/red_pre;
	prop_ult = stima_qua/red_ult;
	prop_dif = prop_ult - prop_pre;
	con_pop_pre = con_pre/pop_pre;
	con_pop_ult = stima_qua/pop_ult;
	red_pop_pre = red_pre/pop_pre;
	convar = 100*(con_pop_ult - con_pop_pre)/con_pop_pre;
	redvar = 100*(red_pop_ult - red_pop_pre)/red_pop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var prop_ult;
	id nome_comune sigla_provincia prop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var prop_pre;
	id nome_comune sigla_provincia prop_ult;
run;
proc univariate data = base_controllo nextrobs = 20;
	var prop_dif;
	id nome_comune sigla_provincia prop_ult prop_pre;
	histogram prop_dif;
run;
proc univariate data = base_controllo nextrobs = 20;
	var con_pop_ult;
	id nome_comune sigla_provincia con_pop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var con_pop_pre;
	id nome_comune sigla_provincia con_pop_ult;
run;
proc freq data = base_controllo;
	where prop_ult > 1;
	tables territorio;
run;
proc corr data = base_controllo;
	var con_pop_ult red_pop_ult;
run;
proc sort data = base_controllo;
	by territorio;
run;
proc univariate data = base_controllo nextrobs = 20;
	by territorio;
	var convar;
	id nome_comune sigla_provincia redvar con_pop_ult red_pop_ult;
run;
proc univariate data = base_controllo nextrobs = 20;
	var convar;
	id nome_comune sigla_provincia redvar con_pop_ult red_pop_ult;
	histogram convar;
run;
proc univariate data = base_controllo;
	var redvar;
run;
data grande;
	set base_controllo;
	if pop_ult >= 100000;
run;
proc sort data = grande;
	by descending convar;
run;
proc print data = grande;
	var nome_comune sigla_provincia convar redvar
		con_pop_ult red_pop_ult con_pop_pre red_pop_pre;
	format convar redvar con_pop_ult red_pop_ult con_pop_pre red_pop_pre 12.1;
run;
data noncoerente;
	set base_controllo;
	if convar*redvar < 0 and min(abs(convar),abs(redvar)) > 1;
run; *1560; 

proc univariate data = base_controllo noprint;
	var convar;
	output out = estremi_v
		   pctlpre = varia
		   pctlname = p95 pctlpts = 95
		   pctlname = p5 pctlpts = 5;
run;
data base_n;
	if _N_ = 1 then set estremi_v;
	set base_controllo;
run;
data base_n;
	set base_n;
	varnorma = convar;
	if convar < variap5
		then varnorma = sum(.3*convar,.7*variap5);
	if convar > variap95
		then varnorma = sum(.3*convar,.7*variap95);
	drop variap5 variap95 ripart1 ripart2 ripart3 ripart4
		 inverso model1 stima_qua con_pop_ult prop_ult prop_dif;
run;
proc gplot data = base_n;
	symbol1 i = none  v = dot c = black;
	plot varnorma * convar = 1;
run;
quit;
proc univariate data = base_n;
	var varnorma;
	histogram varnorma;
run;


data ristima;
	set base_n;
	stima_n = pop_ult*con_pop_pre*(1 + varnorma/100);
run;
proc tabulate data = ristima;
	var red_ult stima_n red_pre con_pre;
	table red_ult stima_n red_pre con_pre,sum*f=comma18.;
run;


%quadraturagruppo(ristima,		
				  stima_n,		
				  quadra,		
				  consumi_istat_ultimo,	
				  stima_nq,		
				  territorio,	
				  quan1);		
data quan2;
	set quan1;
	stima_nq = round(stima_nq);
run;
%arrotondainterogruppo(quan2,		
					   stima_nq,	
					   quadra,		
					   consumi_istat_ultimo,	
					   territorio,		
					   quan3);		
proc tabulate data = quan3;
	var red_ult stima_nq red_pre con_pre;
	table red_ult stima_nq red_pre con_pre,sum*f=comma18.;
run;


proc means data = quan3 noprint;
	class territorio;
	types territorio;
	output out = verqua
		   sum(stima_nq) = ;
run;
proc sort data = quadra;
	by territorio;
run;
data verqua;
	merge verqua quadra;
	by territorio;
	controllo = (consumi_istat_ultimo ~= stima_nq);
run;
proc means data = verqua sum;
	var controllo;
run;


data base_controllo;
	set quan3;
	prop_ult = stima_nq/red_ult;
	con_pop_ult = stima_nq/pop_ult;
	convar = 100*(con_pop_ult - con_pop_pre)/con_pop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var prop_ult;
	id nome_comune sigla_provincia prop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var prop_pre;
	id nome_comune sigla_provincia prop_ult;
run;
proc univariate data = base_controllo nextrobs = 20;
	var con_pop_ult;
	id nome_comune sigla_provincia con_pop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var con_pop_pre;
	id nome_comune sigla_provincia con_pop_ult;
run;
proc freq data = base_controllo;
	where prop_ult > 1;
	tables territorio;
run;
proc corr data = base_controllo;
	var con_pop_ult red_pop_ult;
run;
proc univariate data = base_controllo nextrobs = 20;
	var convar;
	id  nome_comune sigla_provincia redvar con_pop_ult red_pop_ult;
	histogram convar;
run;
data grande;
	set base_controllo;
	if pop_ult >= 100000;
run;
proc sort data = grande;
	by descending convar;
run;
proc print data = grande;
	var nome_comune sigla_provincia convar redvar
		con_pop_ult red_pop_ult con_pop_pre red_pop_pre;
	format convar redvar con_pop_ult red_pop_ult con_pop_pre red_pop_pre 12.1;
run;
proc gplot data = base_controllo;
	symbol1 i = none  v = dot c = black;
	plot con_pop_ult * red_pop_ult = 1;
run;
quit;
data noncoerente;
	set base_controllo;
	if convar*redvar < 0 and min(abs(convar),abs(redvar)) > 1;
run; *1653; 

data attuale;
	set ter_out.economica_comune;
	drop consumi_totali;
run;
proc sort data = attuale;
	by codice_comune__str;
run;
proc sort data = base_controllo;
	by codice_comune__str;
run;
data nuova;
	merge attuale base_controllo (keep = codice_comune__str stima_nq);
	by codice_comune__str;
	rename stima_nq = consumi_totali;
run;
%let tracciato = 
codice_comune__str
reddito
consumi_totali
anno_riferimento
release;
data ordinata;
	retain &tracciato;
	set nuova;
run;


assistant
```python
import os
import pandas as pd
import numpy as np
from scipy import stats
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression

# Set up directory paths
sas_script_dir = "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets"
output_dir = "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets"

# Define the macro functions
execfile(os.path.join(sas_script_dir, "Macro\\macroquadraturagruppo.sas"))
execfile(os.path.join(sas_script_dir, "Macro\\macroarrotondainterogruppo.sas"))

# Load necessary data using pandas
xconsumi_tag = pd.read_excel(os.path.join(sas_script_dir, "tag_00026.xlsx"), sheet_name="TAG-00026_4", usecols="A3:G132")
xreddito_tag = pd.read_excel(os.path.join(sas_script_dir, "tag_00027.xlsx"), sheet_name="TAG-00027_2", usecols="A3:G132")

# Data cleaning
xconsumi_tag.province_e_regioni = xconsumi_tag.province_e_regioni.str.upper()
xreddito_tag.province_e_regioni = xreddito_tag.province_e_regioni.str.upper()
xconsumi_tag.consumi = xconsumi_tag._017 / 1000
xreddito_tag.reddito = xreddito_tag._017 / 1000

# Merge consumi and reddito data
base_tag = pd.merge(xreddito_tag, xconsumi_tag[['province_e_regioni', 'consumi']])
base_tag.sort_values(by='province_e_regioni', inplace=True)
base_tag['propensione'] = base_tag['consumi'] / base_tag['reddito']
base_tag['inverso'] = 1 / base_tag['reddito']

# Visualize propensione distribution
plt.figure(figsize=(10,6))
sns.histplot(base_tag['propensione'], kde=True)
plt.title('Propensione Distribution')
plt.xlabel('Propensione')
plt.ylabel('Frequency')
plt.show()

# Scatter plot of propensione vs. reddito
plt.figure(figsize=(10,6))
sns.scatterplot(x='reddito', y='propensione', data=base_tag)
plt.title('Scatter Plot of Propensione vs. Reddito')
plt.xlabel('Reddito')
plt.ylabel('Propensione')
plt.show()

# Scatter plot of propensione vs. inverso
plt.figure(figsize=(10,6))
sns.scatterplot(x='inverso', y='propensione', data=base_tag)
plt.title('Scatter Plot of Propensione vs. Inverso')
plt.xlabel('Inverso')
plt.ylabel('Propensione')
plt.show()

# Calculate correlation matrix
corr_matrix = base_tag[['propensione', 'reddito', 'inverso']].corr()
print(corr_matrix)

# Linear regression modeling
model1 = LinearRegression()
model1.fit(base_tag[['reddito']], base_tag['propensione'])
propensity_predicted = model1.predict(base_tag[['reddito']])
base_tag['propensity_predicted'] = propensity_predicted

# Polynomial regression modeling for different degrees
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(base_tag[['reddito']])
model2 = LinearRegression()
model2.fit(X_poly, base_tag['propensione'])
propensity_predicted_poly2 = model2.predict(poly.transform(base_tag[['reddito']]))
base_tag['propensity_predicted_poly2'] = propensity_predicted_poly2

# Load and preprocess geographical data
provincia = pd.read_excel(os.path.join(sas_script_dir, "provincia_110.xlsx"))
provincia.Denominazione_Provincia_Citt__me = provincia.Denominazione_Provincia_Citt__me.str.upper()
provincia = province.replace({'REGGIO DI CALABRIA': 'REGGIO CALABRIA'})

# Merging base_tag with provincial data
base_tag = pd.merge(base_tag,
                    provincia,
                    left_on='province_e_regioni',
                    right_on='Denominazione_Provincia_Citt__me',
                    suffixes=('', '_prov'))

# Load and preprocess correlation map data
corrispo = pd.read_excel(os.path.join(sas_script_dir, "Codici-statistici-e-denominazioni-al-31_12_2020.xls"),
                        sheet_name="CODICI al 31_12_2020")
corrispo.Codice_provincia = corrispo.Codice_Comune_numerico_con_110_p.apply(lambda x: str(x)[:3])
corrispo = corrispo[['Codice_Comune_formato_alfanumeri', 'Codice_provincia']].rename(columns={'Codice_Comune_formato_alfanumeri': 'codice_comune__str'})

# Merging base_tag with geographical correlation data
base_tag = pd.merge(base_tag, corrispo, on='codice_comune__str')

# Preprocess comune data
xcod = ter_out.geografica_comune[['codice_comune__str', 'codice_area_nielsen', 'codice_ripartizione']]
popnew = ter_out.Popolazione_eta_sesso_comune.groupby('codice_comune__str')['popolazione'].sum().reset_index().rename(columns={'popolazione': 'pop_ult'})
xcod = pd.merge(xcod, popnew, on='codice_comune__str')

# Compute sum of populations by province and by region
xcods = xcod.groupby('codice_provincia')[['pop_ult']].sum().reset_index()

# Merging base_tag with province and regional data
base_tag = pd.merge(base_tag, xcods, on='codice_provincia')

# Merging base_tag with population by region data
base_tag = pd.merge(base_tag, xcod[['codice_ripartizione', 'pop_ult']], on='codice_ripartizione', suffixes=('', '_region'))

# Perform weighted regression modeling
base_tag['log_pop_ult'] = np.log(base_tag['pop_ult'])
model3 = LinearRegression()
model3.fit(base_tag[['reddito', 'ripart1', 'ripart2', 'ripart3', 'ripart4']], base_tag['propensione'], sample_weight=base_tag['log_pop_ult'])
propensity_predicted_weighted = model3.predict(base_tag[['reddito', 'ripart1', 'ripart2', 'ripart3', 'ripart4']], sample_weight=base_tag['log_pop_ult'])

# Compute predicted propensity with confidence intervals
model3_ci = stats.t.ppf(0.975, len(base_tag) - 1) * np.sqrt(model3.residuals.var() * (1/len(base_tag) + (base_tag['reddito'] - base_tag['reddito'].mean())**2/(np.var(base_tag['reddito'])*len(base_tag))))
propensity_predicted_with_ci = base_tag['propensity_predicted'] + model3_ci
propensity_predicted_with_ci = pd.Series(propensity_predicted_with_ci, index=base_tag.index)

# Create a new column with predicted propensity with confidence intervals
base_tag['propensity_predicted_with_ci'] = propensity_predicted_with_ci

# Load and preprocess comune population data
pop_pre = ter.demo20b[['codc620b', 'pop19']]
pop_pre.rename(columns={'codc620b': 'codice_comune__str', 'pop19': 'pop_pre'}, inplace=True)

# Merging base_tag with population data from previous years
base_tag = pd.merge(base_tag, pop_pre, on='codice_comune__str')

# Load and preprocess economy data
eco = ter.econom20b[['codc620b', 'red19', 'con19']]
eco.rename(columns={'codc620b': 'codice_comune__str', 'red19': 'red_pre', 'con19': 'con_pre'}, inplace=True)
eco.loc[eco['red_pre'] == 0, 'red_pre'] = np.nan

# Preprocess economy data
popnew = ter_out.Popolazione_eta_sesso_comune.groupby('codice_comune__str')['popolazione'].sum().reset_index().rename(columns={'popolazione': 'pop_ult'})
eco_g = pd.merge(geog, eco, left_on='codice_comune__str', right_on='codice_comune__str')
regionale_precedente = eco_g.groupby('territorio')[['red_pre', 'con_pre', 'red_ult', 'pop_ult']].sum().reset_index().rename(columns={'territorio': 'territory'})
regionale_precedente['red_pop_pre'] = regionale_precedente['red_pre'] / regionale_precedente['pop_pre']
regionale_precedente['red_pop_ult'] = regionale_precedente['red_ult'] / regionale_precedente['pop_ult']
regionale_precedente['con_pop_pre'] = regionale_precedente['con_pre'] / regionale_precedente['pop_pre']
regionale_precedente['con_pop_ult'] = regionale_precedente['con_ult'] / regionale_precedente['pop_ult']

# Load and preprocess consumption data
consumi_istat = pd.read_csv(os.path.join(sas_script_dir, "quadratura_consumi.csv"), skiprows=1)
consumi_istat.rename(columns={'codice_comune': 'territory'}, inplace=True)
consumi_istat['territory'] = consumi_istat['territory'].str.upper()
consumi_istat.loc[consumi_istat['territory'] == "PROVINCIA AUTONOMA BOLZANO / BOZEN", 'territory'] = "BOLZANO"
consumi_istat.loc[consumi_istat['territory'] == "PROVINCIA AUTONOMA TRENTO", 'territory'] = "TRENTO"
consumi_istat.loc[consumi_istat['territory'] == "VALLE D'AOSTA / VALLéE D'AOSTE", 'territory'] = "VALLE D'AOSTA"
consumi_istat['consumi_istat_preced'] = consumi_istat['consumi_2019'] / 1000
consumi_istat['consumi_istat_ultimo'] = consumi_istat['consumi_2020'] / 1000

# Merge consumption data with previous and current regions
confronto = pd.merge(regionale_precedente, consumi_istat, on='territory')
confronto['difperc'] = 100 * (confronto['consumi_istat_preced'] - confronto['consumi_istat_ultimo']) / confronto['consumi_istat_preced']
confronto['mediaistat'] = confronto['consumi_istat_ultimo'] / confronto['red_pop_ult']
confronto.drop(['itter107', 'itersave', 'iterend'], axis=1, inplace=True)

# Sort and print consumption comparison results
confronto.sort_values('difperc', ascending=False, inplace=True)
print(confronto[['territory', 'consumi_istat_preced', 'consumi_istat_ultimo', 'difperc']].head())
confronto.sort_values('mediaistat', ascending=False, inplace=True)
print(confronto[['territory', 'consumi_istat_ultimo', 'mediaistat']].head())

# Plot consumption differences
plt.figure(figsize=(10,6))
sns.barplot(x='territory', y='difperc', data=confronto, palette="viridis")
plt.title('Consumption Difference by Territory (2019 vs. 2020)')
plt.xlabel('Territory')
plt.ylabel('Consumption Difference (%)')
plt.xticks(rotation=45)
plt.show()

# Plot consumption per capita
plt.figure(figsize=(10,6))
sns.barplot(x='territory', y='mediaistat', data=confronto, palette="viridis")
plt.title('Consumption per Capita by Territory')
plt.xlabel('Territory')
plt.ylabel('Consumption per Capita')
plt.xticks(rotation=45)
plt.show()

# Load and preprocess population data for previous years
pop_pre = ter.demo20b[['codc620b', 'pop19']]
pop_pre.rename(columns={'codc620b': 'codice_comune__str', 'pop19': 'pop_pre'}, inplace=True)

# Merge population data with economy data
eco_g = pd.merge(geog, eco, left_on='codice_comune__str', right_on='codice_comune__str')

# Merge economy data with comune population data
eco_g = pd.merge(eco_g, pop_pre, on='codice_comune__str')

# Calculate regional, state, and country-level mean consumption
verifica = eco_g.groupby(['territory', 'nome_regione', 'nome_provincia'])[['consumi_totali']].mean().reset_index().rename(columns={'consumi_totali': 'mediastima'})

# Sort and print verified results
verifica.sort_values('mediastima', ascending=False, inplace=True)
print(verifica[['territory', 'mediastima']].head())

# Calculate regional, state, and country-level coefficient of variation
base_controllo = pd.merge(quan3, eco_g, on='codice_comune__str')
base_controllo['prop_pre'] = base_controllo['con_pre'] / base_controllo['red_pre']
base_controllo['prop_ult'] = base_controllo['stima_nq'] / base_controllo['red_ult']
base_controllo['prop_dif'] = base_controllo['prop_ult'] - base_controllo['prop_pre']
base_controllo['con_pop_pre'] = base_controllo['con_pre'] / base_controllo['pop_pre']
base_controllo['con_pop_ult'] = base_controllo['stima_nq'] / base_controllo['pop_ult']
base_controllo['red_pop_pre'] = base_controllo['red_pre'] / base_controllo['pop_pre']

# Compute coefficient of variation
base_controllo['convar'] = (base_controllo['con_pop_ult'] - base_controllo['con_pop_pre']) / base_controllo['con_pop_pre']
base_controllo['redvar'] = (base_controllo['red_pop_ult'] - base_controllo['red_pop_pre']) / base_controllo['red_pop_pre']

# Sort by coefficient of variation and print results
base_controllo.sort_values('convar', ascending=False, inplace=True)
print(base_controllo[['nome_comune', 'sigla_provincia', 'convar']].head())

# Compute number of significantly deviating entries
significance_level = 0.05
noncoerente = base_controllo[((base_controllo['convar'] < -1) | (base_controllo['convar'] > 1)) & (np.abs(base_controllo['convar']) > 1)]

# Plot confidence interval for coefficient of variation
plt.figure(figsize=(10,6))
sns.boxplot(x='convar', data=base_controllo, palette="viridis")
plt.title('Confidence Interval for Coefficient of Variation')
plt.xlabel('Coefficient of Variation')
plt.show()

# Create scatterplot for coefficient of variation and population per capita
plt.figure(figsize=(10,6))
sns.scatterplot(x='con_pop_ult', y='convar', data=base_controllo, palette="viridis")
plt.title('Scatterplot of Coefficient of Variation vs. Population per Capita')
plt.xlabel('Population per Capita')
plt.ylabel('Coefficient of Variation')
plt.show()

# Plot correlation matrix for significant coefficients
correlation_matrix = base_controllo[['reddito', 'propensione', 'consumi_totali', 'convar', 'con_pop_ult', 'red_pop_ult']].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix for Significant Coefficients')
plt.show()

# Load and preprocess population data for previous years
pop_pre = ter.demo20b[['codc620b', 'pop19']]
pop_pre.rename(columns={'codc620b': 'codice_comune__str', 'pop19': 'pop_pre'}, inplace=True)

# Merge population data with economy data
eco_g = pd.merge(geog, eco, left_on='codice_comune__str', right_on='codice_comune__str')

# Merge economy data with comune population data
eco_g = pd.merge(eco_g, pop_pre, on='codice_comune__str')

# Calculate standardized mean difference
base_controllo['std_diff'] = base_controllo['prop_ult'] - base_controllo['prop_pre']
base_controllo['std_diff'] = base_controllo['std_diff'] / np.std(base_controllo['prop_pre'])

# Sort by standardized mean difference and print results
base_controllo.sort_values('std_diff', ascending=False, inplace=True)
print(base_controllo[['nome_comune', 'sigla_provincia', 'prop_ult', 'prop_pre', 'std_diff']].head())

# Calculate t-test p-values for significant coefficients
t_test_results = stats.ttest_ind(base_controllo['propensione'], base_controllo['std_diff'])
print(t_test_results)

# Filter entries with non-significant t-test p-values
filtered_entries = base_controllo[t_test_results.pvalue < significance_level]

# Merge the new attuale data with filtered results
attuale = ter_out.economica_comune.drop('consumi_totali', axis=1)
nuova = pd.merge(attuale, filtered_entries, on='codice_comune__str')

# Create a new output DataFrame with selected columns
tracciato = ['codice_comune__str', 'reddito', 'consumi_totali', 'anno_riferimento', 'release']
ordinata = nuova[tracciato]

print(ordinata)
```

This Python code first sets up the necessary directory paths and defines the macro functions from SAS scripts. It then loads, preprocesses, and merges data to perform regression and statistical analysis. The code uses pandas for data manipulation, numpy for numerical operations, scipy for statistical tests, seaborn and matplotlib for data visualization, and sklearn for polynomial regression. The code covers steps like data cleaning, merging, analysis, and visualization.