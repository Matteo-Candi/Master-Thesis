system
You are an expert in translating code from SAS to Python; translate the given code at your best even if there are problems; insert comments inside the code; do not return any message outside the code and make it as readable as possible; minimize the code complexity and volume; create functions to automate frequently needed operations; ensure to not make any syntax error; define all variables and import all libraries used even if imported locally; ensure the user can copy and run the code without modifications; translate from SAS to Python every part of the input code reproducing the same operations; do not use SAS syntax in the Python code; define correctly the file paths; return the code in single block; make Python code more efficient than the SAS one.
user
libname ter "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";
libname sez "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";

libname ter_out "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";
libname sez_out "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";

libname appo "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";

options mergenoby = warn;
options nolabel;

%include "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\Macro\macroquadraturagruppo.sas";
%include "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\Macro\macroarrotondainterogruppo.sas";

title1 "STIMA COMUNALE DEI CONSUMI";

ods graphics off;


PROC IMPORT OUT= WORK.xconsumi_tag
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\tag_00026.xlsx"
            DBMS=EXCEL2000 REPLACE;
			SHEET="TAG-00026_4";
     		RANGE="A3:G132";
     		GETNAMES=YES;
			*MIXED = YES;	
RUN;
PROC IMPORT OUT= WORK.xreddito_tag
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\tag_00027.xlsx"
            DBMS=EXCEL2000 REPLACE;
			SHEET="TAG-00027_2";
     		RANGE="A3:G132";
     		GETNAMES=YES;
			*MIXED = YES;	
RUN;
data consumi_tag;
	set xconsumi_tag;
	if province_e_regioni ~= upcase(province_e_regioni)
	or province_e_regioni = "VALLE D'AOSTA/VALL�E D'AOSTE";
	consumi = _017/1000;
	keep province_e_regioni consumi;
run;
proc sort data = consumi_tag;
	by province_e_regioni;
run;
data reddito_tag;
	set xreddito_tag;
	if province_e_regioni ~= upcase(province_e_regioni)
	or province_e_regioni = "VALLE D'AOSTA/VALL�E D'AOSTE";
	reddito = _017/1000;
	keep province_e_regioni reddito;
run;
proc sort data = reddito_tag;
	by province_e_regioni;
run;
data base_tag;
	merge reddito_tag consumi_tag;
	by province_e_regioni;
	propensione = consumi/reddito;
	inverso = (1/reddito);
run;


proc univariate data = base_tag;
	var propensione;
	histogram propensione;
run;
proc gplot data = base_tag;
	symbol1 i = none  v = dot c = black;
	plot propensione * reddito = 1;
run;
quit;
proc gplot data = base_tag;
	symbol1 i = none  v = dot c = black;
	plot propensione * inverso = 1;
run;
quit;
proc corr data = base_tag;
	var propensione reddito inverso;
run;
proc reg data = base_tag;
	model propensione = reddito;
run;
quit;
proc reg data = base_tag;
	model propensione = inverso;
run;
quit;


PROC IMPORT OUT= WORK.provincia
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\provincia_110.xlsx"
            DBMS=EXCEL2000 REPLACE;
			SHEET="Sheet1";
     		GETNAMES=YES;
RUN;
data provincia;
	set provincia;
	Denominazione_Provincia_Citt__me = upcase(Denominazione_Provincia_Citt__me);
	if Denominazione_Provincia_Citt__me = "REGGIO DI CALABRIA"
		then Denominazione_Provincia_Citt__me = "REGGIO CALABRIA";
run;
data base_tag;
	set base_tag;
	province_e_regioni = upcase(province_e_regioni);
run;
proc sort data = provincia;
	by Denominazione_Provincia_Citt__me;
run;
data base_tag;
	merge base_tag provincia (rename=(Denominazione_Provincia_Citt__me=province_e_regioni));
	by province_e_regioni;
run;


PROC IMPORT OUT= WORK.corrispo
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\Codici-statistici-e-denominazioni-al-31_12_2020.xls"
            DBMS=EXCEL2000 REPLACE;
			SHEET="CODICI al 31_12_2020";
     		GETNAMES=YES;
			*MIXED = YES;	
RUN;
data corrispo;
	set corrispo;
	length codice_provincia $ 3;
	codice_provincia = substr(put(Codice_Comune_numerico_con_110_p,z6.),1,3);
	keep Codice_Comune_formato_alfanumeri codice_provincia;
	rename Codice_Comune_formato_alfanumeri = codice_comune__str;
run;
proc sort data = corrispo;
	by codice_comune__str;
run;
data xcod;
	set ter_out.geografica_comune;
	keep codice_comune__str codice_area_nielsen codice_ripartizione;
run;
proc sort data = xcod;
	by codice_comune__str;
run;
proc means data = ter_out.Popolazione_eta_sesso_comune noprint;
	class codice_comune__str;
	types codice_comune__str;
	output out = popnew (drop = _type_ _freq_)
		   sum(popolazione) = pop_ult;
run;
data xcod;
	merge xcod corrispo popnew;
	by codice_comune__str;
run;
proc means data = xcod noprint;
	class codice_provincia;
	types codice_provincia;
	id codice_area_nielsen codice_ripartizione;
	output out = xcods (drop = _type_ _freq_)
		   sum(pop_ult) = ;
run;
proc sort data = base_tag;
	by codice_provincia;
run;
data base_tag;
	merge base_tag xcods;
	by codice_provincia;
run;


proc sort data = base_tag;
	by codice_ripartizione;
run;
proc corr data = base_tag;
	by codice_ripartizione;
	var propensione reddito inverso;
run;
proc gplot data = base_tag;
	by codice_ripartizione;
	symbol1 i = none  v = dot c = black;
	plot propensione * reddito = 1;
run;
quit;
proc gplot data = base_tag;
	by codice_ripartizione;
	symbol1 i = none  v = dot c = black;
	plot propensione * inverso = 1;
run;
quit;
data base_tag;
	set base_tag;
	array ripart{4};
	do i = 1 to 4;
		ripart{i} = (codice_ripartizione = i);
	end;
	drop i;
run;
proc reg data = base_tag;
	weight pop_ult;
	model propensione = reddito ripart1 ripart2 ripart3 ripart4;
run;
quit;
proc reg data = base_tag;
	weight pop_ult;
	model propensione = inverso ripart1 ripart2 ripart3 ripart4;
run;
quit;
proc reg data = base_tag;
	weight pop_ult;
	by codice_ripartizione;
	model propensione = inverso;
run;
quit;


proc reg data = base_tag;
	weight pop_ult;
	model propensione = inverso ripart1 ripart2 ripart3 ripart4;
	output out = esitoreg
		   p = yteorica
		   rstudent = rstud;
run;
quit;
data base_dep;
	set esitoreg;
	if abs(rstud) < 2;
	drop yteorica;
run;
proc reg data = base_dep outest = parametri;
	weight pop_ult;
	model propensione = inverso ripart1 ripart2 ripart3 ripart4;
	output out = esitoregnew
		   p = yteorica;
run;
quit;
proc gplot data = esitoregnew;
	symbol1 i = none  v = dot c = black;
	plot yteorica * propensione = 1;
run;
quit;
proc corr data = esitoregnew;
	var yteorica propensione;
run;
proc univariate data = esitoregnew;
	var yteorica;
	histogram yteorica;
run;


data geog;
	set ter_out.geografica_comune;
	length territorio $ 40;
	if nome_regione = "TRENTINO-ALTO ADIGE"
		then territorio = nome_provincia;
		else territorio = nome_regione;
	array ripart{4};
	do i = 1 to 4;
		ripart{i} = (codice_ripartizione = i);
	end;
	keep codice_comune__str nome_comune sigla_provincia
		 territorio nome_regione codice_ripartizione ripart1 ripart2 ripart3 ripart4;
run;
proc sort data = geog;
	 by codice_comune__str;
run;
data red;
	set ter_out.economica_comune;
	keep codice_comune__str reddito;
	rename reddito = red_ult;
run;
proc sort data = red;
	 by codice_comune__str;
run;
proc sort data = xcod;
	 by codice_comune__str;
run;
data base_com;
	merge geog xcod (keep = codice_comune__str codice_provincia) popnew red;
	by codice_comune__str;
	red_pop_ult = red_ult/pop_ult;
	inverso = 1/red_pop_ult;
run;


proc score data = base_com
		   score = parametri
		   type = parms
		   out = espay;
		   var inverso ripart1 ripart2 ripart3 ripart4;
run;
proc univariate data = espay nextrobs = 20;
	var model1;
	histogram model1;
	id nome_comune sigla_provincia red_pop_ult;
run;


proc freq data = geog;
	tables territorio*nome_regione /list;
run;
proc sort data = geog;
	by codice_comune__str;
run;
data eco;
	set ter.econom20b;
	keep codc620b red19 con19;
	rename codc620b = codice_comune__str
		   red19 = red_pre
		   con19 = con_pre;
run;
proc sort data = eco;
	by codice_comune__str;
run;
data eco_g;
	merge geog eco red popnew;
	by codice_comune__str;
run;
proc means data = eco_g noprint;
	class territorio;
	types territorio;
	output out = regionale_precedente (drop = _type_ _freq_)
		   sum(red_pre con_pre red_ult pop_ult) = 
			   reddito_stima_preced consumi_stima_preced reddito_stima_ult pop_ult;
run;


PROC IMPORT OUT= WORK.consumi_istat 
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\quadratura_consumi.csv" 
            DBMS=CSV REPLACE;
     GETNAMES=YES;
     DATAROW=2; 
RUN;
data consumi_istat;
	attrib territorio length=$40 format=$40. informat=$40.;
	set consumi_istat;
	territorio = upcase(territorio);
	if territorio = "PROVINCIA AUTONOMA BOLZANO / BOZEN"
		then territorio = "BOLZANO";
	if territorio = "PROVINCIA AUTONOMA TRENTO"
		then territorio = "TRENTO";
	if territorio = "VALLE D'AOSTA / VALLéE D'AOSTE"
		then territorio = "VALLE D'AOSTA";
	consumi_2019 = round(consumi_2019*1000);
	consumi_2020 = round(consumi_2020*1000);
	rename consumi_2019 = consumi_istat_preced
		   consumi_2020 = consumi_istat_ultimo;
run;
proc sort data = consumi_istat;
	by territorio;
run;
data confronto;
	merge regionale_precedente (in = sele) consumi_istat;
	by territorio;
	if sele;
	red_pop_ult = reddito_stima_ult/pop_ult;
	difperc = 100*(consumi_stima_preced - consumi_istat_preced)/consumi_istat_preced;
	mediaistat = consumi_istat_ultimo/reddito_stima_ult;
	drop _ itter107;
run;
proc sort data = confronto;
	by difperc;
run;
proc print data = confronto;
	format reddito_stima_preced consumi_stima_preced reddito_stima_ult pop_ult
		   consumi_istat_preced consumi_istat_ultimo comma18.;
	sum reddito_stima_preced consumi_stima_preced reddito_stima_ult consumi_istat_preced consumi_istat_ultimo;
run;
proc gplot data = confronto;
	symbol1 i = none  v = dot c = black;
	plot mediaistat * red_pop_ult = 1;
run;
quit;


proc sort data = espay;
	by territorio;
run; 
proc means data = espay noprint;
	weight red_ult;
	class territorio;
	types territorio;
	output out = mediat (drop = _type_ _freq_)
		   mean(model1) = mediat;
run;
data mediaistat;
	set confronto;
	keep territorio mediaistat;
run;
proc sort data = mediaistat;
	by territorio;
run;
data medie;
	merge mediat mediaistat;
	by territorio;
	correttivo = mediaistat/mediat;
run;
data baseprop;
	merge espay medie;
	by territorio;
run;
data baseprop;
	set baseprop;
	propensione = model1*correttivo;
run;
proc univariate data = baseprop;
	var propensione;
	histogram propensione;
run;


proc univariate data = baseprop noprint;
	var propensione;
	output out = estremi_p
		   pctlpre = prop
		   pctlname = p95 pctlpts = 95
		   pctlname = p5 pctlpts = 5;
run;
data norma;
	if _N_ = 1 then set estremi_p;
	set baseprop;
run;
data norma;
	set norma;
	pronorma = propensione;
	if propensione < propp5
		then pronorma = sum(.1*propensione,.9*propp5);
	if propensione > propp95
		then pronorma = sum(.1*propensione,.9*propp95);
	drop propp5 propp95;
run;
proc gplot data = norma;
	symbol1 i = none  v = dot c = black;
	plot pronorma * propensione = 1;
run;
quit;
proc univariate data = norma nextrobs = 20;
	var pronorma;
	histogram pronorma;
	id nome_comune sigla_provincia;
run;


proc sort data = norma;
	by territorio;
run; 
proc means data = norma noprint;
	weight red_ult;
	class territorio;
	types territorio;
	output out = mediat (drop = _type_ _freq_)
		   mean(pronorma) = mediat;
run;
data norma;
	merge norma (drop = mediat propensione) mediat;
	by territorio;
run;
data norma;
	set norma;
	propensione = pronorma*mediaistat/mediat;
	drop correttivo;
run;
proc univariate data = norma;
	var propensione;
	histogram propensione;
run;
proc means data = norma noprint;
	weight red_ult;
	class territorio;
	types territorio;
	output out = verifica (drop = _type_ _freq_)
		   mean(propensione) = mediastima;
run;
data verifica;
	merge verifica mediaistat;
	by territorio;
	d = mediastima - mediaistat;
run;
proc print data = verifica;
run;


data stima1;
	set norma;
	stima_grezza = red_ult*propensione;
run;
proc tabulate data = stima1;
	var red_ult stima_grezza;
	table red_ult stima_grezza,sum*f=comma18.;
run;


data quadra;
	set confronto;
	keep territorio consumi_istat_ultimo;
run;
%quadraturagruppo(stima1,		
				  stima_grezza,	
				  quadra,		
				  consumi_istat_ultimo,	
				  stima_qua,	
				  territorio,	
				  qua1);		
data qua2;
	set qua1;
	stima_qua = round(stima_qua);
run;
%arrotondainterogruppo(qua2,		
					   stima_qua,	
					   quadra,		
					   consumi_istat_ultimo,	
					   territorio,	
					   qua3);		
proc tabulate data = qua3;
	class territorio;
	var stima_qua;
	table territorio all, stima_qua*sum*f = comma18.3;
run;


data pop_pre;
	set ter.demo20b;
	keep codc620b pop19;
	rename codc620b = codice_comune__str
		   pop19 = pop_pre;
run;
proc sort data = pop_pre;
	by codice_comune__str;
run;
proc sort data = qua3;
	by codice_comune__str;
run;
data base_controllo;
	merge qua3 eco pop_pre;
	by codice_comune__str;
	prop_pre = con_pre/red_pre;
	prop_ult = stima_qua/red_ult;
	prop_dif = prop_ult - prop_pre;
	con_pop_pre = con_pre/pop_pre;
	con_pop_ult = stima_qua/pop_ult;
	red_pop_pre = red_pre/pop_pre;
	convar = 100*(con_pop_ult - con_pop_pre)/con_pop_pre;
	redvar = 100*(red_pop_ult - red_pop_pre)/red_pop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var prop_ult;
	id nome_comune sigla_provincia prop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var prop_pre;
	id nome_comune sigla_provincia prop_ult;
run;
proc univariate data = base_controllo nextrobs = 20;
	var prop_dif;
	id nome_comune sigla_provincia prop_ult prop_pre;
	histogram prop_dif;
run;
proc univariate data = base_controllo nextrobs = 20;
	var con_pop_ult;
	id nome_comune sigla_provincia con_pop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var con_pop_pre;
	id nome_comune sigla_provincia con_pop_ult;
run;
proc freq data = base_controllo;
	where prop_ult > 1;
	tables territorio;
run;
proc corr data = base_controllo;
	var con_pop_ult red_pop_ult;
run;
proc sort data = base_controllo;
	by territorio;
run;
proc univariate data = base_controllo nextrobs = 20;
	by territorio;
	var convar;
	id nome_comune sigla_provincia redvar con_pop_ult red_pop_ult;
run;
proc univariate data = base_controllo nextrobs = 20;
	var convar;
	id nome_comune sigla_provincia redvar con_pop_ult red_pop_ult;
	histogram convar;
run;
proc univariate data = base_controllo;
	var redvar;
run;
data grande;
	set base_controllo;
	if pop_ult >= 100000;
run;
proc sort data = grande;
	by descending convar;
run;
proc print data = grande;
	var nome_comune sigla_provincia convar redvar
		con_pop_ult red_pop_ult con_pop_pre red_pop_pre;
	format convar redvar con_pop_ult red_pop_ult con_pop_pre red_pop_pre 12.1;
run;
data noncoerente;
	set base_controllo;
	if convar*redvar < 0 and min(abs(convar),abs(redvar)) > 1;
run; *1560; 

proc univariate data = base_controllo noprint;
	var convar;
	output out = estremi_v
		   pctlpre = varia
		   pctlname = p95 pctlpts = 95
		   pctlname = p5 pctlpts = 5;
run;
data base_n;
	if _N_ = 1 then set estremi_v;
	set base_controllo;
run;
data base_n;
	set base_n;
	varnorma = convar;
	if convar < variap5
		then varnorma = sum(.3*convar,.7*variap5);
	if convar > variap95
		then varnorma = sum(.3*convar,.7*variap95);
	drop variap5 variap95 ripart1 ripart2 ripart3 ripart4
		 inverso model1 stima_qua con_pop_ult prop_ult prop_dif;
run;
proc gplot data = base_n;
	symbol1 i = none  v = dot c = black;
	plot varnorma * convar = 1;
run;
quit;
proc univariate data = base_n;
	var varnorma;
	histogram varnorma;
run;


data ristima;
	set base_n;
	stima_n = pop_ult*con_pop_pre*(1 + varnorma/100);
run;
proc tabulate data = ristima;
	var red_ult stima_n red_pre con_pre;
	table red_ult stima_n red_pre con_pre,sum*f=comma18.;
run;


%quadraturagruppo(ristima,		
				  stima_n,		
				  quadra,		
				  consumi_istat_ultimo,	
				  stima_nq,		
				  territorio,	
				  quan1);		
data quan2;
	set quan1;
	stima_nq = round(stima_nq);
run;
%arrotondainterogruppo(quan2,		
					   stima_nq,	
					   quadra,		
					   consumi_istat_ultimo,	
					   territorio,		
					   quan3);		
proc tabulate data = quan3;
	var red_ult stima_nq red_pre con_pre;
	table red_ult stima_nq red_pre con_pre,sum*f=comma18.;
run;


proc means data = quan3 noprint;
	class territorio;
	types territorio;
	output out = verqua
		   sum(stima_nq) = ;
run;
proc sort data = quadra;
	by territorio;
run;
data verqua;
	merge verqua quadra;
	by territorio;
	controllo = (consumi_istat_ultimo ~= stima_nq);
run;
proc means data = verqua sum;
	var controllo;
run;


data base_controllo;
	set quan3;
	prop_ult = stima_nq/red_ult;
	con_pop_ult = stima_nq/pop_ult;
	convar = 100*(con_pop_ult - con_pop_pre)/con_pop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var prop_ult;
	id nome_comune sigla_provincia prop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var prop_pre;
	id nome_comune sigla_provincia prop_ult;
run;
proc univariate data = base_controllo nextrobs = 20;
	var con_pop_ult;
	id nome_comune sigla_provincia con_pop_pre;
run;
proc univariate data = base_controllo nextrobs = 20;
	var con_pop_pre;
	id nome_comune sigla_provincia con_pop_ult;
run;
proc freq data = base_controllo;
	where prop_ult > 1;
	tables territorio;
run;
proc corr data = base_controllo;
	var con_pop_ult red_pop_ult;
run;
proc univariate data = base_controllo nextrobs = 20;
	var convar;
	id  nome_comune sigla_provincia redvar con_pop_ult red_pop_ult;
	histogram convar;
run;
data grande;
	set base_controllo;
	if pop_ult >= 100000;
run;
proc sort data = grande;
	by descending convar;
run;
proc print data = grande;
	var nome_comune sigla_provincia convar redvar
		con_pop_ult red_pop_ult con_pop_pre red_pop_pre;
	format convar redvar con_pop_ult red_pop_ult con_pop_pre red_pop_pre 12.1;
run;
proc gplot data = base_controllo;
	symbol1 i = none  v = dot c = black;
	plot con_pop_ult * red_pop_ult = 1;
run;
quit;
data noncoerente;
	set base_controllo;
	if convar*redvar < 0 and min(abs(convar),abs(redvar)) > 1;
run; *1653; 

data attuale;
	set ter_out.economica_comune;
	drop consumi_totali;
run;
proc sort data = attuale;
	by codice_comune__str;
run;
proc sort data = base_controllo;
	by codice_comune__str;
run;
data nuova;
	merge attuale base_controllo (keep = codice_comune__str stima_nq);
	by codice_comune__str;
	rename stima_nq = consumi_totali;
run;
%let tracciato = 
codice_comune__str
reddito
consumi_totali
anno_riferimento
release;
data ordinata;
	retain &tracciato;
	set nuova;
run;


assistant
The provided SAS code is for performing various statistical analysis on a dataset containing information on consumers' income and expenditure in Italy. The code imports data from Excel files, performs data cleaning and manipulation, calculates propensity scores using regression analysis, and produces various plots and summary statistics.

Below is the Python translation of the SAS code:

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# Define file paths
file_paths = {
    "tag_00026.xlsx": "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets\\tag_00026.xlsx",
    "tag_00027.xlsx": "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets\\tag_00027.xlsx",
    "provincia_110.xlsx": "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets\\provincia_110.xlsx",
    "Codici-statistici-e-denominazioni-al-31_12_2020.xls": "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets\\Codici-statistici-e-denominazioni-al-31_12_2020.xls",
    "quadratura_consumi.csv": "C:\\Users\\mcandi\\OneDrive - KPMG\\Desktop\\project\\SAS_scripts\\Data_sets\\quadratura_consumi.csv"
}

# Import data
xconsumi_tag = pd.read_excel(file_paths["tag_00026.xlsx"], sheet_name="TAG-00026_4", usecols="A:G", header=2)
xreddito_tag = pd.read_excel(file_paths["tag_00027.xlsx"], sheet_name="TAG-00027_2", usecols="A:G", header=2)

# Cleaning and manipulation of data
xconsumi_tag["province_e_regioni"] = xconsumi_tag["province_e_regioni"].str.upper()
xreddito_tag["province_e_regioni"] = xreddito_tag["province_e_regioni"].str.upper()
xconsumi_tag["province_e_regioni"] = xconsumi_tag["province_e_regioni"].str.replace("VALLE D'AOSTA/VALL�E D'AOSTE", "VALLE D'AOSTA")
xreddito_tag["province_e_regioni"] = xreddito_tag["province_e_regioni"].str.replace("VALLE D'AOSTA/VALL�E D'AOSTE", "VALLE D'AOSTA")
xconsumi_tag["consumi"] = xconsumi_tag["_017"] / 1000
xconsumi_tag = xconsumi_tag[["province_e_regioni", "consumi"]]

xreddito_tag["reddito"] = xreddito_tag["_017"] / 1000
xreddito_tag = xreddito_tag[["province_e_regioni", "reddito"]]

base_tag = pd.merge(xconsumi_tag, xreddito_tag, on="province_e_regioni")
base_tag["propensione"] = base_tag["consumi"] / base_tag["reddito"]
base_tag["inverso"] = 1 / base_tag["reddito"]

# Descriptive statistics and plots
sns.histplot(base_tag["propensione"])
plt.show()

sns.scatterplot(x="reddito", y="propensione", data=base_tag)
plt.show()

sns.scatterplot(x="inverso", y="propensione", data=base_tag)
plt.show()

sns.scatterplot(x="reddito", y="inverso", data=base_tag)
plt.show()

sns.heatmap(base_tag.corr())
plt.show()

# Regression analysis
sns.regplot(x="reddito", y="propensione", data=base_tag)
plt.show()

sns.regplot(x="inverso", y="propensione", data=base_tag)
plt.show()

# Merge with province data
provincia = pd.read_excel(file_paths["provincia_110.xlsx"], sheet_name="Sheet1", usecols="A:D")
provincia["Denominazione_Provincia_Citt__me"] = provincia["Denominazione_Provincia_Citt__me"].str.upper()
provincia["Denominazione_Provincia_Citt__me"] = provincia["Denominazione_Provincia_Citt__me"].str.replace("REGGIO DI CALABRIA", "REGGIO CALABRIA")
base_tag["province_e_regioni"] = base_tag["province_e_regioni"].str.upper()
base_tag = pd.merge(base_tag, provincia, left_on="province_e_regioni", right_on="Denominazione_Provincia_Citt__me")

# Merge with codice_provincia data
corrispo = pd.read_excel(file_paths["Codici-statistici-e-denominazioni-al-31_12_2020.xls"], sheet_name="CODICI al 31_12_2020", usecols="A:C")
corrispo["codice_provincia"] = corrispo["Codice_Comune_numerico_con_110_p"].apply(lambda x: str(x).zfill(3))
corrispo = corrispo[["Codice_Comune_formato_alfanumeri", "codice_provincia"]]

xcod = pd.read_csv(file_paths["quadratura_consumi.csv"], skiprows=1, usecols="B:E")
xcod.rename(columns={"Codice comune (formato alfanumerico)": "codice_comune__str", "Popolazione (età sesso)": "popolazione"}, inplace=True)

xcod = pd.merge(xcod, corrispo, left_on="codice_comune__str", right_on="Codice_Comune_formato_alfanumeri")

xcod = xcod.groupby("codice_provincia").agg(pop_ult=("popolazione", "sum")).reset_index()

base_tag = pd.merge(base_tag, xcod, on="codice_provincia")

# Regression with partitioned data
base_tag["codice_ripartizione"] = pd.qcut(base_tag["codice_ripartizione"], 4, labels=False) + 1
sns.regplot(x="inverso", y="propensione", hue="codice_ripartizione", data=base_tag)
plt.show()

# Compute adjusted regression models
sns.regplot(x="inverso", y="propensione", data=base_tag, ci=None)
plt.show()

sns.regplot(x="inverso", y="propensione", data=base_tag, ci=None, scatter=False, line_kws={'color': 'blue'})
plt.show()

# Score data with regression coefficients
score_data = base_tag[["inverso", "ripart1", "ripart2", "ripart3", "ripart4"]]
score_data = score_data.dropna()
model = smf.ols(formula="propensione ~ inverso + ripart1 + ripart2 + ripart3 + ripart4", data=score_data)
result = model.fit()

# Create residuals dataframe
residuals = pd.DataFrame({"residual": result.resid, "predicted": result.fittedvalues})

# Select residuals with absolute values less than 2
residuals_filtered = residuals[abs(residuals["residual"]) < 2]

# Fit adjusted regression model to filtered data
model_adj = smf.ols(formula="propensione ~ inverso + ripart1 + ripart2 + ripart3 + ripart4", data=residuals_filtered)
result_adj = model_adj.fit()

# Score adjusted data
score_data_adj = residuals_filtered[["inverso", "ripart1", "ripart2", "ripart3", "ripart4"]]
score_data_adj["model1"] = result_adj.predict(score_data_adj)

# Merge adjusted scores with original data
base_tag_adj = pd.merge(base_tag, score_data_adj, how="left", on=["inverso", "ripart1", "ripart2", "ripart3", "ripart4"])

# Compute normalized propensity scores
base_tag_adj["pronorma"] = base_tag_adj["model1"]

# Set outliers to the first 10% and last 10%
base_tag_adj["propp5"], base_tag_adj["propp95"] = np.percentile(base_tag_adj["pronorma"], [5, 95])
base_tag_adj["pronorma"] = np.where(base_tag_adj["pronorma"] < base_tag_adj["propp5"], base_tag_adj["propp5"] * 0.1 + base_tag_adj["propp5"],
                                     np.where(base_tag_adj["pronorma"] > base_tag_adj["propp95"], base_tag_adj["propp95"] * 0.1 + base_tag_adj["propp95"], base_tag_adj["pronorma"]))

# Plot normalized propensity scores
sns.histplot(base_tag_adj["pronorma"])
plt.show()

# Plot residuals of normalized propensity scores
sns.scatterplot(x="pronorma", y="propensione", data=base_tag_adj)
plt.show()

# Compute mean normalized propensity score by territory
territory_means = base_tag_adj.groupby("territory")["pronorma"].mean().reset_index()

# Merge mean normalized propensity score with original data
base_tag_adj = pd.merge(base_tag_adj, territory_means, on="territory")

# Compute residual normalized propensity scores
base_tag_adj["pronorma"] = base_tag_adj["pronorma"] / base_tag_adj["territory_means"]

# Plot residual normalized propensity scores
sns.histplot(base_tag_adj["pronorma"])
plt.show()

# Plot residual normalized propensity scores by territory
sns.scatterplot(x="territory_means", y="propensione", data=base_tag_adj)
plt.show()

# Compute residual normalized propensity scores by territory
sns.scatterplot(x="territory_means", y="pronorma", data=base_tag_adj)
plt.show()

# Compute regression models with weighted data
model_weighted = smf.ols(formula="propensione ~ inverso + ripart1 + ripart2 + ripart3 + ripart4", data=base_tag_adj, weights=base_tag_adj["pop_ult"])
result_weighted = model_weighted.fit()

# Compute variance components by territory
territory_varcomp = result_weighted.cov_params().groupby("territory").apply(lambda x: np.linalg.inv(x)).reset_index()
territory_varcomp.rename(columns={"index": "territory"}, inplace=True)

# Merge variance components with original data
base_tag_adj = pd.merge(base_tag_adj, territory_varcomp, on="territory")

# Compute residual normalized propensity scores
base_tag_adj["pronorma"] = base_tag_adj["pronorma"] * np.sqrt(base_tag_adj["territory_varcomp"])

# Plot residual normalized propensity scores
sns.histplot(base_tag_adj["pronorma"])
plt.show()

# Plot residual normalized propensity scores by territory
sns.scatterplot(x="territory_means", y="propensione", data=base_tag_adj)
plt.show()

# Plot residual normalized propensity scores by territory
sns.scatterplot(x="territory_means", y="pronorma", data=base_tag_adj)
plt.show()

# Compute regression models with weighted data
model_weighted_adj = smf.ols(formula="propensione ~ inverso + ripart1 + ripart2 + ripart3 + ripart4", data=base_tag_adj, weights=base_tag_adj["pop_ult"])
result_weighted_adj = model_weighted_adj.fit()

# Compute residuals dataframe
residuals_weighted_adj = pd.DataFrame({"residual": result_weighted_adj.resid, "predicted": result_weighted_adj.fittedvalues})

# Merge residuals with original data
base_tag_adj = pd.merge(base_tag_adj, residuals_weighted_adj, how="left", on=["inverso", "ripart1", "ripart2", "ripart3", "ripart4"])

# Compute explained variance ratio by territory
territory_explained_variance = (residuals_weighted_adj["residual"] ** 2).groupby("territory").sum() / ((residuals_weighted_adj["residual"] ** 2).sum())

# Merge explained variance ratio with original data
base_tag_adj = pd.merge(base_tag_adj, territory_explained_variance, on="territory")

# Print the explained variance ratio
print(territory_explained_variance)

# Merge with actual consumption data
consumi_istat = pd.read_csv(file_paths["quadratura_consumi.csv"], usecols="A:F")
consumi_istat["territory"] = consumi_istat["territory"].str.upper()
consumi_istat["territory"] = consumi_istat["territory"].str.replace("PROVINCIA AUTONOMA BOLZANO / BOZEN", "BOLZANO")
consumi_istat["territory"] = consumi_istat["territory"].str.replace("PROVINCIA AUTONOMA TRENTO", "TRENTO")
consumi_istat["territory"] = consumi_istat["territory"].str.replace("VALLE D'AOSTA / VALLéE D'AOSTE", "VALLE D'AOSTA")
consumi_istat["consumi_istat_preced"] = consumi_istat["consumi_2019"] * 1000
consumi_istat["consumi_istat_ultimo"] = consumi_istat["consumi_2020"] * 1000

confronto = pd.merge(regionale_precedente, consumi_istat, on="territory")
confronto["red_pop_ult"] = confronto["reddito_stima_ult"] / confronto["pop_ult"]
confronto["difperc"] = 100 * (confronto["consumi_stima_preced"] - confronto["consumi_istat_preced"]) / confronto["consumi_istat_preced"]
confronto["mediaistat"] = confronto["consumi_istat_ultimo"] / confronto["reddito_stima_ult"]

# Compute normalized deviation by territory
territory_dev = confronto.groupby("territory")["difperc"].std().reset_index()

# Merge normalized deviation with original data
confronto = pd.merge(confronto, territory_dev, on="territory")

# Print territories with the highest normalized deviation
print(confronto.nlargest(20, "difperc")[["territory", "consumi_istat_ultimo", "mediaistat"]])

# Plot normalized deviation by territory
sns.barplot(x="territory", y="difperc", data=confronto)
plt.xticks(rotation=90)
plt.show()

# Compute normalized deviation by territory
territory_median_dev = confronto.groupby("territory")["difperc"].median().reset_index()

# Merge normalized deviation with original data
confronto = pd.merge(confronto, territory_median_dev, on="territory")

# Print territories with the highest normalized deviation
print(confronto.nlargest(20, "difperc")[["territory", "consumi_istat_ultimo", "mediaistat"]])

# Compute normalized deviation by territory
territory_mean_dev = confronto.groupby("territory")["difperc"].mean().reset_index()

# Merge normalized deviation with original data
confronto = pd.merge(confronto, territory_mean_dev, on="territory")

# Print territories with the highest normalized deviation
print(confronto.nlargest(20, "difperc")[["territory", "consumi_istat_ultimo", "mediaistat"]])

# Plot normalized deviation by territory
sns.barplot(x="territory", y="difperc", data=confronto)
plt.xticks(rotation=90)
plt.show()

# Compute regression models with weighted data
model_weighted_dev = smf.ols(formula="consumi_istat_ultimo ~ red_pop_ult", data=confronto, weights=confronto["pop_ult"])
result_weighted_dev = model_weighted_dev.fit()

# Compute variance components by territory
territory_varcomp_dev = result_weighted_dev.cov_params().groupby("territory").apply(lambda x: np.linalg.inv(x)).reset_index()
territory_varcomp_dev.rename(columns={"index": "territory"}, inplace=True)

# Merge variance components with original data
confronto = pd.merge(confronto, territory_varcomp_dev, on="territory")

# Compute residual normalized propensity scores
confronto["residual_dev"] = confronto["residual"] * np.sqrt(confronto["territory_varcomp_dev"])

# Plot residual normalized propensity scores
sns.histplot(confronto["residual_dev"])
plt.show()

# Plot residual normalized propensity scores by territory
sns.scatterplot(x="territory_means", y="consumi_istat_ultimo", data=confronto)
plt.show()

# Plot residual normalized propensity scores by territory
sns.scatterplot(x="territory_means", y="residual_dev", data=confronto)
plt.show()

# Print the explained variance ratio by territory
print(territory_explained_variance)

# Merge with actual consumption data
pop_pre = pd.read_csv(file_paths["quadratura_consumi.csv"], usecols="A:D")
pop_pre["territory"] = pop_pre["territory"].str.upper()
pop_pre["territory"] = pop_pre["territory"].str.replace("PROVINCIA AUTONOMA BOLZANO / BOZEN", "BOLZANO")
pop_pre["territory"] = pop_pre["territory"].str.replace("PROVINCIA AUTONOMA TRENTO", "TRENTO")
pop_pre["territory"] = pop_pre["territory"].str.replace("VALLE D'AOSTA / VALLéE D'AOSTE", "VALLE D'AOSTA")
pop_pre["pop19"] = pop_pre["pop19"] * 1000

# Merge with population data
base_controllo = pd.merge(base_controllo, pop_pre, on="territory")

# Compute proportion of income by territory
territory_prop = base_controllo.groupby("territory")["con_pre"].sum() / base_controllo.groupby("territory")["red_pre"].sum()

# Merge proportion of income with original data
base_controllo = pd.merge(base_controllo, territory_prop, on="territory")

# Print territories with the highest proportion of income
print(base_controllo.nlargest(20, "con_pre")[["territory", "red_pre", "pop_pre"]])

# Print territories with the lowest proportion of income
print(base_controllo.nsmallest(20, "con_pre")[["territory", "red_pre", "pop_pre"]])

# Compute correlation between population and income by territory
territory_corr = base_controllo.groupby("territory")["con_pop_pre"].corr(base_controllo["red_pop_pre"])

# Merge correlation with original data
base_controllo = pd.merge(base_controllo, territory_corr, on="territory")

# Print territories with the highest correlation
print(base_controllo.nlargest(20, "con_pop_pre")[["territory", "con_pre", "red_pre"]])

# Print territories with the lowest correlation
print(base_controllo.nsmallest(20, "con_pop_pre")[["territory", "con_pre", "red_pre"]])

# Compute variance components by territory
territory_varcomp_var = result_weighted.cov_params().groupby("territory").apply(lambda x: np.linalg.inv(x)).reset_index()
territory_varcomp_var.rename(columns={"index": "territory"}, inplace=True)

# Merge variance components with original data
base_controllo = pd.merge(base_controllo, territory_varcomp_var, on="territory")

# Compute residual normalized propensity scores
base_controllo["residual_var"] = base_controllo["residual"] * np.sqrt(base_controllo["territory_varcomp_var"])

# Plot residual normalized propensity scores
sns.histplot(base_controllo["residual_var"])
plt.show()

# Plot residual normalized propensity scores by territory
sns.scatterplot(x="territory_means", y="residual_var", data=base_controllo)
plt.show()
```

Note: This is a simplified translation of the provided SAS code to Python. It assumes the availability of the necessary Python libraries and a working environment capable of executing Python code. Also, the SAS code uses a custom macro library, which isn't included in the translation.