system
You are an expert in translating code from SAS to Python; translate the given code at your best even if there are problems; insert comments inside the code; do not return any message outside the code and make it as readable as possible; minimize the code complexity and volume; create functions to automate frequently needed operations; ensure to not make any syntax error; define all variables and import all libraries used even if imported locally; ensure the user can copy and run the code without modifications; translate from SAS to Python every part of the input code reproducing the same operations; do not use SAS syntax in the Python code; define correctly the file paths; return the code in single block; make Python code more efficient than the SAS one.
user
libname ter "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";
libname sez "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";

libname ter_out "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";
libname sez_out "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";

libname appo "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets";

options mergenoby = warn;
options nolabel;

%include "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Macro\macroquadraturagruppo.sas";
%include "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Macro\macroarrotondainterogruppo.sas";

title1 "STIMA COMUNALE DEL REDDITO";


data geog;
	set ter_out.geografica_comune;
	length territorio $ 40;
	if nome_regione = "TRENTINO-ALTO ADIGE"
		then territorio = nome_provincia;
		else territorio = nome_regione;
	keep codice_comune__str territorio nome_regione; 
run;
proc freq data = geog;
	tables territorio*nome_regione /list;
run;
proc sort data = geog;
	by codice_comune__str;
run;
data eco;
	set ter.econom20b;
	keep codc620b red19;
	rename codc620b = codice_comune__str;
run;
proc sort data = eco;
	by codice_comune__str;
run;
data eco_g;
	merge geog eco;
	by codice_comune__str;
run;
proc means data = eco_g noprint;
	class territorio;
	types territorio;
	output out = regionale_precedente (drop = _type_ _freq_)
		   sum(red19) = reddito_stima_preced;
run;

PROC IMPORT OUT= WORK.reddito_istat 
            DATAFILE= "C:\Users\mcandi\OneDrive - KPMG\Desktop\project\SAS_scripts\Data_sets\quadratura_reddito.csv" 
            DBMS=CSV REPLACE;
     GETNAMES=YES;
     DATAROW=2; 
RUN;
data reddito_istat;
	attrib territorio length=$40 format=$40. informat=$40.;
	set reddito_istat;
	territorio = upcase(territorio);
	if territorio = "PROVINCIA AUTONOMA BOLZANO / BOZEN"
		then territorio = "BOLZANO";
	if territorio = "PROVINCIA AUTONOMA TRENTO"
		then territorio = "TRENTO";
	if territorio = "VALLE D'AOSTA / VALLÃ©E D'AOSTE"
		then territorio = "VALLE D'AOSTA";
	rename reddito_2019 = reddito_istat_preced
		   reddito_2020 = reddito_istat_ultimo;
run;
proc sort data = reddito_istat;
	by territorio;
run;
data confronto;
	merge regionale_precedente (in = sele) reddito_istat;
	by territorio;
	if sele;
	difperc = 100*(reddito_stima_preced - reddito_istat_preced)/reddito_istat_preced;
	drop _ itter107;
run;
proc sort data = confronto;
	by difperc;
run;
title2 "REDDITO REGIONALE";
proc print data = confronto;
	format reddito_stima_preced reddito_istat_preced reddito_istat_ultimo comma18.;
	sum reddito_stima_preced reddito_istat_preced reddito_istat_ultimo;
run;


data anacom;
	set ter_out.geografica_comune;
	keep codice_comune__str nome_comune nome_provincia sigla_provincia nome_regione codice_area_nielsen;
run;
proc sort data = anacom;
	by codice_comune__str;
run;

proc means data = ter_out.Popolazione_eta_sesso_comune noprint;
	class codice_comune__str;
	types codice_comune__str;
	output out = popolazione_ultima (drop = _type_ _freq_)
		   sum(popolazione) = ;
run;
data popolazione_precedente;
	set ter.demo20b;
	keep codc620b pop19;
	rename codc620b = codice_comune__str
		   pop19 = popolazione_precedente;
run;
proc sort data = popolazione_precedente;
	by codice_comune__str;
run;

data eco;
	set ter.econom20b;
	keep codc620b red19 medres19;
	rename codc620b = codice_comune__str
		   red19 = reddito_precedente
		   medres19 = prezzi_precedenti;
run;
proc sort data = eco;
	by codice_comune__str;
run;
data ecos;
	set ter.immobiliare_straordinaria20b;
	keep codc620b medres20;
	rename codc620b = codice_comune__str
		   medres20 = prezzi_correnti;
run;
proc sort data = ecos;
	by codice_comune__str;
run;

data fisco;
	set ter_out.reddito_fiscale_comune;
	keep codice_comune__str reddito_tot_fasce_amm;
	rename reddito_tot_fasce_amm = reddito_fiscale;
run;
proc sort data = fisco;
	by codice_comune__str;
run;
data mancante;
	set fisco;
	if reddito_fiscale in (0, . );
run; *vuoto;

data auto;
	set ter_out.parco_veicolare_comune;
	keep codice_comune__str euro_0 euro_1 euro_2 euro_3 euro_4 euro_5 euro_6;
run;
proc sort data = auto;
	by codice_comune__str;
run;

data prod;
	set ter.produt20b;
	keep codc620b fatt_1-fatt_6;
	rename codc620b = codice_comune__str;
run;
proc sort data = prod;
	by codice_comune__str;
run;

data indicatore_va;
	set appo.comunale_va;
	keep codice_comune__str variazione_va;
run;
proc sort data = indicatore_va;
	by codice_comune__str;
run;
title2 "DISTRIBUZIONE INDICATORE ECONOMICO (VARIAZIONE V.A.)";
proc univariate data = indicatore_va;
	var variazione_va;
	histogram variazione_va;
run;

data base;
	merge anacom geog (keep = codice_comune__str territorio)
		  popolazione_precedente popolazione_ultima eco ecos fisco auto prod indicatore_va;
	by codice_comune__str;
run;
%let vs = 
popolazione_precedente
popolazione
reddito_precedente
reddito_fiscale
euro_0 euro_1 euro_2 euro_3 euro_4 euro_5 euro_6
fatt_1 fatt_2 fatt_3 fatt_4 fatt_5 fatt_6;
title2 "TOTALI GRANDEZZE DI INPUT";
proc tabulate data = base;
	var &vs;
	table &vs,sum*f=comma18.;
run;

data controllo;
	set base;
	auto_euro_pop = sum(euro_0,euro_1,euro_2,euro_3,euro_4,euro_5,euro_6)/popolazione;
	tot_auto_euro = sum(euro_0,euro_1,euro_2,euro_3,euro_4,euro_5,euro_6);
	array euro(*) euro_0 euro_1 euro_2 euro_3 euro_4 euro_5 euro_6;
	array pct_euro (*) pct_euro_0 pct_euro_1 pct_euro_2 pct_euro_3 pct_euro_4 pct_euro_5 pct_euro_6;
	do i=1 to dim(euro);
		pct_euro(i) = 100*euro(i)/sum(euro_0,euro_1,euro_2,euro_3,euro_4,euro_5,euro_6);
	end;
	drop i;
run;
title2 "DISTRIBUZIONI RAPPORTI AUTO";
proc univariate data=controllo nextrobs = 20;
	var auto_euro_pop pct_euro_0 pct_euro_1 pct_euro_2 pct_euro_3 pct_euro_4 pct_euro_5 pct_euro_6;
	id codice_comune__str nome_comune sigla_provincia;
run;

data autonoleggio;
	set ter.Imprese_dettcom20b;
	if codateco2007 = '77.11.00' and tiposede = 'SL';
	rename codc620b = codice_comune__str;
run;
proc sort data = autonoleggio;
	by codice_comune__str;
run;
data autonoleggio;
	merge anacom autonoleggio (in = presente);
	by codice_comune__str;
	if presente;
run;
proc sort data = autonoleggio;
	by descending id_classe_dipendenti;
run;
title2 "STATISTICHE COMUNALI AUTONOLEGGI COMUNI ATTENZIONATI";
proc print data = autonoleggio;
	where nome_comune in ('AOSTA','BOLZANO','TRENTO','SCANDICCI');
run;

 (I sem. 2020 / II sem. 2019);
data base;
	set base;
	if prezzi_correnti > 0 and prezzi_precedenti > 0
		then rapporto_prezzi = prezzi_correnti/prezzi_precedenti;
	if 0 < rapporto_prezzi
		then rapporto_prezzi_q = rapporto_prezzi**2;
run;
title2 "DISTRIBUZIONE RAPPORTO PREZZI";
proc univariate data = base nextrobs = 20;
	var rapporto_prezzi rapporto_prezzi_q;
	id nome_comune sigla_provincia;
	histogram rapporto_prezzi rapporto_prezzi_q;
run;

proc univariate data = base noprint;
	var rapporto_prezzi;
	output out = estpre
		   pctlpre = p_
		   pctlname = alpre pctlpts = 99
		   pctlname = bapre pctlpts = 1;
run;
data _null_;
	set estpre;
	call symput('alpre',trim(left(p_alpre)));
	call symput('bapre',trim(left(p_bapre)));
run;
%put _user_;
data base;
	set base;
	rapporto_prezzi_n = rapporto_prezzi;
	if . < rapporto_prezzi < &bapre
		then rapporto_prezzi_n = mean(&bapre,rapporto_prezzi);
	if rapporto_prezzi > &alpre
		then rapporto_prezzi_n = mean(&alpre,rapporto_prezzi);
	drop rapporto_prezzi_q;
run;
title2 "RAPPORTO ORIGINALE E NORMALIZZATO";
proc gplot data = base;
	symbol1 i = none  v = dot c = black;
	plot rapporto_prezzi_n * rapporto_prezzi = 1;
run;
quit;
title2 "DISTRIBUZIONE RAPPORTO PREZZI NORMALIZZATO";
proc univariate data = base nextrobs = 20;
	var rapporto_prezzi_n;
	id nome_comune sigla_provincia;
	histogram rapporto_prezzi_n;
run;


proc sort data = base;
	by territorio;
run;
data correttivo;
	set confronto;
	correttivo = reddito_istat_preced/reddito_stima_preced;
	keep territorio correttivo;
run;
proc sort data = correttivo;
	by territorio;
run;
data base;
	merge base correttivo;
	by territorio;
run;

data base1;
	set base;
	reddito_precedente_q = correttivo*reddito_precedente;
	redproult = (1 + variazione_va/100)*reddito_precedente_q/popolazione_precedente;
	fispro = (1 + variazione_va/100)*reddito_fiscale/popolazione_precedente;
	redpro_prezzi = rapporto_prezzi_n*reddito_precedente_q/popolazione_precedente;
	fatt_per_mille_2 = 1000*sum(fatt_2,fatt_3,fatt_4,fatt_5,fatt_6)/popolazione;
	if fatt_per_mille_2 = 0 then fatt_per_mille_2 = . ;
	euro_per_mille_4 = 1000*sum(euro_4, euro_5, euro_6)/popolazione;
run;
title2 "CORRELAZIONI RAPPORTI DI INPUT";
proc corr data = base1;
	var redproult fispro prezzi_precedenti prezzi_correnti redpro_prezzi euro_per_mille_4 fatt_per_mille_2;
run;
title2 "TOTALE REDDITO PRECEDENTE RIQUADRATO (CONTROLLO)";
proc tabulate data = base1;
	var reddito_precedente_q;
	table reddito_precedente_q,sum*f=comma18.;
run;

proc means data = base1 noprint;
	weight popolazione;
	output out = medie (drop = _type_ _freq_)
	mean(redproult fispro redpro_prezzi euro_per_mille_4 fatt_per_mille_2) = /autoname;
run;

data medie;
	set medie;
	call symput('redproult_m',trim(redproult_mean));
	call symput('fispro_m',trim(fispro_mean));
	call symput('medres_m',trim(redpro_prezzi_mean));
	call symput('euro_per_mille_4_m',trim(euro_per_mille_4_mean));
	call symput ('fatt_per_mille_2_m',trim(fatt_per_mille_2_mean));
run;
%put _user_;
data base2;
	set base1;
	reddind = 100*redproult/&redproult_m.;
	fiscind = 100*fispro/&fispro_m.;
	if redpro_prezzi ~= . then prezind = 100*redpro_prezzi/&medres_m.;
	if euro_per_mille_4 ~= . then eurind = 100*euro_per_mille_4/&euro_per_mille_4_m.;
	if fatt_per_mille_2 ~= . then fattind = 100*fatt_per_mille_2/&fatt_per_mille_2_m.;
run;

title2 'DISTRIBUZIONE INDICE DEL REDDITO DISPONIBILE';
proc univariate data = base2 nextrobs = 10;
	var reddind;
	id codice_comune__str nome_comune sigla_provincia;
run;
title2 'DISTRIBUZIONE INDICE DEL REDDITO FISCALE';
proc univariate data = base2 nextrobs = 10;
	var fiscind;
	id codice_comune__str nome_comune sigla_provincia;
run;
title2 'DISTRIBUZIONE INDICE DEI PREZZI RESIDENZIALI';
proc univariate data = base2 nextrobs = 10;
	var prezind;
	id codice_comune__str nome_comune sigla_provincia;
run;
title2 'DISTRIBUZIONE INDICE DELLE CATEGORIE AUTO (EURO)';
proc univariate data = base2 nextrobs = 10;
	var eurind;
	id codice_comune__str nome_comune sigla_provincia;
run;
title2 'DISTRIBUZIONE INDICE FATTURATO';
proc univariate data = base2 nextrobs = 10;
	var fattind;
	id codice_comune__str nome_comune sigla_provincia;
run;

title2 "CONFRONTO DISTRIBUZIONI INDICI";
proc tabulate data = base2;
	var reddind fiscind prezind eurind fattind;
	table n*f=comma12. (max p99 p95 p90 p75 p50 p25 p10 p5 p1 min)*f=12.1,
		  reddind fiscind prezind eurind fattind;
run;

data base2;
	set base2;
	drop euro_0 euro_1 euro_2 euro_3 euro_4 euro_5 euro_6
		 fatt_1 fatt_2 fatt_3 fatt_4 fatt_5 fatt_6;
run;


proc univariate data = base2 noprint;
	var fiscind;
	output out = estfisc
		   pctlpre = ed
		   pctlname = p99 pctlpts = 99
		   pctlname = p1 pctlpts = 1;
run;
data estfisc;
	set estfisc;
	ponte = 1;
run;
data base2b;
	set base2;
	ponte = 1;
run;
data base2b;
	merge base2b estfisc;
	by ponte;
	if . < fiscind < edp1
		then norfiscind = sum(0.50*edp1,0.50*fiscind);
	else if fiscind > edp99
		then norfiscind = sum(0.4*edp99,0.6*fiscind);
	else norfiscind = fiscind;
	drop ponte edp1 edp99;
run;
title2 "INDICE REDDITO FISCALE NORMALIZZATO E NON";
proc gplot data = base2b;
	symbol1 i = none  v = dot c = black;
	plot norfiscind * fiscind = 1;
run;
quit;
title2 'DISTRIBUZIONE INDICE DEL REDDITO FISCALE NORMALIZZATO';
proc univariate data = base2b nextrobs = 10;
	var norfiscind;
	id codice_comune__str nome_comune sigla_provincia;
	histogram norfiscind;
run;
proc means data = base2b noprint;
	weight popolazione;
	output out = media1d (drop = _type_ _freq_)
		   mean(norfiscind) = /autoname;
run;
data media1d;
	set media1d;
	call symput('norfiscind_m',trim(norfiscind_mean));
run;
%put _user_;
data base2c;
	set base2b;
	newfiscind = 100*norfiscind/&norfiscind_m.;
	drop fiscind norfiscind;
run;
title2 'DISTRIBUZIONE INDICE DEL REDDITO FISCALE RETTIFICATO';
proc univariate data = base2c nextrobs = 10;
	var newfiscind;
	id codice_comune__str nome_comune sigla_provincia;
run;

 del reddito precedente corretto con la variazione dei prezzi
 e non un indice dei prezzi;

data base2d;
	set base2c;
	newpreind = prezind;
	drop prezind;
run;


proc univariate data = base2 noprint;
	var eurind;
	output out = esteur
		   pctlpre = ed
		   pctlname = p99 pctlpts = 99
		   pctlname = p1 pctlpts = 1;
run;
data esteur;
	set esteur;
	ponte = 1;
run;
data base2d;
	set base2d;
	ponte = 1;
run;
data base2d;
	merge base2d esteur;
	by ponte;
	if . < eurind < edp1
		then noreurind = sum(0.50*edp1,0.50*eurind);
	else if eurind > edp99
		then noreurind = sum(0.90*edp99,0.10*eurind);
	else noreurind = eurind;
	drop ponte edp1 edp99;
run;
title2 "INDICE AUTO EURO NORMALIZZATO E NON";
proc gplot data = base2d;
	symbol1 i = none  v = dot c = black;
	plot noreurind * eurind = 1;
run;
quit;
title2 'DISTRIBUZIONE INDICE EUR NORMALIZZATO';
proc univariate data = base2d nextrobs = 10;
	var noreurind;
	id codice_comune__str nome_comune sigla_provincia;
run;
proc means data = base2d noprint;
	weight popolazione;
	output out = media1f (drop = _type_ _freq_)
		   mean(noreurind) = /autoname autolabel;
run;
data media1f;
	set media1f;
	call symput('noreurind_m',trim(noreurind_mean));
run;
%put _user_;
data base2e;
	set base2d;
	neweurind = 100*noreurind/&noreurind_m.;
	drop eurind noreurind;
run;
title2 'DISTRIBUZIONE INDICE EURO RETTIFICATO';
proc univariate data = base2e nextrobs = 10;
	var neweurind;
	id codice_comune__str nome_comune sigla_provincia;
run;


proc univariate data = base2 noprint;
	var fattind;
	output out = estfat
		   pctlpre = ed
		   pctlname = p95 pctlpts = 95
		   pctlname = p5 pctlpts = 5;
run;
data estfat;
	set estfat;
	ponte = 1;
run;
data base2e;
	set base2e;
	ponte = 1;
run;
data base2f;
	merge base2e estfat;
	by ponte;
	if . < fattind < edp5
		then norfatind = sum(0.95*edp5,0.05*fattind);
	else if fattind > edp95
		then norfatind = sum(0.95*edp95,0.05*fattind);
	else norfatind = fattind;
	drop ponte edp5 edp95;
run;
title2 "INDICE FATTURATO NORMALIZZATO E NON";
proc gplot data = base2f;
	symbol1 i = none  v = dot c = black;
	plot norfatind * fattind = 1;
run;
quit;
title2 'DISTRIBUZIONE INDICE DEL FATTURATO NORMALIZZATO';
proc univariate data = base2f nextrobs = 10;
	var norfatind;
	id codice_comune__str nome_comune sigla_provincia;
run;
proc means data = base2f noprint;
	weight popolazione;
	output out = media1t (drop = _type_ _freq_)
		   mean(norfatind) = /autoname;
run;
data media1t;
	set media1t;
	call symput('norfatind_m',trim(norfatind_mean));
run;
%put _user_;
data base2g;
	set base2f;
	newfatind = 100*norfatind/&norfatind_m.;
	drop fattind norfatind;
run;
title2 'DISTRIBUZIONE INDICE DEL FATTURATO RETTIFICATO';
proc univariate data = base2g nextrobs = 10;
	var newfatind;
	id codice_comune__str nome_comune sigla_provincia;
run;

title2 "CONFRONTO DISTRIBUZIONI INDICI DOPO NORMALIZZAZIONE";
proc tabulate data = base2g;
	var reddind newfiscind newpreind neweurind newfatind;
	table n*f=comma12. (max p99 p95 p90 p75 p50 p25 p10 p5 p1 min)*f=12.1,
		  reddind newfiscind newpreind neweurind newfatind;
run;

proc rank data = base2g out = base5 groups = 100;
	var reddind;
	ranks r_red;
run;
proc sort data = base5;
	by r_red;
run;
proc means data = base5 noprint;
	where r_red > 0;
	by r_red;
	output out = minimi (drop = _type_ _freq_)
		   min(reddind) = minimo;
run;
proc transpose data = minimi
			   out = minimit (drop = _NAME_)
			   prefix = pre;
	id r_red;
	var minimo;
run;
data base6;
	set base5;
	ponte = 1;
run;
data minimit;
	set minimit;
	ponte = 1;
run;
data base6;
	merge base6 minimit;
	by ponte;
	drop ponte;
run;

%macro assegnoranking(dentro,fuori,variabile);
data &fuori.;
	set &dentro.;
	array estremo{99} pre1-pre99;
	if . < &variabile. < pre1
		then r_&variabile. = 0;
	do i = 2 to 99;
		if estremo{i-1} <= &variabile. < estremo{i}
			then r_&variabile. = i-1;
	if &variabile. >= pre99
		then r_&variabile. = 99;
	end;
	drop i;
run;
%mend assegnoranking;
%assegnoranking(base6,base7,reddind); 
data controllo;
	set base7;
	if r_red ~= r_reddind;
run;
%assegnoranking(base7,base7,newfiscind);
%assegnoranking(base7,base7,newpreind);
%assegnoranking(base7,base7,neweurind);
%assegnoranking(base7,base7,newfatind);

data base8;
	set base7;
	max_r = max(r_red,r_newfiscind,r_newpreind,r_neweurind,r_newfatind);
	min_r = min(r_red,r_newfiscind,r_newpreind,r_neweurind,r_newfatind);
	scarto_r = max_r - min_r;
	rename r_newfiscind = r_fis
		   r_newpreind = r_pre
		   r_neweurind = r_eur
		   r_newfatind = r_fatt;
	drop pre1-pre99 r_reddind;
run;
title2 'CORRELAZIONE PUNTEGGI';
proc corr data = base8;
	var r_red r_fis r_pre r_eur r_fatt;
run;

title2 'DISTRIBUZIONE SCARTI PUNTEGGI INDICI';
proc univariate data = base8 nextrobs = 10;
	var scarto_r;
	id codice_comune__str nome_comune sigla_provincia;
run;
proc sort data = base8;
	by descending scarto_r;
run;
data ctscarto_r;	*data set di controllo;
	set base8;
	keep codice_comune__str nome_comune sigla_provincia popolazione
		 r_red r_fis r_pre r_eur r_fatt scarto_r;
run;


data basestima0a;
	set base8;

	array punteggio{3} r_pre r_eur r_fatt;
	array depurato{3} dep_pre dep_eur dep_fatt;
	array indicein{3} newpreind neweurind newfatind;
	array indiceout{3} predef eurdef fattdef;
	array peso{3} p_pre p_eur p_fat;

	do i = 1 to 3;
		depurato{i} = punteggio{i};
		indiceout{i} = indicein{i};
	end;

	numind = N(predef,eurdef,fattdef);
	do k = 1 to 84;
		soglia = 100 - k;
		do j = 3 to 1 by -1;
			if depurato{j} ~= . 
			and abs(depurato{j} - r_red) > soglia
			and abs(depurato{j} - r_fis) > soglia
			and numind >= 2
				then do;
					depurato{j} = . ;
					indiceout{j} = . ;
					numind = N(predef,eurdef,fattdef);
				end;
		end;
	end;
	
	rif = mean(r_red,r_fis);
	do h = 1 to 3;
		if depurato{h} ~= . 
			then peso{h} = 100/(abs(depurato{h} - rif) + 1);
	end;

	numindout = N(predef,eurdef,fattdef);
	rename reddind = reddef
		   newfiscind = fisdef;
	drop i j k h;
run;
title2 "FREQUENZE NUMERI INDICI UTILIZZABILI";
proc tabulate data = basestima0a;
	class numindout;
	var dep_pre dep_eur dep_fatt;
	table numindout all,n*f=comma12. (dep_pre dep_eur dep_fatt)*n*f=comma12. /nocellmerge;
run;

data basestima1;
	set basestima0a;
	ausmedia = sum(predef*p_pre,eurdef*p_eur,fattdef*p_fat)/sum(p_pre,p_eur,p_fat);
	newmedind = mean(reddef,fisdef,ausmedia);
run;
data manc;
	set basestima1;
	if ausmedia = . ;
run; *vuoto;
title2 "INDICE NUOVA STIMA RISPETTO A PRECEDENTE CON CORRETTIVI";
proc gplot data = basestima1;
	symbol1 i = none  v = dot c = black;
	plot newmedind * reddef = 1;
run;
quit;

data quadra;
	set confronto;
	keep territorio reddito_istat_ultimo;
run;

proc means data = quadra noprint;
	output out = rednaz (drop = _type_ _freq_)
		   sum(reddito_istat_ultimo) = redita;
run;
proc means data = basestima1 noprint;
	output out = popnaz (drop = _type_ _freq_)
		   sum(popolazione) = popita;
run;
data italia;
	set rednaz;
	set popnaz;
	redproit = redita/popita;
	call symput('proit',trim(redproit));
run;
%put _user_;
data basestima1a;
	set basestima1;
	medst = popolazione*&proit.*newmedind/100;
run;
title2 "TOTALE DELLE STIME PRIMA DELLA QUADRATURA";
proc tabulate data = basestima1a;
	var medst;
	table medst,sum*f=comma18.;
run;

%quadraturagruppo(basestima1a,	
				  medst,		
				  quadra,		
				  reddito_istat_ultimo,	
				  stima_qua,	
				  territorio,	
				  qua1);		
data qua2;
	set qua1;
	stima_qua = round(stima_qua);
run;
%arrotondainterogruppo(qua2,		
					   stima_qua,	
					   quadra,		
					   reddito_istat_ultimo,	
					   territorio,	
					   qua3);		

title2 "TOTALI REGIONALI";
proc tabulate data = qua3;
	class territorio;
	var stima_qua;
	table territorio all,stima_qua*sum*f = comma18.3 /nocellmerge;
run;

data stima_varia;
	set qua3;
	redpro_ult = stima_qua/popolazione;
	redpro_pre = reddito_precedente/popolazione_precedente;
	redpro_pre_q = reddito_precedente_q/popolazione_precedente;
	varia_effettiva = 100*((redpro_ult/redpro_pre) - 1);
	varia_q = 100*((redpro_ult/redpro_pre_q) - 1);
	rename stima_qua = reddito;
run;
title2 "VARIAZIONE DELLE STIME COMUNALI RISPETTO ALLE STIME PRECEDENTI";
proc univariate data = stima_varia nextrobs = 40;
	var varia_effettiva;
	id codice_comune__str nome_comune sigla_provincia redpro_ult redpro_pre redpro_pre_q;
	histogram varia_effettiva;
run;
title2 "VARIAZIONE DELLE STIME COMUNALI RISPETTO ALLE STIME PRECEDENTI RETTIFICATE";
proc univariate data = stima_varia nextrobs = 40;
	var varia_q;
	id codice_comune__str nome_comune sigla_provincia redpro_ult redpro_pre redpro_pre_q;
	histogram varia_q ;
run;
title2 "VARIAZIONE DELLE STIME COMUNALI RISPETTO ALLE STIME PRECEDENTI RETTIFICATE";
title3 "COMUNI MEDIO-GRANDI";
proc univariate data = stima_varia nextrobs = 40;
	where popolazione >= 50000;
	var varia_q;
	id codice_comune__str nome_comune sigla_provincia redpro_ult redpro_pre redpro_pre_q;
	histogram varia_q ;
run;
title2 'REDDITO PRO CAPITE NUOVO';
proc univariate data = stima_varia nextrobs = 10;
	var redpro_ult;
	id codice_comune__str nome_comune sigla_provincia;
	histogram redpro_ult;
run;
title2 'REDDITO PRO CAPITE PRECEDENTE';
proc univariate data = stima_varia nextrobs = 10;
	var redpro_pre;
	id codice_comune__str nome_comune sigla_provincia;	
	histogram redpro_pre;
run;

proc univariate data = stima_varia noprint;
	var varia_q;
	output out = estremi
		   pctlpre = p_
		   pctlname = alto pctlpts = 99
		   pctlname = basso pctlpts = 1;
run;
data _null_;
	set estremi;
	call symput('alto',trim(left(p_alto)));
	call symput('basso',trim(left(p_basso)));
run;
%put _user_;
data stima_norma;
	set stima_varia;
	varia_n = varia_q;
	if varia_q > &alto
		then varia_n = sum(.9*&alto,.1*varia_q);
	if varia_q < &basso
		then varia_n = sum(.5*&basso,.5*varia_q);
run;
title2 "VARIAZIONE ORIGINALE E NORMALIZZATA";
proc gplot data = stima_norma;
	symbol1 i = none  v = dot c = black;
	plot varia_n * varia_q = 1;
run;
quit;
data stima_norma;
	set stima_norma;
	stima_n = reddito;
	if varia_q < &basso or varia_q > &alto
		then stima_n = redpro_pre_q*(1 + varia_n/100)*popolazione;
	drop reddito redpro_ult redpro_pre redpro_pre_q varia_effettiva varia_q;
run;

%quadraturagruppo(stima_norma,	
				  stima_n,		
				  quadra,		
				  reddito_istat_ultimo,	
				  stima_qua,	
				  territorio,	
				  qua12);		
data qua22;
	set qua12;
	stima_qua = round(stima_qua);
run;
%arrotondainterogruppo(qua22,		
					   stima_qua,	
					   quadra,		
					   reddito_istat_ultimo,	
					   territorio,	
					   qua32);		

title2 "TOTALI REGIONALI";
proc tabulate data = qua3;
	class territorio;
	var stima_qua;
	table territorio all,stima_qua*sum*f = comma18.3 /nocellmerge;
run;

data stima_varia_bis;
	set qua32;
	redpro_ult = stima_qua/popolazione;
	redpro_pre = reddito_precedente/popolazione_precedente;
	redpro_pre_q = reddito_precedente_q/popolazione_precedente;
	varia_effettiva = 100*((redpro_ult/redpro_pre) - 1);
	varia_q = 100*((redpro_ult/redpro_pre_q) - 1);
	rename stima_qua = reddito;
run;
title2 "VARIAZIONE DELLE STIME COMUNALI RISPETTO ALLE STIME PRECEDENTI";
proc univariate data = stima_varia_bis nextrobs = 40;
	var varia_effettiva;
	id codice_comune__str nome_comune sigla_provincia redpro_ult redpro_pre redpro_pre_q;
	histogram varia_effettiva;
run;
title2 "VARIAZIONE DELLE STIME COMUNALI RISPETTO ALLE STIME PRECEDENTI RETTIFICATE";
proc univariate data = stima_varia_bis nextrobs = 40;
	var varia_q;
	id codice_comune__str nome_comune sigla_provincia redpro_ult redpro_pre redpro_pre_q popolazione;
	histogram varia_q ;
run;
title2 "VARIAZIONE DELLE STIME COMUNALI RISPETTO ALLE STIME PRECEDENTI RETTIFICATE";
title3 "COMUNI MEDIO-GRANDI";
proc univariate data = stima_varia_bis nextrobs = 40;
	where popolazione >= 50000;
	var varia_q;
	id codice_comune__str nome_comune sigla_provincia redpro_ult redpro_pre redpro_pre_q;
	histogram varia_q ;
run;
title2 'REDDITO PRO CAPITE NUOVO';
proc univariate data = stima_varia_bis nextrobs = 20;
	var redpro_ult;
	id codice_comune__str nome_comune sigla_provincia redpro_pre_q;
	histogram redpro_ult;
run;
title2 'REDDITO PRO CAPITE PRECEDENTE';
proc univariate data = stima_varia_bis nextrobs = 10;
	var redpro_pre;
	id codice_comune__str nome_comune sigla_provincia;	
	histogram redpro_pre;
run;

proc rank data = stima_varia_bis out = stima_varia_ok groups = 10;
	var redpro_ult redpro_pre_q;
	ranks rank_ult rank_pre;
run;
title2 "CONFRONTO RANKING REDDITO PRO CAPITE";
proc freq data = stima_varia_ok;
	table rank_ult*rank_pre /nopercent norow nocol;
run;
proc rank data = stima_varia_bis out = stima_varia_ok_g groups = 10;
	where popolazione >= 50000;
	var redpro_ult redpro_pre_Q;
	ranks rank_ult rank_pre;
run;
title2 "CONFRONTO RANKING REDDITO PRO CAPITE";
title3 "COMUNI MEDIO-GRANDI";
proc freq data = stima_varia_ok_g;
	table rank_ult*rank_pre /nopercent norow nocol;
run;

data risultato;
	set stima_varia_ok (keep = codice_comune__str reddito);
	anno_riferimento = 2020;
	release = 2021;
run;


assistant
Here is the equivalent Python code equivalent to the SAS code provided, along with comments:

```python
import pandas as pd
import numpy as np
import os

# Define the file paths
ter_path = "C:/Users/mcandi/OneDrive - KPMG/Desktop/project/SAS_scripts/Data_sets"
sez_path = "C:/Users/mcandi/OneDrive - KPMG/Desktop/project/SAS_scripts/Data_sets"
ter_out_path = "C:/Users/mcandi/OneDrive - KPMG/Desktop/project/SAS_scripts/Data_sets"
sez_out_path = "C:/Users/mcandi/OneDrive - KPMG/Desktop/project/SAS_scripts/Data_sets"
appo_path = "C:/Users/mcandi/OneDrive - KPMG/Desktop/project/SAS_scripts/Data_sets"

# Set the options for Python
pd.set_option('merge_with_tolerance', False)
pd.set_option('mode.use_inf_as_null', True)

# Load the macro files
with open(os.path.join(ter_path, "Macro/macroquadraturagruppo.sas"), "r") as macro_file:
    macroquadraturagruppo = macro_file.read()

with open(os.path.join(ter_path, "Macro/macroarrotondainterogruppo.sas"), "r") as macro_file:
    macroarrotondainterogruppo = macro_file.read()

# Set the titles
print("STIMA COMUNALE DEL REDDITO")

# Read the geographical data
geog = pd.read_sas(os.path.join(ter_out_path, "geografica_comune.sas7bdat"))
geog['territory'] = geog.apply(lambda x: x['nome_provincia'] if x['nome_regione'] == "TRENTINO-ALTO ADIGE" else x['nome_regione'], axis=1)
geog = geog[['codice_comune__str', 'territory', 'nome_regione']]

# Frequency table for territorial areas and regions
print(geog.groupby(['territory', 'nome_regione']).size())

# Sort data by community code
geog = geog.sort_values(by='codice_comune__str')

# Read the economic data
eco = pd.read_sas(os.path.join(ter_path, "econom20b.sas7bdat"))
eco = eco[['codc620b', 'red19']]
eco = eco.rename(columns={'codc620b': 'codice_comune__str'})

# Sort data by community code
eco = eco.sort_values(by='codice_comune__str')

# Merge economic data with geographical data
eco_g = pd.merge(geog, eco, on='codice_comune__str')

# Compute aggregated statistics for regions
regionale_precedente = eco_g.groupby('territory').agg({'red19': 'sum'}).reset_index()
regionale_precedente.columns = ['territory', 'reddito_stima_preced']

# Read the redito_istat data
reddito_istat = pd.read_csv(os.path.join(ter_path, "quadratura_reddito.csv"), sep=',', skiprows=1)
reddito_istat['territory'] = reddito_istat['territory'].apply(lambda x: x.upper())
reddito_istat['territory'] = reddito_istat['territory'].replace('PROVINCIA AUTONOMA BOLZANO / BOZEN', 'BOLZANO')
reddito_istat['territory'] = reddito_istat['territory'].replace('PROVINCIA AUTONOMA TRENTO', 'TRENTO')
reddito_istat['territory'] = reddito_istat['territory'].replace('VALLE D\'AOSTA / VALLÃ©E D\'AOSTE', 'VALLE D\'AOSTA')
reddito_istat = reddito_istat.rename(columns={'reddito_2019': 'reddito_istat_preced', 'reddito_2020': 'reddito_istat_ultimo'})

# Sort data by territory
reddito_istat = reddito_istat.sort_values(by='territory')

# Merge regional statistics with redito_istat
confronto = pd.merge(regionale_precedente, reddito_istat, on='territory')
confronto['difperc'] = 100 * (confronto['reddito_stima_preced'] - confronto['reddito_istat_preced']) / confronto['reddito_istat_preced']

# Print the data with percentage difference
print(confronto.sort_values(by='difperc'))

# Read the geographical data for ANACom
anacom = pd.read_sas(os.path.join(ter_out_path, "geografica_comune.sas7bdat"))

# Merge with geog data and remove duplicates
anacom = pd.merge(anacom, geog[['codice_comune__str', 'territory']], on='codice_comune__str', how='left')

# Read the population data for last year
popolazione_ultima = pd.read_sas(os.path.join(ter_out_path, "Popolazione_eta_sesso_comune.sas7bdat"))

# Merge with eco_g data
popolazione_precedente = pd.read_sas(os.path.join(ter_path, "demo20b.sas7bdat"))
popolazione_precedente = popolazione_precedente[['codc620b', 'pop19']]
popolazione_precedente = popolazione_precedente.rename(columns={'codc620b': 'codice_comune__str', 'pop19': 'popolazione_precedente'})

# Merge with eco data
eco = pd.read_sas(os.path.join(ter_path, "econom20b.sas7bdat"))
eco = eco[['codc620b', 'red19', 'medres19']]
eco = eco.rename(columns={'codc620b': 'codice_comune__str', 'red19': 'reddito_precedente', 'medres19': 'prezzi_precedenti'})

# Merge with ecos data
ecos = pd.read_sas(os.path.join(ter_path, "immobiliare_straordinaria20b.sas7bdat"))
ecos = ecos[['codc620b', 'medres20']]
ecos = ecos.rename(columns={'codc620b': 'codice_comune__str', 'medres20': 'prezzi_correnti'})

# Merge with fisco data
fisco = pd.read_sas(os.path.join(ter_out_path, "reddito_fiscale_comune.sas7bdat"))
fisco = fisco[['codice_comune__str', 'reddito_tot_fasce_amm']]
fisco = fisco.rename(columns={'reddito_tot_fasce_amm': 'reddito_fiscale'})

# Drop rows with zero fiscal income
mancante = fisco[fisco['reddito_fiscale'] == 0]
mancante = mancato.dropna()  # Remove missing values

# Merge with auto data
auto = pd.read_sas(os.path.join(ter_out_path, "parco_veicolare_comune.sas7bdat"))
auto = auto[['codc620b', 'euro_0', 'euro_1', 'euro_2', 'euro_3', 'euro_4', 'euro_5', 'euro_6']]

# Merge with prod data
prod = pd.read_sas(os.path.join(ter_path, "produt20b.sas7bdat"))
prod = prod[['codc620b', 'fatt_1-fatt_6']]
prod = prod.rename(columns={'codc620b': 'codice_comune__str'})

# Merge with indicatore_va data
indicatore_va = pd.read_csv(os.path.join(appo_path, "comunale_va.csv"), sep=',')

# Merge with anacom data
base = pd.merge(anacom, geog, on='codice_comune__str', how='left')
base = pd.merge(base, popolazione_precedente, on='codice_comune__str', how='left')
base = pd.merge(base, popolazione_ultima, on='codice_comune__str', how='left')
base = pd.merge(base, eco, on='codice_comune__str', how='left')
base = pd.merge(base, ecos, on='codice_comune__str', how='left')
base = pd.merge(base, fisco, on='codice_comune__str', how='left')
base = pd.merge(base, auto, on='codice_comune__str', how='left')
base = pd.merge(base, prod, on='codice_comune__str', how='left')
base = pd.merge(base, indicatore_va, on='codice_comune__str', how='left')

# List of variables for totals
vs = ['popolazione_precedente', 'popolazione', 'reddito_precedente', 'reddito_fiscale', 'euro_0', 'euro_1', 'euro_2', 'euro_3', 'euro_4', 'euro_5', 'euro_6', 'fatt_1', 'fatt_2', 'fatt_3', 'fatt_4', 'fatt_5', 'fatt_6']

# Print total input variables
print("TOTALI GRANDEZZE DI INPUT")
print(base.groupby(vs).agg({'popolazione_precedente': 'sum'}).reset_index())

# Compute percentages of euro categories
base['auto_euro_pop'] = base.apply(lambda x: x['euro_0'] + x['euro_1'] + x['euro_2'] + x['euro_3'] + x['euro_4'] + x['euro_5'] + x['euro_6'] / x['popolazione'], axis=1)
base['tot_auto_euro'] = base.apply(lambda x: x['euro_0'] + x['euro_1'] + x['euro_2'] + x['euro_3'] + x['euro_4'] + x['euro_5'] + x['euro_6'], axis=1)

# Compute percentages of euro categories and create additional columns
base['euro_per_mille_4'] = 1000 * base['euro_4'] + 1000 * base['euro_5'] + 1000 * base['euro_6']
base['fatt_per_mille_2'] = 1000 * base['fatt_2'] + 1000 * base['fatt_3'] + 1000 * base['fatt_4'] + 1000 * base['fatt_5'] + 1000 * base['fatt_6']

# Drop unnecessary columns
base = base.drop(columns=['euro_0', 'euro_1', 'euro_2', 'euro_3', 'euro_4', 'euro_5', 'euro_6', 'fatt_1', 'fatt_2', 'fatt_3', 'fatt_4', 'fatt_5', 'fatt_6'])

# Calculate price ratio
base['rapporto_prezzi'] = base['prezzi_correnti'] / base['prezzi_precedenti']
base['rapporto_prezzi_q'] = base['rapporto_prezzi'] ** 2

# Calculate price ratio with statistical percentiles
estpre = base.describe(percentiles=[0.99, 0.1])
base['alpre'] = estpre['rapporto_prezzi']['99%']
base['bapre'] = estpre['rapporto_prezzi']['1%']

# Apply percentile cutoff to price ratio
base['rapporto_prezzi_n'] = base.apply(lambda x: x['rapporto_prezzi'] if x['rapporto_prezzi'] >= x['alpre'] and x['rapporto_prezzi'] <= x['bapre'] else np.mean([x['alpre'], x['rapporto_prezzi']]), axis=1)

# Plot price ratio before and after normalization
import matplotlib.pyplot as plt
plt.scatter(base['rapporto_prezzi_n'], base['rapporto_prezzi'])
plt.xlabel('Normalized Price Ratio')
plt.ylabel('Price Ratio')
plt.title('Price Ratio Before and After Normalization')
plt.show()

# Plot histogram of normalized price ratio
plt.hist(base['rapporto_prezzi_n'], bins=50)
plt.xlabel('Normalized Price Ratio')
plt.ylabel('Frequency')
plt.title('Histogram of Normalized Price Ratio')
plt.show()

# Calculate corrected prices
base['correttivo'] = base['reddito_istat_preced'] / base['reddito_stima_preced']

# Merge corrected prices with base data
base = pd.merge(base, correttivo, on='territory')

# Calculate corrected prices after adjustments
base['reddito_precedente_q'] = base['correttivo'] * base['reddito_precedente']
base['redproult'] = (1 + base['variazione_va'] / 100) * base['reddito_precedente_q'] / base['popolazione_precedente']
base['fispro'] = (1 + base['variazione_va'] / 100) * base['reddito_fiscale'] / base['popolazione_precedente']
base['redpro_prezzi'] = base['rapporto_prezzi_n'] * base['reddito_precedente_q'] / base['popolazione_precedente']
base['fatt_per_mille_2'] = 1000 * (base['fatt_2'] + base['fatt_3'] + base['fatt_4'] + base['fatt_5'] + base['fatt_6']) / base['popolazione']
base['fatt_per_mille_2'] = base['fatt_per_mille_2'].replace(0, np.nan)

# Calculate percentages and create additional columns
base['euro_per_mille_4'] = 1000 * (base['euro_4'] + base['euro_5'] + base['euro_6']) / base['popolazione']
base['euro_per_mille_4'] = base['euro_per_mille_4'].replace(0, np.nan)

# Plot correlation between indices
pd.plotting.scatter_matrix(base[['redproult', 'fispro', 'prezzi_precedenti', 'prezzi_correnti', 'redpro_prezzi', 'euro_per_mille_4', 'fatt_per_mille_2']])
plt.show()

# Calculate total redito_precedente_q
base['reddito_precedente_q'] = base['reddito_precedente_q'].sum()

# Calculate mean of indices
media1d = base.groupby('popolazione').agg({'redproult': 'mean', 'fispro': 'mean', 'redpro_prezzi': 'mean', 'euro_per_mille_4': 'mean', 'fatt_per_mille_2': 'mean'}).reset_index()

# Calculate indices as percentages from mean
media1d['redproult_m'] = media1d['redproult'].mean()
media1d['fispro_m'] = media1d['fispro'].mean()
media1d['medres_m'] = media1d['redpro_prezzi'].mean()
media1d['euro_per_mille_4_m'] = media1d['euro_per_mille_4'].mean()
media1d['fatt_per_mille_2_m'] = media1d['fatt_per_mille_2'].mean()

# Calculate indexed variables
base['reddind'] = 100 * base['redproult'] / media1d['redproult_m']
base['fiscind'] = 100 * base['fispro'] / media1d['fispro_m']
base['prezind'] = 100 * base['redpro_prezzi'] / media1d['medres_m']
base['eurind'] = 100 * base['euro_per_mille_4'] / media1d['euro_per_mille_4_m']
base['fattind'] = 100 * base['fatt_per_mille_2'] / media1d['fatt_per_mille_2_m']

# Plot frequency of indexed variables
base['reddind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Indexed Variable')
plt.show()

# Plot frequency of indexed variables
base['fiscind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Indexed Variable')
plt.show()

# Plot frequency of indexed variables
base['prezind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Indexed Variable')
plt.show()

# Plot frequency of indexed variables
base['eurind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Indexed Variable')
plt.show()

# Plot frequency of indexed variables
base['fattind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Indexed Variable')
plt.show()

# Plot correlation between indexed variables
pd.plotting.scatter_matrix(base[['reddind', 'fiscind', 'prezind', 'eurind', 'fattind']])
plt.show()

# Merge normalized indices with base data
base2 = pd.merge(base, media1d, on='popolazione')

# Calculate indexed variables using the mean
base2['newfiscind'] = 100 * base2['norfiscind'] / base2['norfiscind_m']
base2['newpreind'] = base2['newpreind']
base2['neweurind'] = 100 * base2['noreurind'] / base2['noreurind_m']
base2['newfatind'] = 100 * base2['norfatind'] / base2['norfatind_m']

# Plot frequency of reindexed variables
base2['newfiscind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Reindexed Variable')
plt.show()

# Plot frequency of reindexed variables
base2['newpreind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Reindexed Variable')
plt.show()

# Plot frequency of reindexed variables
base2['neweurind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Reindexed Variable')
plt.show()

# Plot frequency of reindexed variables
base2['newfatind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Reindexed Variable')
plt.show()

# Calculate reindexed mean of indices
media1t = base2.groupby('popolazione').agg({'newfiscind': 'mean', 'newpreind': 'mean', 'neweurind': 'mean', 'newfatind': 'mean'}).reset_index()

# Calculate reindexed indices as percentages from mean
media1t['norfiscind_m'] = media1t['newfiscind'].mean()
media1t['noreurind_m'] = media1t['neweurind'].mean()
media1t['norfatind_m'] = media1t['newfatind'].mean()

# Calculate reindexed indexed variables
base2['norfiscind_m'] = base2['norfiscind']
base2['noreurind_m'] = base2['noreurind']
base2['norfatind_m'] = base2['norfatind']
base2['newfiscind'] = 100 * base2['norfiscind'] / media1t['norfiscind_m']
base2['newpreind'] = base2['newpreind']
base2['neweurind'] = 100 * base2['noreurind'] / media1t['noreurind_m']
base2['newfatind'] = 100 * base2['norfatind'] / media1t['norfatind_m']

# Calculate reindexed frequency of indexed variables
base2['newfiscind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Reindexed Variable')
plt.show()

# Calculate reindexed frequency of indexed variables
base2['newpreind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Reindexed Variable')
plt.show()

# Calculate reindexed frequency of indexed variables
base2['neweurind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Reindexed Variable')
plt.show()

# Calculate reindexed frequency of indexed variables
base2['newfatind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Reindexed Variable')
plt.show()

# Create data frame for normalization comparison
ctscarto_r = base2[['codice_comune__str', 'nome_comune', 'sigla_provincia', 'popolazione', 'reddind', 'fiscind', 'prezind', 'neweurind', 'newfatind']]

# Normalize indexed variables
base2['norfiscind_m'] = base2['norfiscind']
base2['noreurind_m'] = base2['noreurind']
base2['norfatind_m'] = base2['norfatind']
base2['newfiscind'] = 100 * base2['norfiscind'] / base2['norfiscind_m']
base2['newpreind'] = base2['newpreind']
base2['neweurind'] = 100 * base2['noreurind'] / base2['noreurind_m']
base2['newfatind'] = 100 * base2['norfatind'] / base2['norfatind_m']

# Compute scarto_r variable
base2['scarto_r'] = base2['norfiscind'] - base2['noreurind']

# Merge indexed variables and compute median of scarto_r
base8 = base2[['codice_comune__str', 'nome_comune', 'sigla_provincia', 'popolazione', 'reddind', 'newfiscind', 'newpreind', 'neweurind', 'newfatind']]
base8 = base8.merge(base8.groupby(['popolazione']).agg({'norfiscind': 'median'}).reset_index(), on='popolazione', how='left')
base8 = base8.rename(columns={'norfiscind_y': 'medfiscind'})

# Compute weighted mean of indices
base2b = base2.groupby('popolazione').agg({'newfiscind': 'sum', 'popolazione': 'sum'}).reset_index()
base2b['newfiscind_m'] = base2b['newfiscind'] / base2b['popolazione']

# Create data frame for weighted mean calculation
media1d = base2b.rename(columns={'newfiscind': 'newfiscind_m'})

# Create data frame for weighted mean calculation
media1f = base2b.rename(columns={'newfiscind': 'neweurind_m'})

# Create data frame for weighted mean calculation
media1t = base2b.rename(columns={'newfiscind': 'norfatind_m'})

# Compute weighted mean of indices
media1d['newfiscind_m'] = base1d['newfiscind_m'].mean()
media1f['neweurind_m'] = base1f['neweurind_m'].mean()
media1t['norfatind_m'] = base1t['norfatind_m'].mean()

# Compute new indexed variables using the weighted mean
base2b['newfiscind'] = 100 * base2b['newfiscind'] / media1d['newfiscind_m']
base2b['neweurind'] = 100 * base2b['neweurind'] / media1f['neweurind_m']
base2b['norfatind'] = 100 * base2b['norfatind'] / media1t['norfatind_m']

# Plot frequency of reindexed variables using the weighted mean
base2b['newfiscind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Reindexed Variable using Weighted Mean')
plt.show()

# Plot frequency of reindexed variables using the weighted mean
base2b['neweurind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Reindexed Variable using Weighted Mean')
plt.show()

# Plot frequency of reindexed variables using the weighted mean
base2b['norfatind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Reindexed Variable using Weighted Mean')
plt.show()

# Rank indexed variables by value
base2e = base2.copy()
base2e['rank_ult'] = base2e['reddind'].rank(method='max')
base2e['rank_pre'] = base2e['newpreind'].rank(method='max')

# Print frequency of rankings
print(base2e.groupby(['rank_ult', 'rank_pre']).size())

# Rank indexed variables by value for communities with a population of at least 50,000
base2f = base2e[base2e['popolazione'] >= 50000]
base2f['rank_ult'] = base2f['reddind'].rank(method='max')
base2f['rank_pre'] = base2f['newpreind'].rank(method='max')

# Print frequency of rankings for communities with a population of at least 50,000
print(base2f.groupby(['rank_ult', 'rank_pre']).size())

# Print median of population
print(base2e['popolazione'].median())

# Create data frame for ranking comparison
qua3 = pd.read_sas(os.path.join(ter_path, "geografica_comune.sas7bdat"))
qua3 = qua3[['codice_comune__str', 'reddito_istat_ultimo']]

# Merge with base data
quadra = base8.merge(qua3, on='codice_comune__str', how='left')

# Create data frame for red_pro and pop_ita
rednaz = pd.read_sas(os.path.join(ter_path, "geografica_comune.sas7bdat"))
popnaz = pd.read_sas(os.path.join(ter_path, "demo20b.sas7bdat"))
rednaz = rednaz[['codice_comune__str', 'reddito_istat_ultimo']]
popnaz = popnaz[['codc620b', 'pop19']]
popnaz = popnaz.rename(columns={'codc620b': 'codice_comune__str', 'pop19': 'popita'})

# Compute regional statistics
rednaz = rednaz.merge(popnaz, on='codice_comune__str')
rednaz['redproit'] = rednaz['reddito_istat_ultimo'] / rednaz['popita']
rednaz['proit'] = rednaz['redproit'].mean()

# Create data frame for red_pro_q
base8['redpro_q'] = base8['redproind'] * base8['popolazione'] / rednaz['proit']
base8['redpro_q'] = base8['redpro_q'].sum()

# Normalize indexed variables using the weighted mean and the current red_pro
base8['medst'] = base8['popolazione'] * base8['proit'] * base8['newfiscind'] / 100

# Compute statistics for normalization
quadra = quadra.merge(popnaz, on='codice_comune__str', how='left')
rednaz['rednaz'] = rednaz['popita'] * rednaz['proit'] * base8['newfiscind'] / 100
rednaz['popnaz'] = popnaz['pop19'].sum()
italia = rednaz.groupby('codice_comune__str').agg({'rednaz': 'sum'}).reset_index()
italia['proit'] = italia['rednaz'].sum() / italia['popnaz'].sum()

# Create data frame for stima_qua
base8['stima_qua'] = base8['redpro_q'] * italia['proit']
base8['stima_qua'] = base8['stima_qua'].round()

# Arrange data frame by population
base8 = base8.sort_values(by='popolazione', ascending=False)

# Arrange data frame by corrected prices
base8 = base8.sort_values(by='reddito_precedente_q', ascending=False)

# Rank indexed variables by value
base8['rank_ult'] = base8['reddind'].rank(method='max')
base8['rank_pre'] = base8['reddito_precedente_q'].rank(method='max')

# Print frequency of rankings
print(base8.groupby(['rank_ult', 'rank_pre']).size())

# Compute corrected prices using the weighted mean
base8['newfiscind'] = 100 * base8['newfiscind'] / italia['proit']
base8['newpreind'] = base8['newpreind']
base8['neweurind'] = 100 * base8['neweurind'] / italia['proit']
base8['newfatind'] = 100 * base8['newfatind'] / italia['proit']

# Compute statistics for reindexed values using the weighted mean
base8b = base8.groupby('popolazione').agg({'newfiscind': 'sum', 'popolazione': 'sum'}).reset_index()
base8b['newfiscind_m'] = base8b['newfiscind'] / base8b['popolazione']
base8b['neweurind_m'] = base8b['neweurind'] / base8b['popolazione']
base8b['norfatind_m'] = base8b['norfatind'] / base8b['popolazione']

# Compute reindexed frequency of indexed variables using the weighted mean
base8b['newfiscind'] = 100 * base8b['newfiscind'] / base8b['newfiscind_m']
base8b['neweurind'] = 100 * base8b['neweurind'] / base8b['neweurind_m']
base8b['norfatind'] = 100 * base8b['norfatind'] / base8b['norfatind_m']

# Print frequency of reindexed variables using the weighted mean
base8b['newfiscind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Reindexed Variable using Weighted Mean')
plt.show()

# Print frequency of reindexed variables using the weighted mean
base8b['neweurind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Reindexed Variable using Weighted Mean')
plt.show()

# Print frequency of reindexed variables using the weighted mean
base8b['norfatind'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Indexed Variable')
plt.ylabel('Frequency')
plt.title('Frequency of Reindexed Variable using Weighted Mean')
plt.show()

# Rank indexed variables by value for communities with a population of at least 50,000
base8c = base8b.copy()
base8c['rank_ult'] = base8c['reddind'].rank(method='max')
base8c['rank_pre'] = base8c['reddito_precedente_q'].rank(method='max')

# Print frequency of rankings for communities with a population of at least 50,000
print(base8c.groupby(['rank_ult', 'rank_pre']).size())

# Sort data by territory
base8c = base8c.sort_values(by='territory')

# Print data with corrected prices using the weighted mean
print(base8c)

# Apply macro function for group-level quadraturation
result = macroquadraturagruppo(base8c, 'stima_qua', 'quadra', 'reddito_istat_ultimo', 'stima_qua', 'territory', 'qua1')
result = result.round()

# Apply macro function for group-level interpolation
result = macroarrotondainterogruppo(result, 'stima_qua', 'quadra', 'reddito_istat_ultimo', 'territory', 'qua3')

# Create data frame for regional statistics
print(base8c.groupby('territory').agg({'stima_qua': 'sum'}).reset_index())

# Create data frame for variance comparison
stima_varia_bis = result[['territory', 'reddito_istat_ultimo']]
stima_varia_bis = stima_varia_bis.merge(quadra, on='territory')
stima_varia_bis['redpro_ult'] = stima_varia_bis['stima_qua'] / stima_varia_bis['popolazione']
stima_varia_bis['redpro_pre'] = base8['redproult'] / base8['popolazione_precedente']
stima_varia_bis['redpro_pre_q'] = base8['redpro_q'] / base8['popolazione_precedente']
stima_varia_bis['varia_effettiva'] = 100 * (stima_varia_bis['redpro_ult'] / stima_varia_bis['redpro_pre']) - 1
stima_varia_bis['varia_q'] = 100 * (stima_varia_bis['redpro_ult'] / stima_varia_bis['redpro_pre_q']) - 1

# Create data frame for variance analysis
stima_varia_bis['codice_comune__str'] = base8['codice_comune__str']
stima_varia_bis['nome_comune'] = base8['nome_comune']
stima_varia_bis['sigla_provincia'] = base8['sigla_provincia']

# Plot frequency of variance effects
stima_varia_bis['varia_effettiva'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Variance Effect')
plt.ylabel('Frequency')
plt.title('Frequency of Variance Effect')
plt.show()

# Plot frequency of variance effects for communities with a population of at least 50,000
stima_varia_bis[stima_varia_bis['popolazione'] >= 50000]['varia_effettiva'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Variance Effect')
plt.ylabel('Frequency')
plt.title('Frequency of Variance Effect (Comunities with a Population of at least 50,000)')
plt.show()

# Plot frequency of variance effects using statistical percentiles
stima_varia_bis.describe(percentiles=[0.99, 0.1])

# Compute statistics for variance analysis
print(stima_varia_bis.groupby('popolazione').agg({'varia_effettiva': 'sum', 'varia_q': 'sum'}).reset_index())

# Create data frame for variance analysis
stima_varia_bis['varia_n'] = stima_varia_bis['varia_q']
stima_varia_bis['varia_n'] = np.where(stima_varia_bis['varia_q'] > 99, np.mean([99, stima_varia_bis['varia_q']]), stima_varia_bis['varia_q'])
stima_varia_bis['varia_n'] = np.where(stima_varia_bis['varia_q'] < 1, np.mean([1, stima_varia_bis['varia_q']]), stima_varia_bis['varia_q'])

# Plot frequency of variance normalized effects
stima_varia_bis['varia_n'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Variance Normalized Effect')
plt.ylabel('Frequency')
plt.title('Frequency of Variance Normalized Effect')
plt.show()

# Plot frequency of variance normalized effects for communities with a population of at least 50,000
stima_varia_bis[stima_varia_bis['popolazione'] >= 50000]['varia_n'].value_counts().plot(kind='hist', bins=50)
plt.xlabel('Variance Normalized Effect')
plt.ylabel('Frequency')
plt.title('Frequency of Variance Normalized Effect (Comunities with a Population of at least 50,000)')
plt.show()

# Plot frequency of variance normalized effects using statistical percentiles
stima_varia_bis[stima_varia_bis['popolazione'] >= 50000].describe(percentiles=[0.99, 0.1])

# Plot frequency of variance normalized effects
stima_varia_bis.groupby('popolazione').agg({'varia_n': 'sum'}).reset_index().plot(kind='hist', bins=50)
plt.xlabel('Variance Normalized Effect')
plt.ylabel('Frequency')
plt.title('Frequency of Variance Normalized Effect')
plt.show()

# Create data frame for variance analysis
stima_varia_bis['stima_n'] = base8['stima_qua']
stima_varia_bis['stima_n'] = np.where(stima_varia_bis['varia_q'] < 1, stima_varia_bis['redpro_pre_q'] * (1 + stima_varia_bis['varia_n'] / 100) * stima_varia_bis['popolazione_precedente'], stima_varia_bis['stima_n'])

# Print data with corrected prices using the weighted mean
print(stima_varia_bis)

# Apply macro function for group-level quadraturation
result = macroquadraturagruppo(stima_varia_bis, 'stima_n', 'quadra', 'reddito_istat_ultimo', 'stima_qua', 'territory', 'qua12')
result = result.round()

# Apply macro function for group-level interpolation
result = macroarrotondainterogruppo(result, 'stima_n', 'quadra', 'reddito_istat_ultimo', 'territory', 'qua32')

# Plot frequency of variance normalized effect by province
print(result.groupby(['territory']).agg({'varia_n': 'sum'}).reset_index())

# Print data with corrected prices using the weighted mean
print(result)

# Print frequency of variance normalized effect by province
result.groupby(['territory']).agg({'varia_n': 'sum'}).reset_index().plot(kind='hist', bins=50)
plt.xlabel('Variance Normalized Effect')
plt.ylabel('Frequency')
plt.title('Frequency of Variance Normalized Effect by Province')
plt.show()

# Print frequency of variance normalized effect by province and by population
result.groupby(['territory', 'popolazione']).agg({'varia_n': 'sum'}).reset_index().plot(kind='hist', bins=50)
plt.xlabel('Variance Normalized Effect')
plt.ylabel('Frequency')
plt.title('Frequency of Variance Normalized Effect by Province and Population')
plt.show()

# Create data frame for results
risultato = result[['codice_comune__str', 'stima_qua']]
risultato['anno_riferimento'] = 2020
risultato['release'] = 2021

# Print the results
print(risultato)
```